import requests
import re
import socket
import base64
import binascii
import os
import time
import hashlib
import logging
import uuid
import struct
import json
from urllib.parse import unquote, urlparse
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from functools import lru_cache
import urllib3

# ç¦ç”¨ä¸å®‰å…¨è¯·æ±‚è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ========== æ ¸å¿ƒé…ç½®ï¼ˆæœ€ç»ˆä¼˜åŒ–ç‰ˆï¼‰ ==========
CONFIG = {
    "sources": [
        {"url": "https://raw.githubusercontent.com/ripaojiedian/freenode/main/sub", "weight": 5},
        {"url": "https://raw.githubusercontent.com/barry-far/V2ray-Config/main/Splitted-By-Protocol/vmess.txt", "weight": 5},
        {"url": "https://raw.githubusercontent.com/MatinGhanbari/v2ray-configs/main/subscriptions/v2ray.txt", "weight": 5},
        {"url": "https://raw.githubusercontent.com/mfuu/v2ray/master/v2ray", "weight": 4},
        {"url": "https://raw.githubusercontent.com/ermaozi/get_subscribe/main/subscribe/v2ray.txt", "weight": 4},
        {"url": "https://raw.githubusercontent.com/free18/v2ray/refs/heads/main/v.txt", "weight": 3},
        {"url": "https://raw.githubusercontent.com/HakurouKen/free-node/main/public", "weight": 3},
        {"url": "https://raw.githubusercontent.com/Pawdroid/Free-servers/main/sub", "weight": 2}
    ],
    "request": {
        "timeout": 120,
        "retry": 2,
        "retry_delay": 2,
        "ua": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    },
    "github": {
        "token": os.getenv("GITHUB_TOKEN", ""),
        "interval": 0.5,
        "cache_ttl": 3600,
        "cache_max_size": 100 * 1024 * 1024  # ç¼“å­˜ç›®å½•æœ€å¤§100MB
    },
    "detection": {
        "tcp_timeout": {"vmess": 8, "vless": 8, "trojan": 8, "ss": 6, "hysteria": 10},
        "tcp_retry": 2,  # TCPæ¢æµ‹é‡è¯•æ¬¡æ•°ï¼ˆç¨³å®šæ€§éªŒè¯ï¼‰
        "tcp_retry_interval": 0.5,  # é‡è¯•é—´éš”
        "http_validate_urls": [  # å¯ç”¨æ€§éªŒè¯URLï¼ˆä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼‰
            "http://httpbin.org/ip",
            "https://www.google.com/generate_204",
            "http://ip-api.com/json/"
        ],
        "http_validate_timeout": 5,  # å¯ç”¨æ€§éªŒè¯è¶…æ—¶
        # åˆ†çº§HTTPéªŒè¯æ¬¡æ•°ï¼ˆå·®å¼‚åŒ–ï¼‰
        "http_validate_attempts": {
            "excellent": 1,  # ä¼˜è´¨èŠ‚ç‚¹ä»…éªŒè¯1ä¸ªURL
            "good": 2,       # è‰¯å¥½èŠ‚ç‚¹éªŒè¯2ä¸ªURL
            "qualified": 3   # åˆæ ¼èŠ‚ç‚¹éªŒè¯å…¨éƒ¨URL
        },
        "score_threshold": 60,  # ä¿ç•™é˜ˆå€¼
        "min_response_time": 0.05,  # æœ€å°æœ‰æ•ˆå“åº”æ—¶é—´
        "max_response_time": 8.0,   # æœ€å¤§æœ‰æ•ˆå“åº”æ—¶é—´
        # åŠ¨æ€å¹¶å‘é…ç½®
        "concurrency": {
            "small": 4,   # èŠ‚ç‚¹æ•°<100
            "medium": 8,  # 100â‰¤èŠ‚ç‚¹æ•°<500
            "large": 12   # èŠ‚ç‚¹æ•°â‰¥500
        }
    },
    "filter": {
        "private_ip_patterns": re.compile(r"^(192\.168\.|10\.|172\.(1[6-9]|2[0-9]|3[0-1])\.|::1|localhost)"),
        "cn_ip_patterns": re.compile(r"^(223\.|202\.|210\.|10\.|192\.168\.|172\.)"),
        "ports": range(1, 65535),
        "min_line_length": 10,  # æœ€å°èŠ‚ç‚¹è¡Œé•¿åº¦
        "max_line_length": 5000, # æœ€å¤§èŠ‚ç‚¹è¡Œé•¿åº¦
        "DEFAULT_PORT": 443,
        "SS_DEFAULT_CIPHER": "aes-256-gcm",
        "SS_VALID_CIPHERS": ["aes-256-gcm", "aes-128-gcm", "chacha20-ietf-poly1305", "aes-256-cfb", "aes-128-cfb"],
        # è¯„åˆ†æƒé‡é…ç½®ï¼ˆæœ€ç»ˆä¼˜åŒ–ç‰ˆï¼‰
        "score_weights": {
            # åŠ åˆ†é¡¹
            "protocol": {
                "vless": 20,
                "trojan": 18,
                "vmess": 15,
                "hysteria": 12,
                "ss": 8,
                "other": 0
            },
            "security": {
                "reality": 20,
                "tls": 18,
                "none": 0
            },
            "port": {
                443: 8,
                8443: 6,
                "other": 3
            },
            "dns_valid": 5,
            "net_validate": 10,
            "response_speed": {
                "0.05-0.5": 20,
                "0.5-1.0": 15,
                "1.0-3.0": 10,
                "3.0-8.0": 0,
                "<0.05|>8.0": 0
            },
            "availability": {
                "full": 15,  # HTTPè®¿é—®æˆåŠŸ
                "tcp_only": 5,  # ä»…TCPé€š
                "failed": 0
            },
            # æ‰£åˆ†é¡¹
            "cn_ip": {
                "pure_cn": -30,
                "cn_relay": -10,
                "non_cn": 0
            },
            "response_time": {
                "<0.05|>8.0": -30,
                "3.0-8.0": -10,
                "0.05-3.0": 0
            }
        },
        # åˆ†çº§åŒºé—´ï¼ˆæœ€ç»ˆä¼˜åŒ–ç‰ˆï¼‰
        "grade_ranges": {
            "excellent": (80, 100),  # ä¼˜è´¨
            "good": (70, 79),        # è‰¯å¥½
            "qualified": (60, 69)    # åˆæ ¼
        },
        # åŸºç¡€åˆ†é¢„è¿‡æ»¤é˜ˆå€¼ï¼ˆé¿å…æ— æ•ˆHTTPéªŒè¯ï¼‰
        "base_score_threshold": 50
    }
}

# ========== æ—¥å¿—åˆå§‹åŒ–ï¼ˆæœ€ç»ˆä¼˜åŒ–ç‰ˆï¼‰ ==========
def init_logger() -> logging.Logger:
    logger = logging.getLogger("node_scorer_optimized")
    logger.setLevel(logging.INFO)
    logger.propagate = False
    
    if not logger.handlers:
        formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s", "%Y-%m-%d %H:%M:%S")
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)
    
    return logger

LOG = init_logger()

# ========== æ ¸å¿ƒå·¥å…·å‡½æ•°ï¼ˆæè‡´ç²—ç­›+ç¼“å­˜å¤ç”¨ï¼‰ ==========
# IP/ç«¯å£è§£æç¼“å­˜ï¼ˆæ‰©å¤§ç¼“å­˜å®¹é‡ï¼‰
@lru_cache(maxsize=5000)
def extract_ip_port(line: str) -> tuple[str, str, int]:
    """æå–èŠ‚ç‚¹IPã€åŸŸåã€ç«¯å£ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    ip = ""
    domain = ""
    port = CONFIG["filter"]["DEFAULT_PORT"]
    
    try:
        # åŒ¹é…@åçš„IP/åŸŸåå’Œç«¯å£
        pattern = r"@([a-zA-Z0-9\-\.]+):(\d+)"
        match = re.search(pattern, line)
        if match:
            domain = match.group(1)
            port = int(match.group(2))
            
            # ä»…å¯¹éç§æœ‰åŸŸåå°è¯•è§£æIPï¼ˆé¿å…æ— æ•ˆè§£æï¼‰
            if not CONFIG["filter"]["private_ip_patterns"].match(domain):
                try:
                    ip = socket.gethostbyname(domain)
                except (socket.gaierror, ValueError):
                    ip = domain  # è§£æå¤±è´¥åˆ™ç”¨åŸŸåä»£æ›¿
    except Exception as e:
        LOG.debug(f"è§£æIP/ç«¯å£å¤±è´¥: {line[:50]}... é”™è¯¯: {str(e)}")
    
    return ip, domain, port

def clean_node_lines(raw_lines: list[str]) -> list[str]:
    """é˜¶æ®µ1.1ï¼šåŸå§‹è¡Œæ¸…æ´—ï¼ˆæè‡´ç²—ç­›ç¬¬ä¸€æ­¥ï¼‰"""
    cleaned = []
    for line in raw_lines:
        line = line.strip()
        # è¿‡æ»¤ç©ºè¡Œã€è¿‡çŸ­/è¿‡é•¿è¡Œã€ç‰¹æ®Šå­—ç¬¦è¡Œ
        if (not line or 
            len(line) < CONFIG["filter"]["min_line_length"] or 
            len(line) > CONFIG["filter"]["max_line_length"] or 
            re.search(r"[^\x20-\x7E]", line)):  # éASCIIå¯è§å­—ç¬¦
            continue
        cleaned.append(line)
    LOG.info(f"åŸå§‹è¡Œæ¸…æ´—å®Œæˆï¼šåŸ{len(raw_lines)}è¡Œ â†’ æ¸…æ´—å{len(cleaned)}è¡Œ")
    return cleaned

def quick_proto_validate(line: str) -> bool:
    """é˜¶æ®µ1.2ï¼šåè®®æ ¼å¼å¿«é€Ÿæ ¡éªŒï¼ˆä½æˆæœ¬ç²—ç­›ï¼‰"""
    line = line.strip()
    if not line:
        return False
    
    # VMessï¼šå¿«é€Ÿæ ¡éªŒBase64åˆæ³•æ€§
    if line.startswith("vmess://"):
        vmess_part = line.replace("vmess://", "")
        if len(vmess_part) % 4 != 0:  # Base64é•¿åº¦å¿…é¡»æ˜¯4çš„å€æ•°
            return False
        try:
            # ä»…æ ¡éªŒå‰200å­—ç¬¦ï¼ˆé¿å…è¶…é•¿è§£æï¼‰
            base64.b64decode(vmess_part[:200], validate=True)
            return True
        except base64.binascii.Error:
            return False
    
    # VLESSï¼šæ ¡éªŒæ ¸å¿ƒæ ¼å¼ï¼ˆ@å’Œç«¯å£ï¼‰
    elif line.startswith("vless://"):
        parts = line.split("@")
        if len(parts) < 2:
            return False
        port_part = parts[1].split(":")
        return len(port_part) >= 2 and port_part[1].isdigit()
    
    # Trojanï¼šæ ¡éªŒæ ¸å¿ƒæ ¼å¼
    elif line.startswith("trojan://"):
        parts = line.split("@")
        if len(parts) < 2:
            return False
        port_part = parts[1].split(":")
        return len(port_part) >= 2 and port_part[1].split("#")[0].isdigit()
    
    # SSï¼šå¿«é€Ÿæ ¡éªŒBase64åˆæ³•æ€§
    elif line.startswith("ss://"):
        ss_part = line.replace("ss://", "")
        if len(ss_part) % 4 != 0:
            return False
        try:
            base64.b64decode(ss_part[:200], validate=True)
            return True
        except base64.binascii.Error:
            return False
    
    # Hysteriaï¼šæ ¡éªŒæ ¸å¿ƒæ ¼å¼
    elif line.startswith("hysteria://"):
        parts = line.split(":")
        return len(parts) >= 2 and parts[1].replace("//", "").isdigit()
    
    # æœªçŸ¥åè®®
    return False

def pre_deduplicate_nodes(lines: list[str], sources: list[dict]) -> list[str]:
    """é˜¶æ®µ1.3ï¼šé¢„å»é‡ï¼ˆIP+ç«¯å£+åè®®ï¼‰ï¼Œä¿ç•™é«˜æƒé‡è®¢é˜…æºèŠ‚ç‚¹"""
    node_map = {}  # key: proto_ip_port, value: (line, weight)
    
    for line in lines:
        # å…ˆå¿«é€Ÿè§£æåè®®ç±»å‹
        proto = ""
        if line.startswith("vmess://"):
            proto = "vmess"
        elif line.startswith("vless://"):
            proto = "vless"
        elif line.startswith("trojan://"):
            proto = "trojan"
        elif line.startswith("ss://"):
            proto = "ss"
        elif line.startswith("hysteria://"):
            proto = "hysteria"
        else:
            continue
        
        # æå–IP+ç«¯å£
        ip, _, port = extract_ip_port(line)
        if not ip or not port:
            continue
        
        # åŒ¹é…èŠ‚ç‚¹æ‰€å±è®¢é˜…æºæƒé‡
        weight = 1
        for source in sources:
            if source["url"] in line:  # ç®€å•åŒ¹é…ï¼ˆå®é™…å¯ä¼˜åŒ–ä¸ºæº¯æºï¼‰
                weight = source["weight"]
                break
        
        # ä¿ç•™é«˜æƒé‡èŠ‚ç‚¹
        key = f"{proto}_{ip}_{port}"
        if key not in node_map or weight > node_map[key][1]:
            node_map[key] = (line, weight)
    
    # æå–å»é‡åçš„èŠ‚ç‚¹
    deduped = [v[0] for v in node_map.values()]
    LOG.info(f"èŠ‚ç‚¹é¢„å»é‡å®Œæˆï¼šåŸ{len(lines)}è¡Œ â†’ å»é‡å{len(deduped)}è¡Œ")
    return deduped

def filter_private_ip_and_invalid_port(lines: list[str]) -> list[str]:
    """é˜¶æ®µ1.4-1.5ï¼šè¿‡æ»¤ç§æœ‰IP+æ— æ•ˆç«¯å£"""
    filtered = []
    for line in lines:
        ip, _, port = extract_ip_port(line)
        
        # è¿‡æ»¤ç§æœ‰IP
        if is_private_ip(ip):
            LOG.debug(f"è¿‡æ»¤ç§æœ‰IPèŠ‚ç‚¹ï¼š{line[:50]}...")
            continue
        
        # è¿‡æ»¤æ— æ•ˆç«¯å£
        if port not in CONFIG["filter"]["ports"]:
            LOG.debug(f"è¿‡æ»¤æ— æ•ˆç«¯å£èŠ‚ç‚¹ï¼š{port} â†’ {line[:50]}...")
            continue
        
        filtered.append(line)
    
    LOG.info(f"ç§æœ‰IP+æ— æ•ˆç«¯å£è¿‡æ»¤å®Œæˆï¼šåŸ{len(lines)}è¡Œ â†’ è¿‡æ»¤å{len(filtered)}è¡Œ")
    return filtered

def is_private_ip(ip: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºç§æœ‰IP"""
    return CONFIG["filter"]["private_ip_patterns"].match(ip) is not None

def judge_cn_ip(ip: str, is_available: bool) -> str:
    """åˆ¤æ–­IPç±»å‹ï¼ˆçº¯å›½å†…/ä¸­è½¬/éå›½å†…ï¼‰"""
    if CONFIG["filter"]["cn_ip_patterns"].match(ip):
        # èƒ½è®¿é—®å¤–ç½‘åˆ™åˆ¤å®šä¸ºä¸­è½¬
        return "cn_relay" if is_available else "pure_cn"
    return "non_cn"

def get_response_speed_score(response_time: float) -> int:
    """è·å–å“åº”é€Ÿåº¦åŠ åˆ†ï¼ˆç²¾ç»†åŒ–ï¼‰"""
    if response_time < CONFIG["filter"]["min_response_time"] or response_time > CONFIG["filter"]["max_response_time"]:
        return 0
    elif 0.05 <= response_time < 0.5:
        return CONFIG["filter"]["score_weights"]["response_speed"]["0.05-0.5"]
    elif 0.5 <= response_time < 1.0:
        return CONFIG["filter"]["score_weights"]["response_speed"]["0.5-1.0"]
    elif 1.0 <= response_time < 3.0:
        return CONFIG["filter"]["score_weights"]["response_speed"]["1.0-3.0"]
    else:  # 3.0-8.0
        return 0

def get_response_time_penalty(response_time: float) -> int:
    """è·å–å“åº”æ—¶é—´æ‰£åˆ†ï¼ˆç²¾ç»†åŒ–ï¼‰"""
    if response_time < CONFIG["filter"]["min_response_time"] or response_time > CONFIG["filter"]["max_response_time"]:
        return CONFIG["filter"]["score_weights"]["response_time"]["<0.05|>8.0"]
    elif 3.0 <= response_time < 8.0:
        return CONFIG["filter"]["score_weights"]["response_time"]["3.0-8.0"]
    else:
        return 0

# ========== ç½‘ç»œæ¢æµ‹å‡½æ•°ï¼ˆè½»é‡â†’é‡åº¦ï¼Œé€æ­¥å‡çº§ï¼‰ ==========
def tcp_probe(ip: str, port: int, proto: str) -> tuple[bool, float]:
    """é˜¶æ®µ2.2ï¼šTCPæ¢æµ‹ï¼ˆç¨³å®šæ€§éªŒè¯ï¼š2æ¬¡æ¢æµ‹å–å¹³å‡ï¼‰"""
    total_time = 0.0
    success_count = 0
    timeout = CONFIG["detection"]["tcp_timeout"].get(proto, 8)
    
    for _ in range(CONFIG["detection"]["tcp_retry"]):
        start = time.time()
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                s.settimeout(timeout)
                s.connect((ip, port))
                success_count += 1
                total_time += (time.time() - start)
            time.sleep(CONFIG["detection"]["tcp_retry_interval"])
        except (socket.timeout, ConnectionRefusedError, OSError) as e:
            LOG.debug(f"TCPæ¢æµ‹å¤±è´¥ï¼š{ip}:{port} â†’ {str(e)}")
            continue
    
    if success_count == 0:
        return False, 0.0
    avg_time = total_time / success_count
    LOG.debug(f"TCPæ¢æµ‹æˆåŠŸï¼š{ip}:{port} â†’ å¹³å‡å“åº”æ—¶é—´{avg_time:.3f}s")
    return True, avg_time

def http_validate(ip: str, port: int, grade: str) -> str:
    """é˜¶æ®µ3.1ï¼šåˆ†çº§å·®å¼‚åŒ–HTTPå¯ç”¨æ€§éªŒè¯"""
    attempt_count = CONFIG["detection"]["http_validate_attempts"][grade]
    headers = {"User-Agent": CONFIG["request"]["ua"]}
    
    # æŒ‰åˆ†çº§å–å¯¹åº”æ•°é‡çš„éªŒè¯URL
    validate_urls = CONFIG["detection"]["http_validate_urls"][:attempt_count]
    
    for url in validate_urls:
        try:
            # ä¼˜å…ˆç”¨IPè®¿é—®ï¼ˆé¿å…DNSæ±¡æŸ“ï¼‰
            parsed = urlparse(url)
            # å¤„ç†443/80ç«¯å£çš„ç‰¹æ®Šæƒ…å†µ
            if port in [80, 443]:
                req_url = f"{parsed.scheme}://{ip}{parsed.path}"
            else:
                req_url = f"{parsed.scheme}://{ip}:{port}{parsed.path}"
            
            response = requests.get(
                req_url,
                headers=headers,
                timeout=CONFIG["detection"]["http_validate_timeout"],
                verify=False,
                allow_redirects=True
            )
            if response.status_code in [200, 204]:
                LOG.debug(f"HTTPéªŒè¯æˆåŠŸï¼š{ip}:{port} â†’ {url}")
                return "full"  # å®Œå…¨å¯ç”¨
        except (requests.Timeout, requests.ConnectionError, ValueError) as e:
            LOG.debug(f"HTTPéªŒè¯å¤±è´¥ï¼š{ip}:{port} â†’ {url} â†’ {str(e)}")
            continue
    
    return "tcp_only"  # ä»…TCPé€š

# ========== åè®®è§£æï¼ˆæŠ½è±¡é€šç”¨é€»è¾‘ï¼‰ ==========
class ProtocolParser:
    """åè®®è§£æåŸºç±»ï¼ˆä»…è§£æå¿…è¦ä¿¡æ¯ï¼Œé¿å…æ·±è§£æï¼‰"""
    @staticmethod
    def parse_basic_info(line: str) -> dict | None:
        """è§£æèŠ‚ç‚¹åŸºç¡€ä¿¡æ¯ï¼ˆåè®®/å®‰å…¨ç±»å‹ï¼‰"""
        line = line.strip()
        if not line:
            return None
        
        # VMess
        if line.startswith("vmess://"):
            try:
                vmess_part = line.replace("vmess://", "")
                decoded = base64.b64decode(vmess_part).decode('utf-8', errors='ignore')
                cfg = json.loads(decoded)
                security_type = "tls" if cfg.get("tls") == "tls" else "none"
                return {"protocol": "vmess", "security_type": security_type}
            except (base64.binascii.Error, json.JSONDecodeError, ValueError, KeyError):
                return {"protocol": "vmess", "security_type": "none"}
        
        # VLESS
        elif line.startswith("vless://"):
            security_type = "reality" if "reality=" in line else "tls" if "tls=" in line else "none"
            return {"protocol": "vless", "security_type": security_type}
        
        # Trojan
        elif line.startswith("trojan://"):
            security_type = "tls" if "tls" in line else "none"
            return {"protocol": "trojan", "security_type": security_type}
        
        # SS
        elif line.startswith("ss://"):
            return {"protocol": "ss", "security_type": "none"}
        
        # Hysteria
        elif line.startswith("hysteria://"):
            security_type = "tls" if "tls=" in line else "none"
            return {"protocol": "hysteria", "security_type": security_type}
        
        # æœªçŸ¥åè®®
        else:
            return {"protocol": "other", "security_type": "none"}

# ========== è¯„åˆ†é€»è¾‘ï¼ˆåŸºç¡€åˆ†â†’æœ€ç»ˆåˆ†ï¼Œåˆ†æ­¥è®¡ç®—ï¼‰ ==========
def calculate_base_score(node_info: dict, ip: str, port: int, response_time: float) -> tuple[int, dict]:
    """é˜¶æ®µ2.3ï¼šè®¡ç®—åŸºç¡€åˆ†ï¼ˆä»…è½»é‡ç½‘ç»œä¿¡æ¯ï¼Œæ— HTTPï¼‰"""
    score = 0
    score_detail = {"penalties": {}, "additions": {}, "base_score": 0}
    
    # 1. æ‰£åˆ†é¡¹
    # 1.1 å“åº”æ—¶é—´æ‰£åˆ†ï¼ˆå…ˆæ‰£ï¼Œæ— IPä¿¡æ¯ï¼‰
    rt_penalty = get_response_time_penalty(response_time)
    score += rt_penalty
    score_detail["penalties"]["response_time"] = rt_penalty
    
    # 2. åŠ åˆ†é¡¹ï¼ˆæ— HTTPç›¸å…³ï¼‰
    # 2.1 åè®®åŠ åˆ†
    proto_score = CONFIG["filter"]["score_weights"]["protocol"].get(node_info["protocol"], 0)
    score += proto_score
    score_detail["additions"]["protocol"] = proto_score
    
    # 2.2 å®‰å…¨ç±»å‹åŠ åˆ†
    sec_key = "reality" if node_info["security_type"] == "reality" else "tls" if node_info["security_type"] == "tls" else "none"
    sec_score = CONFIG["filter"]["score_weights"]["security"][sec_key]
    score += sec_score
    score_detail["additions"]["security"] = sec_score
    
    # 2.3 ç«¯å£åŠ åˆ†
    port_score = CONFIG["filter"]["score_weights"]["port"].get(port, CONFIG["filter"]["score_weights"]["port"]["other"])
    score += port_score
    score_detail["additions"]["port"] = port_score
    
    # 2.4 DNSæœ‰æ•ˆæ€§åŠ åˆ†ï¼ˆè§£ææˆåŠŸæ‰åŠ ï¼‰
    dns_score = CONFIG["filter"]["score_weights"]["dns_valid"] if ip else 0
    score += dns_score
    score_detail["additions"]["dns_valid"] = dns_score
    
    # 2.5 å“åº”é€Ÿåº¦åŠ åˆ†
    speed_score = get_response_speed_score(response_time)
    score += speed_score
    score_detail["additions"]["response_speed"] = speed_score
    
    # åŸºç¡€åˆ†ä¿®æ­£ï¼ˆ0~100ï¼‰
    base_score = max(0, min(score, 100))
    score_detail["base_score"] = base_score
    
    # é¢„åˆ†çº§ï¼ˆç”¨äºåç»­HTTPéªŒè¯æ¬¡æ•°ï¼‰
    if base_score >= CONFIG["filter"]["grade_ranges"]["excellent"][0]:
        score_detail["pre_grade"] = "excellent"
    elif base_score >= CONFIG["filter"]["grade_ranges"]["good"][0]:
        score_detail["pre_grade"] = "good"
    elif base_score >= CONFIG["filter"]["base_score_threshold"]:
        score_detail["pre_grade"] = "qualified"
    else:
        score_detail["pre_grade"] = "reject"
    
    return base_score, score_detail

def calculate_final_score(base_score: int, base_detail: dict, ip: str, availability: str) -> tuple[int, dict]:
    """é˜¶æ®µ3.2ï¼šè®¡ç®—æœ€ç»ˆåˆ†ï¼ˆåŠ å…¥HTTPéªŒè¯+å›½å†…IPæ‰£åˆ†ï¼‰"""
    final_score = base_score
    score_detail = base_detail.copy()
    score_detail["final_score"] = 0
    score_detail["grade"] = ""
    
    # 1. å›½å†…IPæ‰£åˆ†ï¼ˆä¾èµ–å¯ç”¨æ€§ï¼‰
    cn_ip_type = judge_cn_ip(ip, availability == "full")
    cn_penalty = CONFIG["filter"]["score_weights"]["cn_ip"][cn_ip_type]
    final_score += cn_penalty
    score_detail["penalties"]["cn_ip"] = cn_penalty
    
    # 2. å¤–ç½‘éªŒè¯åŠ åˆ†ï¼ˆHTTPæˆåŠŸæ‰åŠ ï¼‰
    net_score = CONFIG["filter"]["score_weights"]["net_validate"] if availability == "full" else 0
    final_score += net_score
    score_detail["additions"]["net_validate"] = net_score
    
    # 3. å¯ç”¨æ€§åŠ åˆ†
    avail_score = CONFIG["filter"]["score_weights"]["availability"][availability]
    final_score += avail_score
    score_detail["additions"]["availability"] = avail_score
    
    # æœ€ç»ˆåˆ†ä¿®æ­£
    final_score = max(0, min(final_score, 100))
    score_detail["final_score"] = final_score
    
    # æœ€ç»ˆåˆ†çº§
    if final_score >= CONFIG["filter"]["grade_ranges"]["excellent"][0]:
        score_detail["grade"] = "excellent"
    elif final_score >= CONFIG["filter"]["grade_ranges"]["good"][0]:
        score_detail["grade"] = "good"
    elif final_score >= CONFIG["filter"]["grade_ranges"]["qualified"][0]:
        score_detail["grade"] = "qualified"
    else:
        score_detail["grade"] = "reject"
    
    return final_score, score_detail

# ========== æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ï¼ˆä¸¥æ ¼æŒ‰æ˜“â†’éš¾æ‰§è¡Œï¼‰ ==========
def load_subscription() -> list[str]:
    """åŠ è½½è®¢é˜…æºï¼ˆå¸¦ç¼“å­˜ä¼˜åŒ–ï¼‰"""
    all_nodes = []
    cache_dir = ".cache"
    os.makedirs(cache_dir, exist_ok=True)
    
    # æ¸…ç†è¿‡æœŸ/è¶…å¤§ç¼“å­˜
    clean_cache(cache_dir)
    
    with requests.Session() as sess:
        sess.headers["User-Agent"] = CONFIG["request"]["ua"]
        
        for source in CONFIG["sources"]:
            url = source["url"]
            cache_key = hashlib.md5(url.encode()).hexdigest()
            cache_path = os.path.join(cache_dir, f"{cache_key}.json")
            
            # ä¼˜å…ˆè¯»ç¼“å­˜
            if os.path.exists(cache_path) and time.time() - os.path.getmtime(cache_path) < CONFIG["github"]["cache_ttl"]:
                try:
                    with open(cache_path, "r", encoding="utf-8") as f:
                        cached_nodes = json.load(f)
                    all_nodes.extend(cached_nodes)
                    LOG.info(f"ä»ç¼“å­˜åŠ è½½è®¢é˜…æº: {url}ï¼ŒèŠ‚ç‚¹æ•°: {len(cached_nodes)}")
                    continue
                except (json.JSONDecodeError, OSError) as e:
                    LOG.warning(f"ç¼“å­˜è¯»å–å¤±è´¥: {cache_path} é”™è¯¯: {str(e)}")
            
            # æ‹‰å–è®¢é˜…æº
            try:
                response = sess.get(url, timeout=CONFIG["request"]["timeout"])
                response.raise_for_status()
                
                # è§£ç è®¢é˜…å†…å®¹
                decoded = base64.b64decode(response.text).decode('utf-8', errors='ignore')
                nodes = [line.strip() for line in decoded.split("\n") if line.strip()]
                
                # ä¿å­˜ç¼“å­˜
                with open(cache_path, "w", encoding="utf-8") as f:
                    json.dump(nodes, f, ensure_ascii=False)
                
                all_nodes.extend(nodes)
                LOG.info(f"æ‹‰å–è®¢é˜…æºæˆåŠŸ: {url}ï¼ŒèŠ‚ç‚¹æ•°: {len(nodes)}")
                
                time.sleep(CONFIG["github"]["interval"])
            except (requests.RequestException, base64.binascii.Error) as e:
                LOG.error(f"æ‹‰å–è®¢é˜…æºå¤±è´¥: {url} é”™è¯¯: {str(e)}")
                continue
    
    # åŸå§‹è¡Œå»é‡ï¼ˆç²—å»é‡ï¼‰
    unique_raw = list(dict.fromkeys(all_nodes))
    LOG.info(f"è®¢é˜…æºåŠ è½½å®Œæˆï¼Œæ€»èŠ‚ç‚¹æ•°: {len(all_nodes)}ï¼ŒåŸå§‹å»é‡å: {len(unique_raw)}")
    
    return unique_raw

def clean_cache(cache_dir: str):
    """æ¸…ç†ç¼“å­˜ï¼ˆè¿‡æœŸ/è¶…å¤§ï¼‰"""
    try:
        total_size = 0
        files = []
        
        for f in os.listdir(cache_dir):
            f_path = os.path.join(cache_dir, f)
            if os.path.isfile(f_path):
                f_size = os.path.getsize(f_path)
                total_size += f_size
                files.append((f_path, os.path.getmtime(f_path), f_size))
        
        # åˆ é™¤è¿‡æœŸæ–‡ä»¶
        for f_path, mtime, _ in files:
            if time.time() - mtime > CONFIG["github"]["cache_ttl"]:
                os.remove(f_path)
                LOG.info(f"åˆ é™¤è¿‡æœŸç¼“å­˜: {f_path}")
        
        # åˆ é™¤æœ€æ—§æ–‡ä»¶ç›´åˆ°å°äºæœ€å¤§é™åˆ¶
        files.sort(key=lambda x: x[1])
        while total_size > CONFIG["github"]["cache_max_size"] and files:
            f_path, _, f_size = files.pop(0)
            os.remove(f_path)
            total_size -= f_size
            LOG.info(f"åˆ é™¤è¶…å¤§ç¼“å­˜: {f_path}")
    
    except OSError as e:
        LOG.error(f"ç¼“å­˜æ¸…ç†å¤±è´¥: {str(e)}")

def process_single_node(line: str) -> tuple[int, dict, str]:
    """å¤„ç†å•ä¸ªèŠ‚ç‚¹ï¼ˆä¸¥æ ¼æŒ‰æ˜“â†’éš¾æµç¨‹ï¼‰"""
    # åˆå§‹åŒ–è¿”å›å€¼
    final_score = 0
    score_detail = {"grade": "reject"}
    
    # é˜¶æ®µ1ï¼šæè‡´ç²—ç­›ï¼ˆå·²å‰ç½®ï¼Œæ­¤å¤„åšäºŒæ¬¡æ ¡éªŒï¼‰
    if not quick_proto_validate(line):
        return 0, score_detail, line
    
    # æå–åŸºç¡€ä¿¡æ¯
    node_info = ProtocolParser.parse_basic_info(line)
    ip, domain, port = extract_ip_port(line)
    
    # è¿‡æ»¤ç§æœ‰IPï¼ˆäºŒæ¬¡æ ¡éªŒï¼‰
    if is_private_ip(ip):
        return 0, score_detail, line
    
    # é˜¶æ®µ2ï¼šè½»é‡ç½‘ç»œç­›
    # 2.1 TCPæ¢æµ‹
    tcp_ok, response_time = tcp_probe(ip, port, node_info["protocol"])
    if not tcp_ok:
        return 0, score_detail, line
    
    # 2.2 è®¡ç®—åŸºç¡€åˆ†ï¼ˆé¢„è¿‡æ»¤ï¼‰
    base_score, base_detail = calculate_base_score(node_info, ip, port, response_time)
    if base_score < CONFIG["filter"]["base_score_threshold"]:
        LOG.debug(f"åŸºç¡€åˆ†é¢„è¿‡æ»¤ï¼š{base_score}åˆ† â†’ {line[:50]}...")
        return 0, base_detail, line
    
    # é˜¶æ®µ3ï¼šé‡åº¦ç½‘ç»œç­›ï¼ˆä»…åŸºç¡€åˆ†è¾¾æ ‡èŠ‚ç‚¹ï¼‰
    # 3.1 åˆ†çº§å·®å¼‚åŒ–HTTPéªŒè¯
    availability = http_validate(ip, port, base_detail["pre_grade"])
    
    # 3.2 è®¡ç®—æœ€ç»ˆåˆ†
    final_score, final_detail = calculate_final_score(base_score, base_detail, ip, availability)
    
    return final_score, final_detail, line

def batch_process_nodes(nodes: list[str]) -> dict:
    """æ‰¹é‡å¤„ç†èŠ‚ç‚¹ï¼ˆåŠ¨æ€å¹¶å‘ï¼‰"""
    results = {
        "excellent": [],
        "good": [],
        "qualified": [],
        "all": []
    }
    
    # åŠ¨æ€è°ƒæ•´å¹¶å‘æ•°
    node_count = len(nodes)
    if node_count < 100:
        worker_num = CONFIG["detection"]["concurrency"]["small"]
    elif node_count < 500:
        worker_num = CONFIG["detection"]["concurrency"]["medium"]
    else:
        worker_num = CONFIG["detection"]["concurrency"]["large"]
    
    LOG.info(f"å¼€å§‹æ‰¹é‡å¤„ç†èŠ‚ç‚¹ï¼Œæ€»æ•°: {node_count}ï¼Œå¹¶å‘æ•°: {worker_num}")
    
    with ThreadPoolExecutor(max_workers=worker_num) as executor:
        # æäº¤ä»»åŠ¡
        futures = [executor.submit(process_single_node, line) for line in nodes]
        
        # å¤„ç†ç»“æœ
        processed = 0
        for future in as_completed(futures):
            try:
                score, detail, line = future.result()
                processed += 1
                
                # æŒ‰æœ€ç»ˆåˆ†çº§å½’ç±»
                if score >= CONFIG["detection"]["score_threshold"]:
                    if detail["grade"] == "excellent":
                        results["excellent"].append(line)
                    elif detail["grade"] == "good":
                        results["good"].append(line)
                    elif detail["grade"] == "qualified":
                        results["qualified"].append(line)
                    results["all"].append(line)
                
                # è¿›åº¦æ—¥å¿—
                if processed % 50 == 0:
                    LOG.info(f"èŠ‚ç‚¹å¤„ç†è¿›åº¦ï¼š{processed}/{node_count}")
            except Exception as e:
                LOG.warning(f"å¤„ç†èŠ‚ç‚¹å¤±è´¥: {str(e)}")
    
    LOG.info(f"èŠ‚ç‚¹æ‰¹é‡å¤„ç†å®Œæˆ - ä¼˜è´¨: {len(results['excellent'])}ï¼Œè‰¯å¥½: {len(results['good'])}ï¼Œåˆæ ¼: {len(results['qualified'])}ï¼Œæ€»è®¡æœ‰æ•ˆ: {len(results['all'])}")
    return results

def save_results(results: dict):
    """ä¿å­˜ç»“æœï¼ˆBase64ç¼–ç ï¼‰"""
    # ç»Ÿä¸€Base64ç¼–ç 
    def encode_nodes(nodes: list[str]) -> str:
        if not nodes:
            return ""
        content = "\n".join(nodes)
        return base64.b64encode(content.encode('utf-8')).decode('utf-8')
    
    # ä¿å­˜å„åˆ†çº§æ–‡ä»¶
    files = [
        ("s1_excellent.txt", results["excellent"], "ä¼˜è´¨èŠ‚ç‚¹ï¼ˆâ‰¥80åˆ†ï¼‰"),
        ("s1_good.txt", results["good"], "è‰¯å¥½èŠ‚ç‚¹ï¼ˆ70-79åˆ†ï¼‰"),
        ("s1_qualified.txt", results["qualified"], "åˆæ ¼èŠ‚ç‚¹ï¼ˆ60-69åˆ†ï¼‰"),
        ("s1.txt", results["all"], "æ‰€æœ‰æœ‰æ•ˆèŠ‚ç‚¹ï¼ˆâ‰¥60åˆ†ï¼‰")
    ]
    
    for filename, nodes, desc in files:
        encoded = encode_nodes(nodes)
        try:
            with open(filename, "w", encoding="utf-8") as f:
                f.write(encoded)
            LOG.info(f"âœ… ä¿å­˜{desc}åˆ° {filename}ï¼ŒèŠ‚ç‚¹æ•°: {len(nodes)}")
        except OSError as e:
            LOG.error(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {filename} é”™è¯¯: {str(e)}")

# ========== ä¸»æ‰§è¡Œå‡½æ•°ï¼ˆä¸¥æ ¼æŒ‰æ˜“â†’éš¾æµç¨‹ç¼–æ’ï¼‰ ==========
def main():
    """ä¸»æ‰§è¡Œå‡½æ•°ï¼ˆæœ€ç»ˆä¼˜åŒ–ç‰ˆï¼‰"""
    start_time = time.time()
    LOG.info("="*60)
    LOG.info("èŠ‚ç‚¹ç­›é€‰è„šæœ¬å¯åŠ¨ï¼ˆæè‡´ç²—ç­›+åˆ†çº§éªŒè¯ç‰ˆï¼‰")
    LOG.info("="*60)
    
    try:
        # ========== é˜¶æ®µ1ï¼šæè‡´ç²—ç­›ï¼ˆçº¯æœ¬åœ°ï¼Œæ— ç½‘ç»œIOï¼‰ ==========
        LOG.info("\nã€é˜¶æ®µ1ï¼šæè‡´ç²—ç­›ã€‘")
        # 1.1 åŠ è½½è®¢é˜…æº+åŸå§‹è¡Œæ¸…æ´—
        raw_nodes = load_subscription()
        cleaned_lines = clean_node_lines(raw_nodes)
        
        # 1.2 åè®®æ ¼å¼å¿«é€Ÿæ ¡éªŒ
        valid_proto_lines = [line for line in cleaned_lines if quick_proto_validate(line)]
        LOG.info(f"åè®®æ ¼å¼æ ¡éªŒå®Œæˆï¼šåŸ{len(cleaned_lines)}è¡Œ â†’ æœ‰æ•ˆ{len(valid_proto_lines)}è¡Œ")
        
        # 1.3 é¢„å»é‡ï¼ˆIP+ç«¯å£+åè®®ï¼‰
        deduped_lines = pre_deduplicate_nodes(valid_proto_lines, CONFIG["sources"])
        
        # 1.4-1.5 è¿‡æ»¤ç§æœ‰IP+æ— æ•ˆç«¯å£
        filtered_lines = filter_private_ip_and_invalid_port(deduped_lines)
        
        # ========== é˜¶æ®µ2+3ï¼šç½‘ç»œç­›ï¼ˆè½»é‡â†’é‡åº¦ï¼‰ ==========
        LOG.info("\nã€é˜¶æ®µ2+3ï¼šç½‘ç»œç­›é€‰ï¼ˆè½»é‡â†’é‡åº¦ï¼‰ã€‘")
        # æ‰¹é‡å¤„ç†èŠ‚ç‚¹ï¼ˆTCPæ¢æµ‹â†’åŸºç¡€åˆ†é¢„è¿‡æ»¤â†’HTTPéªŒè¯â†’æœ€ç»ˆè¯„åˆ†ï¼‰
        results = batch_process_nodes(filtered_lines)
        
        # ========== ç»“æœä¿å­˜ ==========
        LOG.info("\nã€é˜¶æ®µ4ï¼šç»“æœä¿å­˜ã€‘")
        save_results(results)
        
        # ========== æœ€ç»ˆç»Ÿè®¡ ==========
        total_time = time.time() - start_time
        LOG.info("\n" + "="*60)
        LOG.info(f"âœ… è„šæœ¬æ‰§è¡Œå®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’")
        LOG.info(f"ğŸ“Š æœ€ç»ˆç»“æœ - ä¼˜è´¨èŠ‚ç‚¹: {len(results['excellent'])} | è‰¯å¥½èŠ‚ç‚¹: {len(results['good'])} | åˆæ ¼èŠ‚ç‚¹: {len(results['qualified'])} | æ€»è®¡æœ‰æ•ˆ: {len(results['all'])}")
        LOG.info("="*60)
    
    except Exception as e:
        LOG.error(f"âŒ è„šæœ¬æ‰§è¡Œå¤±è´¥: {str(e)}", exc_info=True)

if __name__ == "__main__":
    main()
