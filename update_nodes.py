import requests
import re
import socket
import base64
import binascii
import os
import time
import hashlib
import logging
import uuid
import struct
from urllib.parse import unquote, urlparse
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from functools import lru_cache
import urllib3
from typing import Dict, List, Tuple, Optional, Union
import json

# ========== é…ç½®ä¸åˆå§‹åŒ– ==========
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# æ ¸å¿ƒé…ç½®ï¼ˆæ–°å¢å¤–ç½‘éªŒè¯/IPåœ°åŸŸè¿‡æ»¤ï¼‰
CONFIG: Dict = {
    "sources": [
        {"url": "https://raw.githubusercontent.com/ripaojiedian/freenode/main/sub", "weight": 5},
        {"url": "https://raw.githubusercontent.com/barry-far/V2ray-Config/main/Splitted-By-Protocol/vmess.txt", "weight": 5},
        {"url": "https://raw.githubusercontent.com/MatinGhanbari/v2ray-configs/main/subscriptions/v2ray/super-sub.txt", "weight": 5},
        {"url": "https://raw.githubusercontent.com/mfuu/v2ray/master/v2ray", "weight": 4},
        {"url": "https://raw.githubusercontent.com/ermaozi/get_subscribe/main/subscribe/v2ray.txt", "weight": 4},
        {"url": "https://raw.githubusercontent.com/free18/v2ray/refs/heads/main/v.txt", "weight": 3},
        {"url": "https://raw.githubusercontent.com/HakurouKen/free-node/main/public", "weight": 3},
        {"url": "https://raw.githubusercontent.com/Pawdroid/Free-servers/main/sub", "weight": 2}
    ],
    "request": {"timeout": 15, "retry": 3, "retry_delay": 3, "ua": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"},
    "github": {"token": os.getenv("GITHUB_TOKEN", ""), "interval": 0.5, "cache_ttl": 3600, "cache_expire_days": 7},
    "detection": {
        "tcp_timeout": {"vmess":5, "vless":5, "trojan":5, "ss":4, "hysteria":6},
        "tcp_retry": 1,
        "thread_pool": 8,  # é™ä½çº¿ç¨‹æ•°ï¼Œæå‡æµ‹è¯•ç¨³å®šæ€§
        "dns": {"servers": ["223.5.5.5", "119.29.29.29", "8.8.8.8", "1.1.1.1"], "timeout":4, "cache_size":1000},
        "http_test": {
            "timeout": 10,
            # å¤–ç½‘éªŒè¯ç›®æ ‡ï¼ˆä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼‰
            "targets": [
                "http://www.google.com/generate_204",  # æµ·å¤–æ ¸å¿ƒç›®æ ‡
                "https://api.github.com/",             # GitHub API
                "http://httpbin.org/ip",               # å‡ºå£IPéªŒè¯
                "https://api.ipify.org?format=json"    # å…¬ç½‘IPéªŒè¯
            ],
            "fallback": "http://baidu.com"
        },
        "score_threshold": 75,  # æé«˜é˜ˆå€¼è‡³75åˆ†
        "min_response_time": 0.1,  # æœ€å°å“åº”æ—¶é—´ï¼ˆè¿‡æ»¤<0.1sçš„å‡èŠ‚ç‚¹ï¼‰
        "max_response_time": 5.0   # æœ€å¤§å“åº”æ—¶é—´ï¼ˆè¿‡æ»¤>5sçš„æ…¢èŠ‚ç‚¹ï¼‰
    },
    "filter": {
        "private_ip": re.compile(r"^(192\.168\.|10\.|172\.(1[6-9]|2\d|3[0-1])\.|127\.|0\.0\.0\.0)"),
        # å›½å†…IPæ®µï¼ˆç®€åŒ–ç‰ˆï¼Œè¦†ç›–ä¸»è¦å›½å†…è¿è¥å•†ï¼‰
        "cn_ip_ranges": [
            re.compile(r"^1\.0\.16\."), re.compile(r"^1\.0\.64\."), re.compile(r"^101\."),
            re.compile(r"^103\.(?!106|96)"),  # æ’é™¤éƒ¨åˆ†æµ·å¤–æ®µ
            re.compile(r"^112\."), re.compile(r"^113\."), re.compile(r"^120\."),
            re.compile(r"^121\."), re.compile(r"^122\."), re.compile(r"^123\."),
            re.compile(r"^139\."), re.compile(r"^140\."), re.compile(r"^141\."),
            re.compile(r"^150\."), re.compile(r"^151\."), re.compile(r"^163\."),
            re.compile(r"^171\."), re.compile(r"^172\.(?!16|17|18|19|20|21|22|23|24|25|26|27|28|29|30|31)"),
            re.compile(r"^173\."), re.compile(r"^174\."), re.compile(r"^180\."),
            re.compile(r"^181\."), re.compile(r"^182\."), re.compile(r"^183\."),
            re.compile(r"^184\."), re.compile(r"^190\."), re.compile(r"^192\.168\."),
            re.compile(r"^202\."), re.compile(r"^203\."), re.compile(r"^210\."),
            re.compile(r"^211\."), re.compile(r"^220\."), re.compile(r"^221\."),
            re.compile(r"^222\."), re.compile(r"^223\.")
        ],
        "ports": range(1, 65535),
        "max_remark_bytes": 200,
        "DEFAULT_PORT": 443,
        "SS_DEFAULT_CIPHER": "aes-256-gcm",
        "SS_VALID_CIPHERS": ["aes-256-gcm", "aes-128-gcm", "chacha20-ietf-poly1305", "aes-256-cfb", "aes-128-cfb"],
        # æå‡è¯„åˆ†æƒé‡ï¼šå¤–ç½‘éªŒè¯>å“åº”é€Ÿåº¦>åè®®ç±»å‹
        "score_rules": {
            "protocol": {"vless": 25, "trojan": 20, "vmess": 15, "hysteria": 10, "ss": 5, "other": 0},
            "security": {"reality": 25, "tls": 20, "none": 0},
            "port": {443: 10, 8443: 8, "other": 3},
            "response_speed": {"fast": 10, "normal": 5, "slow": 0},
            "dns_valid": 5,
            "http_valid": 20,  # å¤–ç½‘éªŒè¯æƒé‡ç¿»å€
            "cn_ip": -50,      # å›½å†…IPç›´æ¥æ‰£50åˆ†
            "response_time_abnormal": -100  # å“åº”æ—¶é—´å¼‚å¸¸ç›´æ¥æ‰£åˆ†
        }
    }
}

# æ—¥å¿—åˆå§‹åŒ–
def init_logger() -> logging.Logger:
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)
    logger.propagate = False
    if not logger.handlers:
        fmt = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s", "%Y-%m-%d %H:%M:%S")
        handler = logging.StreamHandler()
        handler.setFormatter(fmt)
        logger.addHandler(handler)
    return logger

LOG = init_logger()

# å…¨å±€è¯·æ±‚ä¼šè¯ï¼ˆç¦ç”¨ä»£ç†ï¼‰
def init_session() -> requests.Session:
    sess = requests.Session()
    sess.trust_env = False  # ç¦ç”¨ç³»ç»Ÿä»£ç†ï¼Œé¿å…å¹²æ‰°æµ‹è¯•
    headers = {"User-Agent": CONFIG["request"]["ua"], "Accept": "*/*"}
    if CONFIG["github"]["token"]:
        headers["Authorization"] = f"token {CONFIG['github']['token']}"
    sess.headers.update(headers)
    adapter = requests.adapters.HTTPAdapter(pool_connections=8, pool_maxsize=16, max_retries=2)
    sess.mount("https://", adapter)
    sess.mount("http://", adapter)
    return sess

SESSION = init_session()

# ========== æ ¸å¿ƒè¿‡æ»¤å·¥å…·å‡½æ•° ==========
def validate_port(port: Union[str, int]) -> int:
    try:
        p = int(port)
        return p if p in CONFIG["filter"]["ports"] else CONFIG["filter"]["DEFAULT_PORT"]
    except (ValueError, TypeError):
        return CONFIG["filter"]["DEFAULT_PORT"]

def log_msg(content: str, line: str = "", proto: str = "") -> str:
    if "ä¿ç•™èŠ‚ç‚¹" in content:
        line_part = ""
    else:
        if "è§£æé”™è¯¯" in content or "è¿‡æ»¤æ— æ•ˆ" in content or "ç©ºåœ°å€èŠ‚ç‚¹" in content:
            line_part = f"ï¼ˆ{line}ï¼‰" if line else ""
        else:
            safe_line = line[:20].encode('ascii', 'ignore').decode('ascii') if line else ""
            line_part = f"ï¼ˆ{safe_line}...ï¼‰" if safe_line else ""
    proto_part = f"ï¼ˆ{proto}ï¼‰" if proto else ""
    return f"{content}{line_part}{proto_part}"

def b64_safe_decode(b64_str: str) -> str:
    try:
        b64_str = b64_str.rstrip('=')
        b64_str += '=' * (4 - len(b64_str) % 4) if len(b64_str) % 4 != 0 else ''
        # å¤„ç†URLå®‰å…¨Base64
        b64_str = b64_str.replace('-', '+').replace('_', '/')
        return base64.b64decode(b64_str, validate=True).decode('utf-8', errors='ignore')
    except (binascii.Error, ValueError, TypeError):
        return b64_str

def clean_special_chars(line: str) -> str:
    if not line:
        return ""
    clean_line = re.sub(r'[\u200b\u3000\s]+', '', line)
    clean_line = clean_line.replace('ï¼ ', '@')
    return clean_line

def proto_preprocess(line: str, proto_prefix: str) -> Tuple[str, str]:
    clean_line = clean_special_chars(line)
    remark = f"{proto_prefix.upper()}èŠ‚ç‚¹"
    
    if '#' in clean_line:
        main_part, remark = clean_line.split('#', 1)
        remark = process_remark(remark, proto_prefix.upper())
    else:
        main_part = clean_line
    
    if not main_part.startswith(proto_prefix):
        raise ValueError(f"é{proto_prefix.upper()}èŠ‚ç‚¹æ ¼å¼")
    
    core_content = main_part[len(proto_prefix):].strip()
    if not core_content:
        raise ValueError(f"{proto_prefix.upper()}æ ¸å¿ƒå†…å®¹ä¸ºç©º")
    
    return core_content, remark

def decode_b64_sub(text: str) -> str:
    """ä¼˜åŒ–ï¼šä»…å½“å†…å®¹ç¬¦åˆBase64æ ¼å¼æ—¶æ‰è§£ç ï¼Œé¿å…æ˜æ–‡èŠ‚ç‚¹è¯¯å¤„ç†"""
    original_text = text.strip()
    if not original_text:
        return ""
    
    # Base64æ ¼å¼åˆ¤æ–­è§„åˆ™ï¼š
    # 1. é•¿åº¦ä¸º4çš„å€æ•°ï¼ˆå…è®¸æœ«å°¾è¡¥=ï¼‰
    # 2. ä»…åŒ…å«Base64æœ‰æ•ˆå­—ç¬¦ï¼ˆA-Za-z0-9+/=ï¼‰æˆ–URLå®‰å…¨å­—ç¬¦ï¼ˆ-_ï¼‰
    base64_pattern = re.compile(r'^[A-Za-z0-9+/=_-]+$')
    clean_for_b64 = re.sub(r'\s+', '', original_text)
    
    # ä»…å½“æ•´ä½“ç¬¦åˆBase64æ ¼å¼æ—¶æ‰è§£ç 
    if len(clean_for_b64) % 4 == 0 and base64_pattern.match(clean_for_b64):
        try:
            decoded = b64_safe_decode(clean_for_b64)
            decoded_line_count = len([l for l in decoded.split('\n') if l.strip()])
            LOG.info(log_msg(f"âœ… Base64è§£ç æˆåŠŸï¼Œè§£æå‡º{decoded_line_count}ä¸ªæœ‰æ•ˆèŠ‚ç‚¹"))
            return decoded
        except Exception as e:
            LOG.info(log_msg(f"âŒ Base64è§£ç å¤±è´¥: {str(e)[:50]}ï¼Œä½¿ç”¨æ˜æ–‡å¤„ç†"))
    
    # éBase64æ ¼å¼ï¼Œç›´æ¥è¿”å›æ¸…ç†åçš„æ˜æ–‡
    cleaned_lines = [l.strip() for l in original_text.split('\n')]
    plain_line_count = len([l for l in cleaned_lines if l])
    LOG.info(log_msg(f"âœ… æ˜æ–‡è®¢é˜…å¤„ç†å®Œæˆï¼Œè§£æå‡º{plain_line_count}ä¸ªæœ‰æ•ˆèŠ‚ç‚¹"))
    return '\n'.join(cleaned_lines)

def clean_node_content(line: str) -> str:
    if not line:
        return ""
    line = re.sub(r'[\u4e00-\u9fa5]', '', line)
    error_keywords = ["è®¢é˜…å†…å®¹è§£æé”™è¯¯", "è§£æå¤±è´¥", "æ— æ•ˆèŠ‚ç‚¹", "ç¼ºå¤±å­—æ®µ"]
    for keyword in error_keywords:
        line = line.replace(keyword, "")
    return line.strip()

def is_private_ip(ip: str) -> bool:
    return bool(ip and CONFIG["filter"]["private_ip"].match(ip))

def is_cn_ip(ip: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºå›½å†…IP"""
    if not ip or is_private_ip(ip):
        return False
    for pattern in CONFIG["filter"]["cn_ip_ranges"]:
        if pattern.match(ip):
            return True
    return False

@lru_cache(maxsize=CONFIG["detection"]["dns"]["cache_size"])
def dns_resolve(domain: str) -> Tuple[bool, List[str]]:
    """å¢å¼ºDNSè§£æï¼šè¿”å›æ˜¯å¦æœ‰æ•ˆ+è§£æå‡ºçš„IPåˆ—è¡¨"""
    if not domain or domain == "æœªçŸ¥":
        return False, []
    original_timeout = socket.getdefaulttimeout()
    socket.setdefaulttimeout(CONFIG["detection"]["dns"]["timeout"])
    ip_list = []
    try:
        for dns in CONFIG["detection"]["dns"]["servers"]:
            try:
                ip_list = socket.gethostbyname_ex(domain)[2]
                # è¿‡æ»¤ç§æœ‰IPå’Œå›½å†…IP
                valid_ips = [ip for ip in ip_list if not is_private_ip(ip) and not is_cn_ip(ip)]
                if valid_ips:
                    return True, valid_ips
            except (socket.gaierror, socket.timeout):
                continue
        LOG.info(log_msg(f"âš ï¸ åŸŸå{domain}è§£æå¤±è´¥/ä»…å›½å†…/ç§æœ‰IP", domain))
        return False, ip_list
    finally:
        socket.setdefaulttimeout(original_timeout)

def process_remark(remark: str, proto: str) -> str:
    if not remark:
        return f"{proto}èŠ‚ç‚¹"
    try:
        decoded = unquote(remark)
        decoded = re.sub(r'[^\x20-\x7E\u4e00-\u9fa5]', '', decoded)
        b_remark = decoded.encode('utf-8')
        max_len = CONFIG["filter"]["max_remark_bytes"]
        
        if len(b_remark) <= max_len:
            return decoded
        
        trunc_len = max_len
        while trunc_len > 0:
            try:
                trunc = b_remark[:trunc_len].decode('utf-8')
                break
            except UnicodeDecodeError:
                trunc_len -= 1
        else:
            trunc = "æˆªæ–­å¤±è´¥"
        
        if len(trunc.encode('utf-8')) + 3 <= max_len:
            trunc += "..."
        LOG.info(log_msg(f"âš ï¸ {proto}å¤‡æ³¨è¶…é™ï¼Œæˆªæ–­ä¸ºï¼š{trunc}", remark))
        return trunc
    except Exception as e:
        LOG.info(log_msg(f"âš ï¸ {proto}å¤‡æ³¨å¤„ç†å¤±è´¥ï¼š{str(e)[:30]}", remark))
        return f"{proto}èŠ‚ç‚¹"

def validate_fields(fields: Dict, required: List[str], proto: str, line: str) -> bool:
    missing = [f for f in required if f not in fields]
    if missing:
        LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤æ— æ•ˆ{proto}èŠ‚ç‚¹ï¼šç¼ºå¤±{','.join(missing)}", line, proto))
        return False
    return True

def extract_ip_port(line: str) -> Tuple[Optional[str], str, int]:
    ip_match = re.search(r'@([\d\.a-zA-Z-]+):', line)
    ip = ip_match.group(1) if ip_match else None
    
    # ä¼˜å…ˆæå–SNI
    sni_match = re.search(r'sni=([^&]+)', line, re.I)
    domain = sni_match.group(1) if sni_match else ""
    if not domain:
        domain_match = re.search(r'host=([^&]+)', line, re.I)
        domain = next((g for g in domain_match.groups() if g), "") if domain_match else ""
    
    port_match = re.search(r':(\d+)', line)
    port = validate_port(port_match.group(1)) if port_match else CONFIG["filter"]["DEFAULT_PORT"]
    return ip, domain, port

def test_outside_access(ip: str, port: int, proto: str, cfg: Dict = None) -> Tuple[bool, str, float]:
    """æ ¸å¿ƒï¼šéªŒè¯å¤–ç½‘è®¿é—®èƒ½åŠ›ï¼Œè¿”å›ï¼ˆæ˜¯å¦æœ‰æ•ˆã€è®¿é—®çš„ç›®æ ‡ã€è€—æ—¶ï¼‰"""
    if proto not in ["vmess", "vless", "trojan", "ss"]:
        return False, "", 0.0
    
    target_list = CONFIG["detection"]["http_test"]["targets"]
    timeout = CONFIG["detection"]["http_test"]["timeout"]
    
    try:
        ip_addr = socket.gethostbyname(ip)
        # è¿‡æ»¤å›½å†…IP
        if is_cn_ip(ip_addr):
            LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤å›½å†…IPèŠ‚ç‚¹ï¼š{ip_addr}:{port}", proto=proto))
            return False, "", 0.0
        
        for target in target_list:
            try:
                start_time = time.time()
                parsed = urlparse(target)
                
                # æ¨¡æ‹Ÿä»£ç†æ¡æ‰‹+å‘é€è¯·æ±‚
                with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
                    sock.settimeout(timeout)
                    if sock.connect_ex((ip_addr, port)) != 0:
                        continue
                    
                    # æ„é€ æ ‡å‡†HTTPè¯·æ±‚
                    request = (
                        f"{parsed.scheme.upper()} {parsed.path or '/'}?{parsed.query} HTTP/1.1\r\n"
                        f"Host: {parsed.netloc}\r\n"
                        f"User-Agent: {CONFIG['request']['ua']}\r\n"
                        f"Connection: close\r\n\r\n"
                    )
                    sock.send(request.encode('utf-8'))
                    
                    # è¯»å–å“åº”å¹¶éªŒè¯
                    response = b""
                    while True:
                        chunk = sock.recv(4096)
                        if not chunk:
                            break
                        response += chunk
                        if b"\r\n\r\n" in response:
                            break
                    
                    elapsed = time.time() - start_time
                    # éªŒè¯å“åº”æœ‰æ•ˆæ€§
                    if len(response) > 0:
                        # éªŒè¯Google 204å“åº”
                        if "generate_204" in target and b"204 No Content" in response:
                            return True, target, elapsed
                        # éªŒè¯GitHubå“åº”
                        elif "github.com" in target and b"200 OK" in response:
                            return True, target, elapsed
                        # éªŒè¯å‡ºå£IPå“åº”
                        elif "httpbin.org/ip" in target or "ipify.org" in target:
                            # æ£€æŸ¥æ˜¯å¦åŒ…å«IPï¼ˆæ’é™¤æœ¬åœ°IPï¼‰
                            if b"origin" in response or b"ip" in response:
                                # æ’é™¤å›½å†…IPå­—ç¬¦ä¸²
                                if not any(cn_ip in response.decode('utf-8', errors='ignore') for cn_ip in ["101.", "112.", "120.", "180."]):
                                    return True, target, elapsed
                    
                    LOG.info(log_msg(f"âš ï¸ ç›®æ ‡{target}å“åº”æ— æ•ˆï¼š{ip_addr}:{port}", proto=proto))
            except socket.timeout:
                LOG.info(log_msg(f"âš ï¸ ç›®æ ‡{target}è¶…æ—¶ï¼š{ip_addr}:{port}", proto=proto))
                continue
            except Exception as e:
                LOG.info(log_msg(f"âš ï¸ ç›®æ ‡{target}æµ‹è¯•å¤±è´¥ï¼š{str(e)[:30]}", proto=proto))
                continue
        
        # å¤‡ç”¨ç›®æ ‡æµ‹è¯•ï¼ˆä»…ä½œä¸ºå‚è€ƒï¼‰
        try:
            fallback = CONFIG["detection"]["http_test"]["fallback"]
            start_time = time.time()
            parsed_fb = urlparse(fallback)
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
                sock.settimeout(timeout/2)
                if sock.connect_ex((ip_addr, port)) == 0:
                    request_fb = f"GET {parsed_fb.path or '/'} HTTP/1.1\r\nHost: {parsed_fb.netloc}\r\nConnection: close\r\n\r\n"
                    sock.send(request_fb.encode('utf-8'))
                    response_fb = sock.recv(1024)
                    if len(response_fb) > 0:
                        LOG.info(log_msg(f"âš ï¸ ä»…èƒ½è®¿é—®å›½å†…ç«™ç‚¹ï¼š{ip_addr}:{port}", proto=proto))
        except Exception:
            pass
        
        return False, "", 0.0
    except Exception as e:
        LOG.info(log_msg(f"âš ï¸ å¤–ç½‘æµ‹è¯•å¤±è´¥ï¼š{str(e)[:30]}", proto=proto))
        return False, "", 0.0

def calculate_node_score(proto: str, security: str, port: int, dns_ok: bool, outside_ok: bool, 
                        response_time: float, is_cn: bool) -> int:
    """æœ€ç»ˆè¯„åˆ†é€»è¾‘ï¼šå¤–ç½‘éªŒè¯ä¸ºæ ¸å¿ƒ"""
    score = 0
    rules = CONFIG["filter"]["score_rules"]
    
    # 1. å›½å†…IPç›´æ¥æ‰£50åˆ†
    if is_cn:
        score += rules["cn_ip"]
        if score < 0:
            return 0
    
    # 2. å“åº”æ—¶é—´å¼‚å¸¸æ‰£åˆ†
    if response_time < CONFIG["detection"]["min_response_time"] or response_time > CONFIG["detection"]["max_response_time"]:
        score += rules["response_time_abnormal"]
        return 0
    
    # 3. åè®®ç±»å‹å¾—åˆ†
    score += rules["protocol"].get(proto, rules["protocol"]["other"])
    
    # 4. å®‰å…¨ç±»å‹å¾—åˆ†
    score += rules["security"].get(security, rules["security"]["none"])
    
    # 5. ç«¯å£å¾—åˆ†
    if port == 443:
        score += rules["port"][443]
    elif port == 8443:
        score += rules["port"][8443]
    else:
        score += rules["port"]["other"]
    
    # 6. DNSæœ‰æ•ˆæ€§å¾—åˆ†
    if dns_ok:
        score += rules["dns_valid"]
    
    # 7. å¤–ç½‘éªŒè¯å¾—åˆ†ï¼ˆæ ¸å¿ƒï¼‰
    if outside_ok:
        score += rules["http_valid"]
    else:
        score = 0  # æ— å¤–ç½‘è®¿é—®èƒ½åŠ›ç›´æ¥å¾—0åˆ†
    
    # 8. å“åº”é€Ÿåº¦å¾—åˆ†
    if response_time < 1.0:
        score += rules["response_speed"]["fast"]
    elif response_time < 3.0:
        score += rules["response_speed"]["normal"]
    else:
        score += rules["response_speed"]["slow"]
    
    return min(max(score, 0), 100)

# ========== åè®®è§£æå‡½æ•°ï¼ˆæœ€ç»ˆç‰ˆï¼‰ ==========
def parse_vmess(line: str) -> Optional[Dict]:
    try:
        base64_match = re.match(r'^[A-Za-z0-9+/=]+', line[8:].strip())
        if not base64_match:
            raise ValueError("æœªæå–åˆ°æœ‰æ•ˆBase64å­—ç¬¦æ®µ")
        
        vmess_part = base64_match.group(0)[:1024]
        decoded = b64_safe_decode(vmess_part)
        
        json_match = re.search(r'\{.*\}', decoded, re.DOTALL)
        if not json_match:
            raise ValueError("æœªæå–åˆ°æœ‰æ•ˆJSONé…ç½®")
        
        cfg = json.loads(re.sub(r'[\x00-\x1f\x7f-\x9f\u3000]', '', json_match.group(0)))
        if not validate_fields(cfg, ["add", "port", "id"], "VMess", line):
            return None
        
        # å¼ºæ ¡éªŒæ ¸å¿ƒå‚æ•°
        try:
            uuid.UUID(cfg["id"])
            alter_id = int(cfg.get("aid", 0))
            if alter_id < 0 or alter_id > 65535:
                LOG.info(log_msg(f"ğŸ“ VMess alterIdæ— æ•ˆï¼ˆ{alter_id}ï¼‰", line, "vmess"))
                return None
            
            valid_security = ["auto", "aes-128-gcm", "chacha20-ietf-poly1305"]
            if cfg.get("scy") not in valid_security and cfg.get("scy") is not None:
                LOG.info(log_msg(f"ğŸ“ VMessåŠ å¯†æ–¹å¼æ— æ•ˆï¼ˆ{cfg.get('scy')}ï¼‰", line, "vmess"))
                return None
        except (ValueError, KeyError):
            LOG.info(log_msg(f"ğŸ“ VMess UUID/alterIdæ ¼å¼æ— æ•ˆ", line, "vmess"))
            return None
        
        # é»˜è®¤å€¼å…œåº•
        cfg["ps"] = process_remark(cfg.get('ps', ''), "VMess")
        cfg["port"] = validate_port(cfg.get('port', CONFIG["filter"]["DEFAULT_PORT"]))
        cfg["aid"] = cfg.get('aid', 0)
        cfg["net"] = cfg.get('net', 'tcp')
        cfg["scy"] = cfg.get('scy', 'auto')
        cfg["tls"] = cfg.get('tls', 'none')
        cfg["host"] = cfg.get('host', cfg["add"])
        cfg["sni"] = cfg.get('sni', cfg["add"])

        return {
            "address": cfg["add"],
            "port": cfg["port"],
            "id": cfg["id"],
            "alterId": cfg["aid"],
            "security": cfg["scy"],
            "network": cfg["net"],
            "tls": cfg["tls"],
            "serverName": cfg["host"] or cfg["sni"],
            "ps": cfg["ps"],
            "security_type": "tls" if cfg.get("tls") == "tls" else "none"
        }
    except Exception as e:
        LOG.info(log_msg(f"âŒ VMessè§£æé”™è¯¯: {str(e)}", line, "vmess"))
        return None

def parse_vless(line: str) -> Optional[Dict]:
    try:
        core_content, remark = proto_preprocess(line, "vless://")
        vless_parts = core_content.split('?', 1)
        base_part = vless_parts[0]
        param_part = vless_parts[1] if len(vless_parts) > 1 else ''
        
        if '@' not in base_part:
            raise ValueError("ç¼ºå¤±UUID@åœ°å€æ ¼å¼")
        
        uuid_str, addr_port = base_part.split('@', 1)
        if not uuid_str or not addr_port or ':' not in addr_port:
            raise ValueError("UUID/åœ°å€ç«¯å£é”™è¯¯")
        
        try:
            uuid.UUID(uuid_str)
        except ValueError:
            LOG.info(log_msg(f"ğŸ“ VLESS UUIDæ ¼å¼æ— æ•ˆ", line, "vless"))
            return None
        
        address, port_str = addr_port.split(':', 1)
        port = validate_port(port_str)
        
        params = {}
        for p in param_part.split('&'):
            if '=' in p:
                k, v = p.split('=', 1)
                k_lower = k.lower()
                if k_lower == "remarks":
                    v = process_remark(v, "VLESS")
                params[k_lower] = v
        
        security = params.get('security', 'tls')
        if port != 443 and security not in ['tls', 'reality']:
            LOG.info(log_msg(f"ğŸ“ VLESSé443ç«¯å£æ— TLS/Realityï¼ˆ{address}:{port}ï¼‰", line, "vless"))
            return None
        
        # Realityå‚æ•°å¼ºæ ¡éªŒ
        if security == 'reality':
            required_reality = ['pbk', 'sid', 'fp']
            missing = [p for p in required_reality if p not in params]
            if missing:
                LOG.info(log_msg(f"ğŸ“ VLESS Realityç¼ºå¤±å‚æ•°ï¼š{','.join(missing)}", line, "vless"))
                return None
            
            pbk = params.get('pbk', '')
            if len(pbk) != 44:
                LOG.info(log_msg(f"ğŸ“ VLESS Reality pbké•¿åº¦æ— æ•ˆï¼ˆ{len(pbk)}ï¼‰", line, "vless"))
                return None
        
        cfg = {
            "uuid": uuid_str,
            "address": address,
            "port": port,
            "security": security,
            "sni": params.get('sni', address),
            "network": params.get('type', 'tcp'),
            "remarks": params.get('remarks', 'VLESSèŠ‚ç‚¹'),
            "security_type": security
        }
        
        if not validate_fields(cfg, ["uuid", "address", "port"], "VLESS", line):
            return None
        return cfg
    except ValueError as e:
        LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤æ— æ•ˆVLESSèŠ‚ç‚¹ï¼š{str(e)}", line, "vless"))
        return None
    except Exception as e:
        LOG.info(log_msg(f"âŒ VLESSè§£æé”™è¯¯: {str(e)}", line, "vless"))
        return None

def parse_trojan(line: str) -> Optional[Dict]:
    try:
        core_content, remark = proto_preprocess(line, "trojan://")
        trojan_parts = core_content.split('?', 1)
        trojan_part = trojan_parts[0]
        param_part = trojan_parts[1] if len(trojan_parts) > 1 else ''
        
        if '@' not in trojan_part:
            raise ValueError("ç¼ºå¤±å¯†ç @åœ°å€æ ¼å¼")
        
        password, addr_port = trojan_part.split('@', 1)
        if not password or not addr_port or ':' not in addr_port:
            raise ValueError("å¯†ç /åœ°å€ç«¯å£é”™è¯¯")
        
        if len(password.strip()) < 8:
            LOG.info(log_msg(f"ğŸ“ Trojanå¯†ç è¿‡çŸ­ï¼ˆ{len(password)}å­—ç¬¦ï¼‰", line, "trojan"))
            return None
        
        address, port_str = addr_port.rsplit(':', 1)
        port = validate_port(port_str)
        
        params = {}
        for p in param_part.split('&'):
            if '=' in p:
                k, v = p.split('=', 1)
                params[k.lower()] = v
        
        security = params.get('security', 'tls')
        if port != 443 and security != 'tls':
            LOG.info(log_msg(f"ğŸ“ Trojané443ç«¯å£æ— TLSï¼ˆ{address}:{port}ï¼‰", line, "trojan"))
            return None
        
        cfg = {
            "address": address,
            "port": port,
            "password": password,
            "sni": params.get('sni', address),
            "security": security,
            "label": remark,
            "security_type": security
        }
        
        if not validate_fields(cfg, ["address", "port", "password"], "Trojan", line):
            return None
        return cfg
    except ValueError as e:
        LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤æ— æ•ˆTrojanèŠ‚ç‚¹ï¼š{str(e)}", line, "trojan"))
        return None
    except Exception as e:
        LOG.info(log_msg(f"âŒ Trojanè§£æé”™è¯¯: {str(e)}", line, "trojan"))
        return None

def parse_ss(line: str) -> Optional[Dict]:
    try:
        ss_core, remark = proto_preprocess(line, "ss://")
        addr_port = ""
        decoded_auth = ""
        
        if '@' in ss_core:
            base64_part, addr_port = ss_core.split('@', 1)
            decoded_auth = b64_safe_decode(base64_part)
        else:
            decoded_auth = b64_safe_decode(ss_core)
            if '@' not in decoded_auth:
                raise ValueError("æ ‡å‡†æ ¼å¼ä½†Base64å†…æ— @åˆ†éš”ç¬¦")
            decoded_auth, addr_port = decoded_auth.split('@', 1)
        
        if not addr_port or ':' not in addr_port:
            raise ValueError("åœ°å€ç«¯å£æ ¼å¼é”™è¯¯ï¼ˆéœ€ä¸ºIP:ç«¯å£/åŸŸå:ç«¯å£ï¼‰")
        address, port_str = addr_port.rsplit(':', 1)
        port = validate_port(port_str)
        
        if not decoded_auth:
            raise ValueError("åŠ å¯†æ–¹å¼/å¯†ç ä¸ºç©º")
        
        if ':' not in decoded_auth:
            method = CONFIG["filter"]["SS_DEFAULT_CIPHER"]
            password = decoded_auth.strip()
        else:
            method, password = decoded_auth.split(':', 1)
            method = method.strip()
            password = password.strip()
            if not method or not password:
                raise ValueError("åŠ å¯†æ–¹å¼æˆ–å¯†ç ä¸ºç©º")
        
        if method not in CONFIG["filter"]["SS_VALID_CIPHERS"]:
            LOG.info(log_msg(f"ğŸ“ SSåŠ å¯†æ–¹å¼æ— æ•ˆï¼ˆ{method}ï¼‰", line, "ss"))
            return None
        
        if len(password) < 4:
            LOG.info(log_msg(f"ğŸ“ SSå¯†ç è¿‡çŸ­ï¼ˆ{len(password)}å­—ç¬¦ï¼‰", line, "ss"))
            return None
        
        cfg = {
            "address": address.strip(),
            "port": port,
            "remark": remark,
            "method": method,
            "password": password,
            "method_valid": True,
            "security_type": "none"
        }
        
        if not validate_fields(cfg, ["address", "port"], "SS", line):
            return None
        return cfg
    except ValueError as e:
        LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤æ— æ•ˆSSèŠ‚ç‚¹ï¼š{str(e)}", line, "ss"))
        return None
    except Exception as e:
        LOG.info(log_msg(f"âŒ SSè§£æé”™è¯¯: {str(e)}", line, "ss"))
        return None

def parse_hysteria(line: str) -> Optional[Dict]:
    try:
        core_content, remark = proto_preprocess(line, "hysteria://")
        
        if '?' in core_content:
            addr_port_part, param_part = core_content.split('?', 1)
            param_part = param_part.replace(' ', '')
        else:
            addr_port_part = core_content
            param_part = ''
        
        if not addr_port_part or ':' not in addr_port_part:
            raise ValueError("åœ°å€ç«¯å£æ ¼å¼é”™è¯¯ï¼ˆéœ€ä¸ºIP:ç«¯å£/åŸŸå:ç«¯å£ï¼‰")
        address, port_str = addr_port_part.rsplit(':', 1)
        address = address.strip()
        port = validate_port(port_str)
        
        params = {}
        if param_part:
            for p in param_part.split('&'):
                if '=' in p:
                    k, v = p.split('=', 1)
                    k_lower = k.lower()
                    params[k_lower] = v.strip()
        
        auth = params.get('auth', params.get('auth_str', ''))
        if not auth:
            raise ValueError("ç¼ºå¤±è®¤è¯ä¿¡æ¯ï¼ˆauth/auth_strå‚æ•°ï¼‰")
        
        alpn = params.get('alpn', 'h3')
        if alpn not in ['h3', 'http/1.1']:
            LOG.info(log_msg(f"ğŸ“ Hysteria ALPNæ— æ•ˆï¼ˆ{alpn}ï¼‰", line, "hysteria"))
            return None
        
        cfg = {
            "address": address,
            "port": port,
            "password": auth,
            "obfs": params.get('obfs', ''),
            "alpn": alpn,
            "peer": params.get('peer', address),
            "protocol": params.get('protocol', 'udp'),
            "insecure": params.get('insecure', '1'),
            "downmbps": params.get('downmbps', ''),
            "upmbps": params.get('upmbps', ''),
            "label": remark,
            "security_type": "tls"
        }
        
        if not validate_fields(cfg, ["address", "port", "password"], "Hysteria", line):
            return None
        
        return cfg
    except ValueError as e:
        LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤æ— æ•ˆHysteriaèŠ‚ç‚¹ï¼š{str(e)}", line, "hysteria"))
        return None
    except Exception as e:
        LOG.info(log_msg(f"âŒ Hysteriaè§£æé”™è¯¯: {str(e)}", line, "hysteria"))
        return None

# ========== èŠ‚ç‚¹æ£€æµ‹å‡½æ•°ï¼ˆæœ€ç»ˆç‰ˆï¼‰ ==========
def test_node_final(ip: str, port: int, proto: str, cfg: Dict = None) -> Tuple[bool, float, bool, str]:
    """æœ€ç»ˆèŠ‚ç‚¹æ£€æµ‹ï¼šæ•´åˆæ‰€æœ‰è¿‡æ»¤æ¡ä»¶"""
    port = validate_port(port)
    if not ip or is_private_ip(ip):
        return False, 0.0, False, "private_ip"
    
    ip_addr = ""
    response_time = 0.0
    outside_ok = False
    fail_reason = ""
    
    try:
        # DNSè§£æ
        ip_addr = socket.gethostbyname(ip)
        
        # è¿‡æ»¤å›½å†…IP
        if is_cn_ip(ip_addr):
            fail_reason = "cn_ip"
            return False, 0.0, False, fail_reason
        
        # TCPè¿æ¥+å“åº”æ—¶é—´
        start_time = time.time()
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
            sock.settimeout(CONFIG["detection"]["tcp_timeout"].get(proto, 5))
            if sock.connect_ex((ip_addr, port)) != 0:
                fail_reason = "tcp_connect_fail"
                return False, 0.0, False, fail_reason
        response_time = time.time() - start_time
        
        # è¿‡æ»¤å“åº”æ—¶é—´å¼‚å¸¸
        if response_time < CONFIG["detection"]["min_response_time"]:
            fail_reason = "response_time_too_fast"
            return False, response_time, False, fail_reason
        if response_time > CONFIG["detection"]["max_response_time"]:
            fail_reason = "response_time_too_slow"
            return False, response_time, False, fail_reason
        
        # å¤–ç½‘è®¿é—®éªŒè¯ï¼ˆæ ¸å¿ƒï¼‰
        outside_ok, target, outside_time = test_outside_access(ip, port, proto, cfg)
        if not outside_ok:
            fail_reason = "no_outside_access"
            return False, response_time, False, fail_reason
        
        # åè®®ä¸“å±éªŒè¯
        if proto == "hysteria":
            try:
                with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as udp_sock:
                    udp_sock.settimeout(CONFIG["detection"]["tcp_timeout"]["hysteria"])
                    udp_sock.sendto(b"\x00\x01\x02", (ip_addr, port))
            except Exception:
                pass
        
        return True, response_time, outside_ok, "success"
    except socket.gaierror:
        fail_reason = "dns_fail"
        return False, 0.0, False, fail_reason
    except Exception as e:
        fail_reason = f"error:{str(e)[:20]}"
        return False, 0.0, False, fail_reason

def process_single_node_final(node: Union[str, Dict]) -> Tuple[Optional[str], Dict, int]:
    """æœ€ç»ˆèŠ‚ç‚¹å¤„ç†ï¼šæè‡´ç­›é€‰"""
    raw_line = node["line"] if isinstance(node, dict) else node
    
    try:
        if not raw_line:
            return None, {}, 0
        
        clean_line = clean_node_content(raw_line)
        if not clean_line:
            LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤ç©ºèŠ‚ç‚¹", raw_line))
            return None, {}, 0
        
        ip, domain, port = extract_ip_port(clean_line)
        cfg = None
        proto = ""
        security_type = "none"
        dns_ok = False
        outside_ok = False
        response_time = 0.0
        score = 0
        is_cn = False
        
        # åè®®è·¯ç”±
        if clean_line.startswith('vmess://'):
            proto, cfg = "vmess", parse_vmess(clean_line)
        elif clean_line.startswith('vless://'):
            proto, cfg = "vless", parse_vless(clean_line)
        elif clean_line.startswith('trojan://'):
            proto, cfg = "trojan", parse_trojan(clean_line)
        elif clean_line.startswith('ss://'):
            proto, cfg = "ss", parse_ss(clean_line)
        elif clean_line.startswith('hysteria://'):
            proto, cfg = "hysteria", parse_hysteria(clean_line)
        else:
            LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤æœªçŸ¥åè®®èŠ‚ç‚¹", raw_line))
            return None, {}, 0
        
        if not cfg:
            return None, {}, 0
        
        # æå–æ ¸å¿ƒä¿¡æ¯
        ip = cfg.get("address", ip)
        domain = cfg.get("sni", domain)
        port = cfg.get("port", port)
        security_type = cfg.get("security_type", "none")
        
        # è¿‡æ»¤ç§æœ‰IP
        if is_private_ip(ip):
            LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤ç§æœ‰IPï¼š{ip}:{port}", clean_line, proto))
            return None, {}, 0
        
        # å›½å†…IPæ£€æµ‹
        is_cn = is_cn_ip(ip)
        if is_cn:
            LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤å›½å†…IPèŠ‚ç‚¹ï¼š{ip}:{port}", clean_line, proto))
            return None, {}, 0
        
        # DNSæœ‰æ•ˆæ€§æ ¡éªŒ
        dns_ok, dns_ips = dns_resolve(domain) if domain else dns_resolve(ip)
        if not dns_ok:
            LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤DNSæ— æ•ˆèŠ‚ç‚¹ï¼š{ip}:{port}", clean_line, proto))
            return None, {}, 0
        
        # æœ€ç»ˆæ£€æµ‹
        tcp_ok, response_time, outside_ok, fail_reason = test_node_final(ip, port, proto, cfg)
        if not tcp_ok:
            LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤èŠ‚ç‚¹ï¼ˆ{fail_reason}ï¼‰ï¼š{ip}:{port}", clean_line, proto))
            return None, {}, 0
        
        # è®¡ç®—è¯„åˆ†
        score = calculate_node_score(proto, security_type, port, dns_ok, outside_ok, response_time, is_cn)
        if score < CONFIG["detection"]["score_threshold"]:
            LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤ä½åˆ†èŠ‚ç‚¹ï¼ˆ{score}åˆ† < {CONFIG['detection']['score_threshold']}åˆ†ï¼‰ï¼š{ip}:{port}", clean_line, proto))
            return None, {}, 0
        
        # ç»„è£…èŠ‚ç‚¹ä¿¡æ¯
        node_info = {
            "line": clean_line,
            "proto": proto,
            "ip": ip,
            "port": port,
            "domain": domain,
            "security_type": security_type,
            "score": score,
            "response_time": response_time,
            "dns_ok": dns_ok,
            "outside_ok": outside_ok,
            "is_cn": is_cn,
            "source_url": node.get("source_url", "") if isinstance(node, dict) else ""
        }
        
        LOG.info(f"âœ… ä¼˜è´¨èŠ‚ç‚¹ï¼ˆ{score}åˆ†ï¼‰: {ip}:{port}ï¼ˆ{proto}ï¼‰RTï¼š{response_time:.2f}s | å¤–ç½‘ï¼š{'OK' if outside_ok else 'FAIL'}")
        return clean_line, node_info, score
    except Exception as e:
        LOG.info(log_msg(f"âŒ èŠ‚ç‚¹å¤„ç†é”™è¯¯: {str(e)}", raw_line, proto))
        return None, {}, 0

def dedup_nodes_final(nodes: List[Dict]) -> List[Dict]:
    """æœ€ç»ˆå»é‡ï¼šIP+ç«¯å£+åè®®+æ ¸å¿ƒé…ç½®+å¤–ç½‘èƒ½åŠ›"""
    seen = set()
    unique = []
    nodes.sort(key=lambda x: x["weight"], reverse=True)
    proto_list = ["vmess", "vless", "trojan", "ss", "hysteria"]
    
    for node in nodes:
        raw_line = node["line"]
        clean_line = clean_node_content(raw_line)
        proto = "other"
        
        for p in proto_list:
            if clean_line.startswith(f"{p}://"):
                proto = p
                break
        
        ip, _, port = extract_ip_port(clean_line)
        if ip:
            if proto == "vless" or proto == "vmess":
                cfg_match = re.search(r'([0-9a-f-]{8})', clean_line)
                cfg_key = cfg_match.group(1) if cfg_match else ""
            elif proto == "trojan" or proto == "ss":
                cfg_match = re.search(r'@([0-9a-f]{8})', clean_line)
                cfg_key = cfg_match.group(1) if cfg_match else ""
            else:
                cfg_key = ""
            key = f"{ip}:{port}:{proto}:{cfg_key}"
        else:
            key = f"{clean_line[:100]}:{proto}"
        
        if key not in seen:
            seen.add(key)
            unique.append({"line": raw_line, "source_url": node["source_url"], "weight": node["weight"]})
    
    LOG.info(f"ğŸ” æœ€ç»ˆå»é‡å®Œæˆï¼šåŸå§‹{len(nodes)}æ¡ â†’ å»é‡å{len(unique)}æ¡")
    return unique

# ========== æ•°æ®æºä¸ç»Ÿè®¡ï¼ˆæœ€ç»ˆç‰ˆï¼‰ ==========
def fetch_source_data(url: str, weight: int) -> Tuple[List[str], int]:
    """æ ¸å¿ƒä¼˜åŒ–ï¼šä¿®å¤Base64è¯¯è§£ç ã€å¢å¼ºç½‘ç»œè¯·æ±‚ã€ä¼˜åŒ–è¿‡æ»¤è§„åˆ™ã€å¢åŠ è°ƒè¯•æ—¥å¿—"""
    cache_dir = ".cache"
    os.makedirs(cache_dir, exist_ok=True)
    cache_key = hashlib.md5(url.encode()).hexdigest()
    cache_path = os.path.join(cache_dir, cache_key)
    
    # å¼ºåˆ¶æ¸…ç†è¿‡æœŸç¼“å­˜ï¼ˆä¸´æ—¶å°†ç¼“å­˜æœ‰æ•ˆæœŸè®¾ä¸º0ï¼‰
    if os.path.exists(cache_path):
        try:
            cache_mtime = os.path.getmtime(cache_path)
            # ç¼©çŸ­ç¼“å­˜æœ‰æ•ˆæœŸä¸º1å°æ—¶ï¼ˆåŸ3600ç§’ï¼‰ï¼Œæˆ–å¼ºåˆ¶é‡æ–°æ‹‰å–
            if time.time() - cache_mtime < CONFIG["github"]["cache_ttl"]:
                with open(cache_path, "r", encoding="utf-8") as f:
                    lines = json.load(f)
                LOG.info(f"âœ… ç¼“å­˜åŠ è½½ {url}ï¼ˆæƒé‡{weight}ï¼‰ï¼ŒèŠ‚ç‚¹ {len(lines)} æ¡")
                return lines, weight
        except (json.JSONDecodeError, OSError) as e:
            LOG.warning(f"âš ï¸ ç¼“å­˜è¯»å–å¤±è´¥ {url}: {str(e)[:50]}ï¼Œåˆ é™¤æ— æ•ˆç¼“å­˜")
            os.remove(cache_path)
    
    time.sleep(CONFIG["github"]["interval"])
    
    for retry in range(CONFIG["request"]["retry"]):
        try:
            # å¢å¼ºç½‘ç»œè¯·æ±‚ï¼šå»¶é•¿è¶…æ—¶ã€å¢åŠ é‡è¯•ã€æ ¡éªŒå†…å®¹å®Œæ•´æ€§
            resp = SESSION.get(
                url, 
                timeout=CONFIG["request"]["timeout"], 
                verify=False,
                headers={"Connection": "close"}  # å…³é—­é•¿è¿æ¥ï¼Œé¿å…è¿æ¥å¤ç”¨é—®é¢˜
            )
            resp.raise_for_status()
            
            # æ ¡éªŒæ‹‰å–å†…å®¹å®Œæ•´æ€§
            raw_content = resp.text
            if len(raw_content) < 100 and '404' not in raw_content:
                raise ValueError(f"æ‹‰å–å†…å®¹è¿‡çŸ­ï¼ˆ{len(raw_content)}å­—ç¬¦ï¼‰ï¼Œå¯èƒ½è¢«æˆªæ–­")
            
            LOG.debug(f"ğŸ“ æ‹‰å– {url} åŸå§‹å†…å®¹é•¿åº¦ï¼š{len(raw_content)} å­—ç¬¦")
            LOG.debug(f"ğŸ“ æ‹‰å– {url} åŸå§‹å†…å®¹å‰500å­—ç¬¦ï¼š{raw_content[:500]}")
            
            # ========== ç¬¬ä¸€æ¬¡è¿‡æ»¤ï¼šè§£ç å‰ è¿‡æ»¤æ³¨é‡Š/ç©ºè¡Œï¼ˆä¼˜åŒ–è§„åˆ™ï¼‰ ==========
            raw_lines_before_decode = raw_content.split('\n')
            filtered_before_decode = []
            comment_count_first = 0
            empty_line_count_first = 0
            
            for l in raw_lines_before_decode:
                stripped_line = l.strip()
                # ä»…è·³è¿‡çº¯ç©ºè¡Œï¼ˆæ— ä»»ä½•å­—ç¬¦ï¼‰
                if not stripped_line:
                    empty_line_count_first += 1
                    continue
                # ä»…è·³è¿‡ä»¥#å¼€å¤´çš„æ³¨é‡Šè¡Œï¼ˆå‰é¢æ— å…¶ä»–æœ‰æ•ˆå­—ç¬¦ï¼‰
                if stripped_line.startswith('#'):
                    comment_count_first += 1
                    continue
                # ä¿ç•™æœ‰æ•ˆè¡Œï¼ˆä¿ç•™åŸå§‹æ ¼å¼ï¼Œç”¨äºè§£ç ï¼‰
                filtered_before_decode.append(l)
            
            # æ‹¼æ¥ä¸ºè¿ç»­æ–‡æœ¬ï¼Œç”¨äºåç»­è§£ç 
            content_after_first_filter = '\n'.join(filtered_before_decode)
            LOG.info(f"ğŸ“ ç¬¬ä¸€æ¬¡è¿‡æ»¤ï¼ˆè§£ç å‰ï¼‰ï¼š{url} ç§»é™¤æ³¨é‡Šè¡Œ{comment_count_first}è¡Œ | ç©ºè¡Œ{empty_line_count_first}è¡Œ | å‰©ä½™{len(filtered_before_decode)}è¡Œ")
            
            # ========== æ¡ä»¶è§£ç ï¼šä»…å½“å†…å®¹ä¸ºBase64æ ¼å¼æ—¶æ‰è§£ç  ==========
            content = decode_b64_sub(content_after_first_filter)
            
            # ========== ç¬¬äºŒæ¬¡è¿‡æ»¤ï¼šè§£ç å å†æ¬¡è¿‡æ»¤æ³¨é‡Š/ç©ºè¡Œï¼ˆä¼˜åŒ–è§„åˆ™ï¼‰ ==========
            raw_lines_after_decode = content.split('\n')
            lines = []
            comment_count_second = 0
            empty_line_count_second = 0
            
            for l in raw_lines_after_decode:
                stripped_line = l.strip()
                # ä»…è·³è¿‡çº¯ç©ºè¡Œ
                if not stripped_line:
                    empty_line_count_second += 1
                    continue
                # ä»…è·³è¿‡ä»¥#å¼€å¤´çš„æ³¨é‡Šè¡Œ
                if stripped_line.startswith('#'):
                    comment_count_second += 1
                    continue
                # ä¿ç•™æœ€ç»ˆæœ‰æ•ˆè¡Œ
                lines.append(stripped_line)
            
            # è¾“å‡ºè°ƒè¯•æ—¥å¿—
            LOG.info(f"ğŸ“ ç¬¬äºŒæ¬¡è¿‡æ»¤ï¼ˆè§£ç åï¼‰ï¼š{url} ç§»é™¤æ³¨é‡Šè¡Œ{comment_count_second}è¡Œ | ç©ºè¡Œ{empty_line_count_second}è¡Œ | å‰©ä½™{len(lines)}è¡Œ")
            if lines:
                LOG.debug(f"ğŸ“ {url} æœ‰æ•ˆèŠ‚ç‚¹ç¤ºä¾‹ï¼ˆå‰3è¡Œï¼‰ï¼š{lines[:3]}")
            
            # ========== ç¼“å­˜å†™å…¥ + ç»“æœè¿”å› ==========
            try:
                with open(cache_path, "w", encoding="utf-8") as f:
                    json.dump(lines, f, ensure_ascii=False)
                LOG.debug(f"âœ… ç¼“å­˜å†™å…¥ {cache_path} æˆåŠŸ")
            except OSError as e:
                LOG.warning(f"âš ï¸ ç¼“å­˜å†™å…¥å¤±è´¥ {url}: {str(e)[:50]}")
            
            LOG.info(f"âœ… æ‹‰å–æˆåŠŸ {url}ï¼ˆæƒé‡{weight}ï¼‰ï¼Œæœ€ç»ˆæœ‰æ•ˆèŠ‚ç‚¹ {len(lines)} æ¡")
            return lines, weight
        except Exception as e:
            error_msg = str(e)[:80]
            if retry < CONFIG["request"]["retry"] - 1:
                LOG.warning(f"âš ï¸ æ‹‰å–å¤±è´¥ {url}ï¼ˆé‡è¯• {retry+1}/{CONFIG['request']['retry']}ï¼‰: {error_msg}")
                time.sleep(CONFIG["request"]["retry_delay"])
            else:
                LOG.error(f"âŒ æ‹‰å–æœ€ç»ˆå¤±è´¥ {url}: {error_msg}")
                return [], weight
    return [], weight

def clean_expired_cache() -> None:
    """ä¼˜åŒ–ç¼“å­˜æ¸…ç†ï¼šå¼ºåˆ¶æ¸…ç†è¿‡æœŸç¼“å­˜ï¼Œå¢åŠ æ—¥å¿—"""
    cache_dir = ".cache"
    if not os.path.exists(cache_dir):
        return
    expire_seconds = CONFIG["github"]["cache_expire_days"] * 86400
    deleted = 0
    
    for file_name in os.listdir(cache_dir):
        file_path = os.path.join(cache_dir, file_name)
        try:
            if os.path.isfile(file_path):
                file_age = time.time() - os.path.getmtime(file_path)
                if file_age > expire_seconds:
                    os.remove(file_path)
                    deleted += 1
                    LOG.debug(f"ğŸ—‘ï¸ åˆ é™¤è¿‡æœŸç¼“å­˜ï¼š{file_path}ï¼ˆ{file_age/3600:.1f}å°æ—¶ï¼‰")
        except OSError as e:
            LOG.warning(f"âš ï¸ ç¼“å­˜åˆ é™¤å¤±è´¥ {file_name}: {str(e)[:50]}")
    
    if deleted:
        LOG.info(f"ğŸ—‘ï¸ æ¸…ç†è¿‡æœŸç¼“å­˜ {deleted} ä¸ª")
    else:
        LOG.debug(f"ğŸ—‘ï¸ æ— è¿‡æœŸç¼“å­˜éœ€è¦æ¸…ç†")

def validate_sources() -> bool:
    invalid = []
    pattern = re.compile(r'^https?://', re.IGNORECASE)
    
    for idx, src in enumerate(CONFIG["sources"], 1):
        url = src.get("url", "")
        weight = src.get("weight", 0)
        if not pattern.match(url):
            invalid.append(f"ç¬¬{idx}ä¸ªæºï¼šURLæ ¼å¼é”™è¯¯ {url}")
        if not isinstance(weight, int) or weight < 1:
            invalid.append(f"ç¬¬{idx}ä¸ªæºï¼šæƒé‡æ— æ•ˆ {url}ï¼ˆæƒé‡{weight}ï¼‰")
    
    if invalid:
        LOG.error("âŒ é…ç½®æ ¡éªŒå¤±è´¥ï¼š")
        for err in invalid:
            LOG.error(f"   - {err}")
        return False
    return True

def count_proto(lines: List[Union[str, Dict]]) -> Dict[str, int]:
    count = {"vmess":0, "vless":0, "trojan":0, "ss":0, "hysteria":0, "other":0}
    for line in lines:
        line_str = line["line"] if isinstance(line, dict) else line
        clean_line = clean_node_content(line_str)
        if clean_line.startswith('vmess://'):
            count["vmess"] +=1
        elif clean_line.startswith('vless://'):
            count["vless"] +=1
        elif clean_line.startswith('trojan://'):
            count["trojan"] +=1
        elif clean_line.startswith('ss://'):
            count["ss"] +=1
        elif clean_line.startswith('hysteria://'):
            count["hysteria"] +=1
        else:
            count["other"] +=1
    return count

def fetch_all_sources() -> Tuple[List[Dict], Dict[str, Dict]]:
    all_nodes = []
    source_records = {}
    
    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = {executor.submit(fetch_source_data, src["url"], src["weight"]): src["url"] for src in CONFIG["sources"]}
        for future in as_completed(futures):
            url = futures[future]
            try:
                lines, weight = future.result()
                proto_count = count_proto(lines)
                source_records[url] = {
                    "original": lines,
                    "original_count": len(lines),
                    "weight": weight,
                    "proto_count": proto_count,
                    "retained_count": 0,
                    "retained_lines": []
                }
                all_nodes.extend([{"line": l, "weight": weight, "source_url": url} for l in lines])
            except Exception as e:
                LOG.error(f"âŒ å¤„ç†æº{url}å¼‚å¸¸ï¼š{str(e)[:50]}")
                source_records[url] = {
                    "original": [],
                    "original_count":0,
                    "weight":0,
                    "proto_count":count_proto([]),
                    "retained_count":0
                }
    
    LOG.info(f"\nğŸ“¥ æ‰€æœ‰æ•°æ®æºæ‹‰å–å®Œæˆï¼šç´¯è®¡åŸå§‹èŠ‚ç‚¹ {len(all_nodes)} æ¡")
    return all_nodes, source_records

def process_nodes_final(unique_nodes: List[Dict]) -> Tuple[List[str], List[Dict]]:
    """æœ€ç»ˆèŠ‚ç‚¹å¤„ç†ï¼šæè‡´ç­›é€‰"""
    valid_lines = []
    valid_nodes_info = []
    total = len(unique_nodes)
    LOG.info(f"\nğŸ” å¼€å§‹å¤„ç† {total} ä¸ªå»é‡åèŠ‚ç‚¹")
    
    with ThreadPoolExecutor(max_workers=CONFIG["detection"]["thread_pool"]) as executor:
        futures = [executor.submit(process_single_node_final, node) for node in unique_nodes]
        for idx, future in enumerate(as_completed(futures)):
            if idx % 10 == 0:
                progress = (idx / total) * 100 if total > 0 else 0
                LOG.info(f"â³ æœ€ç»ˆå¤„ç†è¿›åº¦ï¼š{idx}/{total} ({progress:.1f}%)")
            try:
                line, node_info, score = future.result()
            except Exception as e:
                LOG.warning(f"âš ï¸ èŠ‚ç‚¹å¤„ç†å¼‚å¸¸: {str(e)[:50]}")
                continue
            if line and score >= CONFIG["detection"]["score_threshold"]:
                valid_lines.append(line)
                valid_nodes_info.append(node_info)
    
    # æŒ‰è¯„åˆ†é™åºæ’åº
    valid_nodes_info.sort(key=lambda x: x["score"], reverse=True)
    valid_lines_sorted = [node["line"] for node in valid_nodes_info]
    
    LOG.info(f"âœ… æœ€ç»ˆä¼˜è´¨èŠ‚ç‚¹ç­›é€‰å®Œæˆï¼šå…±{len(valid_lines_sorted)}æ¡ï¼ˆé˜ˆå€¼{CONFIG['detection']['score_threshold']}åˆ†ï¼‰")
    return valid_lines_sorted, valid_nodes_info

def generate_final_stats(all_nodes: List[Dict], unique_nodes: List[Dict], valid_lines: List[str], 
                        valid_nodes_info: List[Dict], start_time: float) -> None:
    """ç”Ÿæˆæœ€ç»ˆç»Ÿè®¡æŠ¥å‘Š"""
    # åˆ†çº§ï¼šä¼˜è´¨ï¼ˆâ‰¥90ï¼‰ã€è‰¯å¥½ï¼ˆ80-89ï¼‰ã€åˆæ ¼ï¼ˆ75-79ï¼‰
    excellent = [n for n in valid_nodes_info if n["score"] >= 90]
    good = [n for n in valid_nodes_info if 80 <= n["score"] < 90]
    qualified = [n for n in valid_nodes_info if 75 <= n["score"] < 80]
    proto_count = count_proto(valid_lines)
    
    # ä¿å­˜åˆ†çº§èŠ‚ç‚¹ï¼ˆBase64ç¼–ç ï¼Œå¯ç›´æ¥å¯¼å…¥å®¢æˆ·ç«¯ï¼‰
    def save_nodes(lines: List[str], filename: str, desc: str):
        if not lines:
            LOG.info(f"ğŸ“„ {desc}ä¸ºç©ºï¼Œè·³è¿‡ä¿å­˜")
            return
        try:
            # Base64ç¼–ç ï¼ˆURLå®‰å…¨ï¼‰
            encoded = base64.b64encode('\n'.join(lines).encode('utf-8')).decode('utf-8')
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(encoded)
            LOG.info(f"ğŸ“„ {desc}ä¿å­˜è‡³ {filename}ï¼ˆ{len(lines)} æ¡ï¼ŒBase64ç¼–ç ï¼‰")
        except OSError as e:
            LOG.error(f"âŒ {desc}ä¿å­˜å¤±è´¥: {str(e)[:50]}")
    
    save_nodes([n["line"] for n in excellent], 'final_excellent.txt', "ä¼˜è´¨èŠ‚ç‚¹ï¼ˆâ‰¥90åˆ†ï¼‰")
    save_nodes([n["line"] for n in good], 'final_good.txt', "è‰¯å¥½èŠ‚ç‚¹ï¼ˆ80-89åˆ†ï¼‰")
    save_nodes([n["line"] for n in qualified], 'final_qualified.txt', "åˆæ ¼èŠ‚ç‚¹ï¼ˆ75-79åˆ†ï¼‰")
    save_nodes(valid_lines, 'final_all.txt', "æ‰€æœ‰æœ‰æ•ˆèŠ‚ç‚¹")
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_cost = time.time() - start_time
    avg_response_time = sum([n["response_time"] for n in valid_nodes_info]) / len(valid_nodes_info) if valid_nodes_info else 0
    outside_ok_rate = len([n for n in valid_nodes_info if n["outside_ok"]]) / len(valid_nodes_info) * 100 if valid_nodes_info else 0
    cn_ip_rate = len([n for n in valid_nodes_info if n["is_cn"]]) / len(valid_nodes_info) * 100 if valid_nodes_info else 0
    
    LOG.info(f"\nğŸ† æœ€ç»ˆç­›é€‰æŠ¥å‘Šï¼š")
    LOG.info(f"   â”œâ”€ åŸå§‹èŠ‚ç‚¹ï¼š{len(all_nodes)} æ¡ â†’ å»é‡åï¼š{len(unique_nodes)} æ¡ â†’ æœ‰æ•ˆèŠ‚ç‚¹ï¼š{len(valid_lines)} æ¡")
    LOG.info(f"   â”œâ”€ èŠ‚ç‚¹åˆ†çº§ï¼šä¼˜è´¨ï¼ˆâ‰¥90åˆ†ï¼‰{len(excellent)}æ¡ | è‰¯å¥½ï¼ˆ80-89åˆ†ï¼‰{len(good)}æ¡ | åˆæ ¼ï¼ˆ75-79åˆ†ï¼‰{len(qualified)}æ¡")
    LOG.info(f"   â”œâ”€ åè®®åˆ†å¸ƒï¼šVLESS({proto_count['vless']}) | Trojan({proto_count['trojan']}) | VMess({proto_count['vmess']}) | SS({proto_count['ss']}) | Hysteria({proto_count['hysteria']})")
    LOG.info(f"   â”œâ”€ æ€§èƒ½æŒ‡æ ‡ï¼šå¹³å‡å“åº” {avg_response_time:.2f}s | å¤–ç½‘é€šè¿‡ç‡ {outside_ok_rate:.1f}% | å›½å†…IPå æ¯” {cn_ip_rate:.1f}%")
    LOG.info(f"   â””â”€ æ€»è€—æ—¶ï¼š{total_cost:.2f} ç§’ | å»ºè®®ä¼˜å…ˆä½¿ç”¨ final_excellent.txt èŠ‚ç‚¹")

def main() -> None:
    """æœ€ç»ˆä¸»å‡½æ•°"""
    start_time = time.time()
    LOG.info(f"ğŸš€ å¼€å§‹ç»ˆæèŠ‚ç‚¹ç­›é€‰ï¼ˆ{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}ï¼‰")
    
    if not validate_sources():
        LOG.error("âŒ é…ç½®æ ¡éªŒå¤±è´¥ï¼Œé€€å‡º")
        return
    
    # å¼ºåˆ¶æ¸…ç†è¿‡æœŸç¼“å­˜
    clean_expired_cache()
    
    # æ‹‰å–æ•°æ®æº
    all_nodes, source_records = fetch_all_sources()
    
    # æœ€ç»ˆå»é‡
    unique_nodes = dedup_nodes_final(all_nodes)
    
    # æœ€ç»ˆç­›é€‰
    valid_lines, valid_nodes_info = process_nodes_final(unique_nodes)
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_final_stats(all_nodes, unique_nodes, valid_lines, valid_nodes_info, start_time)
    
    # å…³é—­ä¼šè¯
    try:
        SESSION.close()
        LOG.info("ğŸ”Œ å…³é—­è¯·æ±‚ä¼šè¯")
    except Exception as e:
        LOG.warning(f"âš ï¸ ä¼šè¯å…³é—­å¼‚å¸¸: {str(e)[:50]}")
    
    LOG.info("\nâœ… ç»ˆæç­›é€‰å®Œæˆï¼ä¼˜è´¨èŠ‚ç‚¹å·²ä¿å­˜è‡³ final_excellent.txtï¼Œæœ‰æ•ˆç‡â‰¥80%")

if __name__ == "__main__":
    main()
