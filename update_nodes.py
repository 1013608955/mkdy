import requests
import re
import socket
import base64
import binascii
import os
import time
import hashlib
import logging
from urllib.parse import unquote
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from functools import lru_cache
import urllib3
from typing import Dict, List, Tuple, Optional, Union
import json

# ========== é…ç½®ä¸åˆå§‹åŒ– ==========
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# æ ¸å¿ƒé…ç½®ï¼ˆç»Ÿä¸€é»˜è®¤å€¼ï¼Œåˆ é™¤æ— æ„ä¹‰å¸¸é‡åˆ«åï¼‰
CONFIG: Dict = {
    "sources": [
        {"url": "https://raw.githubusercontent.com/barry-far/V2ray-Config/main/Splitted-By-Protocol/vmess.txt", "weight": 5},
        {"url": "https://raw.githubusercontent.com/MatinGhanbari/v2ray-configs/main/subscriptions/v2ray/super-sub.txt", "weight": 5},
        {"url": "https://raw.githubusercontent.com/mfuu/v2ray/master/v2ray", "weight": 4},
        {"url": "https://raw.githubusercontent.com/ermaozi/get_subscribe/main/subscribe/v2ray.txt", "weight": 4},
        {"url": "https://raw.githubusercontent.com/free18/v2ray/refs/heads/main/v.txt", "weight": 3},
        {"url": "https://raw.githubusercontent.com/HakurouKen/free-node/main/public", "weight": 3},
        {"url": "https://raw.githubusercontent.com/Pawdroid/Free-servers/main/sub", "weight": 2}
    ],
    "request": {"timeout": 120, "retry": 2, "retry_delay": 2, "ua": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"},
    "github": {"token": os.getenv("GITHUB_TOKEN", ""), "interval": 0.5, "cache_ttl": 3600, "cache_expire_days": 7},
    "detection": {
        "tcp_timeout": {"vmess":4, "vless":4, "trojan":4, "ss":2, "hysteria":4},
        "tcp_retry": 1,
        "thread_pool": 8,
        "dns": {"servers": ["223.5.5.5", "119.29.29.29", "8.8.8.8", "1.1.1.1"], "timeout":5, "cache_size":1000}
    },
    "filter": {
        "private_ip": re.compile(r"^(192\.168\.|10\.|172\.(1[6-9]|2\d|3[0-1])\.|127\.|0\.0\.0\.0)"),
        "ports": range(1, 65535),
        "max_remark_bytes": 200,
        "DEFAULT_PORT": 443,  # ç»Ÿä¸€é»˜è®¤ç«¯å£
        "SS_DEFAULT_CIPHER": "aes-256-gcm"  # ç»Ÿä¸€SSé»˜è®¤åŠ å¯†æ–¹å¼
    }
}

# æ—¥å¿—åˆå§‹åŒ–
def init_logger() -> logging.Logger:
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)
    logger.propagate = False
    if not logger.handlers:
        fmt = logging.Formatter("%(asctime)s - %(message)s", "%Y-%m-%d %H:%M:%S")
        handler = logging.StreamHandler()
        handler.setFormatter(fmt)
        logger.addHandler(handler)
    return logger

LOG = init_logger()

# å…¨å±€è¯·æ±‚ä¼šè¯
def init_session() -> requests.Session:
    sess = requests.Session()
    headers = {"User-Agent": CONFIG["request"]["ua"], "Accept": "application/vnd.github.v3.raw+json"}
    if CONFIG["github"]["token"]:
        headers["Authorization"] = f"token {CONFIG['github']['token']}"
    sess.headers.update(headers)
    adapter = requests.adapters.HTTPAdapter(pool_connections=10, pool_maxsize=20, max_retries=3)
    sess.mount("https://", adapter)
    sess.mount("http://", adapter)
    return sess

SESSION = init_session()

# ========== é€šç”¨å·¥å…·å‡½æ•°ï¼ˆå¤ç”¨é‡å¤é€»è¾‘ï¼‰ ==========
def validate_port(port: Union[str, int]) -> int:
    """æ ¡éªŒå¹¶è¿”å›åˆæ³•ç«¯å£ï¼Œé»˜è®¤443"""
    try:
        p = int(port)
        return p if p in CONFIG["filter"]["ports"] else CONFIG["filter"]["DEFAULT_PORT"]
    except (ValueError, TypeError):
        return CONFIG["filter"]["DEFAULT_PORT"]

def log_msg(content: str, line: str = "", proto: str = "") -> str:
    """æ—¥å¿—æ ¼å¼åŒ–ï¼ˆä¿ç•™æ‰€æœ‰å›¾æ ‡è¾“å‡ºï¼‰"""
    if "ä¿ç•™èŠ‚ç‚¹" in content:
        line_part = ""
    else:
        if "è§£æé”™è¯¯" in content or "è¿‡æ»¤æ— æ•ˆ" in content or "ç©ºåœ°å€èŠ‚ç‚¹" in content:
            line_part = f"ï¼ˆ{line}ï¼‰" if line else ""
        else:
            safe_line = line[:20].encode('ascii', 'ignore').decode('ascii')
            line_part = f"ï¼ˆ{safe_line}...ï¼‰" if safe_line else ""
    proto_part = f"ï¼ˆ{proto}ï¼‰" if proto else ""
    return f"{content}{line_part}{proto_part}"

def b64_safe_decode(b64_str: str) -> str:
    """å®‰å…¨è§£ç Base64ï¼ˆè‡ªåŠ¨è¡¥å…¨å¡«å……ç¬¦ï¼Œå¤±è´¥è¿”å›åŸå­—ç¬¦ä¸²ï¼‰"""
    try:
        b64_str = b64_str.rstrip('=')
        b64_str += '=' * (4 - len(b64_str) % 4) if len(b64_str) % 4 != 0 else ''
        return base64.b64decode(b64_str).decode('utf-8', errors='ignore')
    except Exception:
        return b64_str

def clean_special_chars(line: str) -> str:
    """é€šç”¨å­—ç¬¦æ¸…æ´—ï¼šç§»é™¤ä¸å¯è§å­—ç¬¦ã€å…¨è§’@è½¬åŠè§’"""
    if not line:
        return ""
    clean_line = re.sub(r'[\u200b\u3000\s]+', '', line)
    clean_line = clean_line.replace('ï¼ ', '@')
    return clean_line

def proto_preprocess(line: str, proto_prefix: str) -> Tuple[str, str]:
    """é€šç”¨åè®®å‰ç½®å¤„ç†ï¼šæ¸…æ´—å­—ç¬¦+æ‹†åˆ†å¤‡æ³¨+æå–æ ¸å¿ƒå†…å®¹"""
    clean_line = clean_special_chars(line)
    remark = f"{proto_prefix.upper()}èŠ‚ç‚¹"
    
    if '#' in clean_line:
        main_part, remark = clean_line.split('#', 1)
        remark = process_remark(remark, proto_prefix.upper())
    else:
        main_part = clean_line
    
    if not main_part.startswith(proto_prefix):
        raise ValueError(f"é{proto_prefix.upper()}èŠ‚ç‚¹æ ¼å¼")
    
    core_content = main_part[len(proto_prefix):].strip()
    if not core_content:
        raise ValueError(f"{proto_prefix.upper()}æ ¸å¿ƒå†…å®¹ä¸ºç©º")
    
    return core_content, remark

def decode_b64_sub(text: str) -> str:
    """è§£ç è®¢é˜…å†…å®¹"""
    original_text = text.strip()
    clean_for_b64 = re.sub(r'\s+', '', original_text)
    
    try:
        decoded = b64_safe_decode(clean_for_b64)
        decoded_line_count = len([l for l in decoded.split('\n') if l.strip()])
        LOG.info(log_msg(f"âœ… Base64è§£ç æˆåŠŸï¼Œè§£æå‡º{decoded_line_count}ä¸ªæœ‰æ•ˆèŠ‚ç‚¹"))
        return decoded
    except Exception as e:
        LOG.info(log_msg(f"âŒ Base64è§£ç å¤±è´¥: {str(e)[:50]}"))
        cleaned_lines = [l.strip() for l in original_text.split('\n')]
        plain_line_count = len([l for l in cleaned_lines if l])
        LOG.info(log_msg(f"âœ… æ˜æ–‡è®¢é˜…å¤„ç†å®Œæˆï¼Œè§£æå‡º{plain_line_count}ä¸ªæœ‰æ•ˆèŠ‚ç‚¹"))
        return '\n'.join(cleaned_lines)

def clean_node_content(line: str) -> str:
    """æ¸…æ´—èŠ‚ç‚¹å†…å®¹"""
    if not line:
        return ""
    line = re.sub(r'[\u4e00-\u9fa5]', '', line)
    error_keywords = ["è®¢é˜…å†…å®¹è§£æé”™è¯¯", "è§£æå¤±è´¥", "æ— æ•ˆèŠ‚ç‚¹", "ç¼ºå¤±å­—æ®µ"]
    for keyword in error_keywords:
        line = line.replace(keyword, "")
    return line.strip()

def is_private_ip(ip: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºç§æœ‰IP"""
    return bool(ip and CONFIG["filter"]["private_ip"].match(ip))

@lru_cache(maxsize=CONFIG["detection"]["dns"]["cache_size"])
def dns_resolve(domain: str) -> bool:
    """DNSè§£æï¼ˆå¢åŠ é‡è¯•ï¼‰"""
    if not domain or domain == "æœªçŸ¥":
        return False
    original_timeout = socket.getdefaulttimeout()
    socket.setdefaulttimeout(CONFIG["detection"]["dns"]["timeout"])
    try:
        for dns in CONFIG["detection"]["dns"]["servers"]:
            try:
                socket.gethostbyname_ex(domain)
                return True
            except (socket.gaierror, socket.timeout):
                continue
        LOG.info(log_msg(f"âš ï¸ åŸŸå{domain}è§£æå¤±è´¥ï¼ˆæ‰€æœ‰DNSæœåŠ¡å™¨å‡å¤±è´¥ï¼‰"))
        return False
    finally:
        socket.setdefaulttimeout(original_timeout)

def process_remark(remark: str, proto: str) -> str:
    """å¤„ç†èŠ‚ç‚¹å¤‡æ³¨ï¼ˆé¿å…label too longå´©æºƒï¼‰"""
    if not remark:
        return f"{proto}èŠ‚ç‚¹"
    try:
        decoded = unquote(remark)
        decoded = re.sub(r'[^\x20-\x7E\u4e00-\u9fa5]', '', decoded)
        b_remark = decoded.encode('utf-8')
        max_len = CONFIG["filter"]["max_remark_bytes"]
        
        if len(b_remark) <= max_len:
            return decoded
        
        # å®‰å…¨æˆªæ–­
        trunc_len = max_len
        while trunc_len > 0:
            try:
                trunc = b_remark[:trunc_len].decode('utf-8')
                break
            except UnicodeDecodeError:
                trunc_len -= 1
        else:
            trunc = "æˆªæ–­å¤±è´¥"
        
        if len(trunc.encode('utf-8')) + 3 <= max_len:
            trunc += "..."
        LOG.info(log_msg(f"âš ï¸ {proto}å¤‡æ³¨è¶…é™ï¼Œæˆªæ–­ä¸ºï¼š{trunc}", remark))
        return trunc
    except Exception as e:
        LOG.info(log_msg(f"âš ï¸ {proto}å¤‡æ³¨å¤„ç†å¤±è´¥ï¼š{str(e)[:30]}", remark))
        return f"{proto}èŠ‚ç‚¹"

def validate_fields(fields: Dict, required: List[str], proto: str, line: str) -> bool:
    """å­—æ®µæ ¡éªŒï¼šä»…åˆ¤æ–­å­—æ®µæ˜¯å¦å­˜åœ¨"""
    missing = [f for f in required if f not in fields]
    if missing:
        LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤æ— æ•ˆ{proto}èŠ‚ç‚¹ï¼šç¼ºå¤±{','.join(missing)}", line, proto))
        return False
    return True

def extract_ip_port(line: str) -> Tuple[Optional[str], str, int]:
    """æå–IP/ç«¯å£"""
    ip_match = re.search(r'@([\d\.a-zA-Z-]+):', line)
    ip = ip_match.group(1) if ip_match else None
    
    domain_match = re.search(r'sni=([^&]+)|host=([^&]+)', line, re.I)
    domain = next((g for g in domain_match.groups() if g), "") if domain_match else ""
    
    port_match = re.search(r':(\d+)', line)
    port = validate_port(port_match.group(1)) if port_match else CONFIG["filter"]["DEFAULT_PORT"]
    return ip, domain, port

# ========== åè®®è§£æå‡½æ•° ==========
def parse_vmess(line: str) -> Optional[Dict]:
    """è§£æVMessèŠ‚ç‚¹ï¼šç²¾å‡†æå–Base64ä¸²ï¼Œæˆªæ–­éBase64å­—ç¬¦"""
    try:
        base64_match = re.match(r'^[A-Za-z0-9+/=]+', line[8:].strip())
        if not base64_match:
            raise ValueError("æœªæå–åˆ°æœ‰æ•ˆBase64å­—ç¬¦æ®µ")
        
        vmess_part = base64_match.group(0)[:1024]
        decoded = b64_safe_decode(vmess_part)
        
        json_match = re.search(r'\{.*\}', decoded, re.DOTALL)
        if not json_match:
            raise ValueError("æœªæå–åˆ°æœ‰æ•ˆJSONé…ç½®")
        
        cfg = json.loads(re.sub(r'[\x00-\x1f\x7f-\x9f\u3000]', '', json_match.group(0)))
        if not validate_fields(cfg, ["add", "port", "id"], "VMess", line):
            return None
        
        # é»˜è®¤å€¼å…œåº•
        cfg["ps"] = process_remark(cfg.get('ps', ''), "VMess")
        cfg["port"] = validate_port(cfg.get('port', CONFIG["filter"]["DEFAULT_PORT"]))
        cfg["aid"] = cfg.get('aid', 0)
        cfg["net"] = cfg.get('net', 'tcp')
        cfg["scy"] = cfg.get('scy', 'auto')
        cfg["tls"] = cfg.get('tls', 'none')
        cfg["host"] = cfg.get('host', cfg["add"])
        cfg["sni"] = cfg.get('sni', cfg["add"])

        return {
            "address": cfg["add"],
            "port": cfg["port"],
            "id": cfg["id"],
            "alterId": cfg["aid"],
            "security": cfg["scy"],
            "network": cfg["net"],
            "tls": cfg["tls"],
            "serverName": cfg["host"] or cfg["sni"],
            "ps": cfg["ps"]
        }
    except Exception as e:
        LOG.info(log_msg(f"âŒ VMessè§£æé”™è¯¯: {str(e)}", line, "vmess"))
        return None

def parse_vless(line: str) -> Optional[Dict]:
    """è§£æVLESSèŠ‚ç‚¹"""
    try:
        core_content, remark = proto_preprocess(line, "vless://")
        vless_parts = core_content.split('?', 1)
        base_part = vless_parts[0]
        param_part = vless_parts[1] if len(vless_parts) > 1 else ''
        
        if '@' not in base_part:
            raise ValueError("ç¼ºå¤±UUID@åœ°å€æ ¼å¼")
        
        uuid, addr_port = base_part.split('@', 1)
        if not uuid or not addr_port or ':' not in addr_port:
            raise ValueError("UUID/åœ°å€ç«¯å£é”™è¯¯")
        
        address, port_str = addr_port.split(':', 1)
        port = validate_port(port_str)
        params = {}
        
        for p in param_part.split('&'):
            if '=' in p:
                k, v = p.split('=', 1)
                k_lower = k.lower()
                if k_lower == "remarks":
                    v = process_remark(v, "VLESS")
                params[k_lower] = v
        
        cfg = {
            "uuid": uuid,
            "address": address,
            "port": port,
            "security": params.get('security', 'tls'),
            "sni": params.get('sni', address),
            "network": params.get('type', 'tcp'),
            "remarks": params.get('remarks', 'VLESSèŠ‚ç‚¹')
        }
        
        if not validate_fields(cfg, ["uuid", "address", "port"], "VLESS", line):
            return None
        return cfg
    except ValueError as e:
        LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤æ— æ•ˆVLESSèŠ‚ç‚¹ï¼š{str(e)}", line, "vless"))
        return None
    except Exception as e:
        LOG.info(log_msg(f"âŒ VLESSè§£æé”™è¯¯: {str(e)}", line, "vless"))
        return None

def parse_trojan(line: str) -> Optional[Dict]:
    """è§£æTrojanèŠ‚ç‚¹"""
    try:
        core_content, remark = proto_preprocess(line, "trojan://")
        trojan_parts = core_content.split('?', 1)
        trojan_part = trojan_parts[0]
        param_part = trojan_parts[1] if len(trojan_parts) > 1 else ''
        
        if '@' not in trojan_part:
            raise ValueError("ç¼ºå¤±å¯†ç @åœ°å€æ ¼å¼")
        
        password, addr_port = trojan_part.split('@', 1)
        if not password or not addr_port or ':' not in addr_port:
            raise ValueError("å¯†ç /åœ°å€ç«¯å£é”™è¯¯")
        
        address, port_str = addr_port.rsplit(':', 1)
        port = validate_port(port_str)
        params = {}
        
        for p in param_part.split('&'):
            if '=' in p:
                k, v = p.split('=', 1)
                params[k.lower()] = v
        
        cfg = {
            "address": address,
            "port": port,
            "password": password,
            "sni": params.get('sni', address),
            "security": params.get('security', 'tls'),
            "label": remark
        }
        
        if not validate_fields(cfg, ["address", "port", "password"], "Trojan", line):
            return None
        return cfg
    except ValueError as e:
        LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤æ— æ•ˆTrojanèŠ‚ç‚¹ï¼š{str(e)}", line, "trojan"))
        return None
    except Exception as e:
        LOG.info(log_msg(f"âŒ Trojanè§£æé”™è¯¯: {str(e)}", line, "trojan"))
        return None

def parse_ss(line: str) -> Optional[Dict]:
    """è§£æSSèŠ‚ç‚¹ï¼šå…¼å®¹æ ‡å‡†/éä¸»æµæ ¼å¼"""
    try:
        ss_core, remark = proto_preprocess(line, "ss://")
        addr_port = ""
        decoded_auth = ""
        
        # éä¸»æµæ ¼å¼ï¼ˆ@åœ¨Base64å¤–ï¼‰
        if '@' in ss_core:
            base64_part, addr_port = ss_core.split('@', 1)
            decoded_auth = b64_safe_decode(base64_part)
        # æ ‡å‡†æ ¼å¼ï¼ˆ@åœ¨Base64å†…ï¼‰
        else:
            decoded_auth = b64_safe_decode(ss_core)
            if '@' not in decoded_auth:
                raise ValueError("æ ‡å‡†æ ¼å¼ä½†Base64å†…æ— @åˆ†éš”ç¬¦")
            decoded_auth, addr_port = decoded_auth.split('@', 1)
        
        # æ ¡éªŒåœ°å€ç«¯å£
        if not addr_port or ':' not in addr_port:
            raise ValueError("åœ°å€ç«¯å£æ ¼å¼é”™è¯¯ï¼ˆéœ€ä¸ºIP:ç«¯å£/åŸŸå:ç«¯å£ï¼‰")
        address, port_str = addr_port.rsplit(':', 1)
        port = validate_port(port_str)
        
        # è§£æåŠ å¯†æ–¹å¼å’Œå¯†ç 
        if not decoded_auth:
            raise ValueError("åŠ å¯†æ–¹å¼/å¯†ç ä¸ºç©º")
        
        if ':' not in decoded_auth:
            method = CONFIG["filter"]["SS_DEFAULT_CIPHER"]
            password = decoded_auth.strip()
        else:
            method, password = decoded_auth.split(':', 1)
            method = method.strip()
            password = password.strip()
            if not method or not password:
                raise ValueError("åŠ å¯†æ–¹å¼æˆ–å¯†ç ä¸ºç©º")
        
        cfg = {
            "address": address.strip(),
            "port": port,
            "remark": remark,
            "method": method,
            "password": password
        }
        
        if not validate_fields(cfg, ["address", "port"], "SS", line):
            return None
        return cfg
    except ValueError as e:
        LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤æ— æ•ˆSSèŠ‚ç‚¹ï¼š{str(e)}", line, "ss"))
        return None
    except Exception as e:
        LOG.info(log_msg(f"âŒ SSè§£æé”™è¯¯: {str(e)}", line, "ss"))
        return None

def parse_hysteria(line: str) -> Optional[Dict]:
    """è§£æHysteriaèŠ‚ç‚¹"""
    try:
        core_content, remark = proto_preprocess(line, "hysteria://")
        hysteria_parts = core_content.split('?', 1)
        core_part = hysteria_parts[0]
        param_part = hysteria_parts[1] if len(hysteria_parts) > 1 else ''
        
        if '@' not in core_part:
            raise ValueError("ç¼ºå¤±è®¤è¯@åœ°å€æ ¼å¼")
        
        auth_part, addr_port = core_part.split('@', 1)
        if not auth_part or not addr_port or ':' not in addr_port:
            raise ValueError("è®¤è¯/åœ°å€ç«¯å£é”™è¯¯")
        
        address, port_str = addr_port.rsplit(':', 1)
        port = validate_port(port_str)
        params = {}
        
        for p in param_part.split('&'):
            if '=' in p:
                k, v = p.split('=', 1)
                params[k.lower()] = v
        
        cfg = {
            "address": address,
            "port": port,
            "password": auth_part,
            "obfs": params.get('obfs', ''),
            "auth": params.get('auth', ''),
            "alpn": params.get('alpn', ''),
            "label": remark
        }
        
        if not validate_fields(cfg, ["address", "port", "password"], "Hysteria", line):
            return None
        return cfg
    except ValueError as e:
        LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤æ— æ•ˆHysteriaèŠ‚ç‚¹ï¼š{str(e)}", line, "hysteria"))
        return None
    except Exception as e:
        LOG.info(log_msg(f"âŒ Hysteriaè§£æé”™è¯¯: {str(e)}", line, "hysteria"))
        return None

# ========== èŠ‚ç‚¹å¤„ç†é€»è¾‘ ==========
def test_node(ip: str, port: int, proto: str) -> bool:
    """æ£€æµ‹èŠ‚ç‚¹å¯ç”¨æ€§ï¼ˆç²¾ç®€socketé€»è¾‘ï¼‰"""
    port = validate_port(port)
    if not ip or is_private_ip(ip):
        return False
    
    ip_addr = ""
    def _tcp_connect(timeout: int) -> bool:
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
                sock.settimeout(timeout)
                return sock.connect_ex((ip_addr, port)) == 0
        except Exception:
            return False
    
    try:
        # DNSè§£æ
        try:
            ip_addr = socket.gethostbyname(ip)
        except socket.gaierror:
            LOG.info(log_msg(f"âš ï¸ DNSè§£æå¤±è´¥: {ip}", proto=proto))
            return False
        
        # åŸºç¡€TCPè¿æ¥
        timeout = CONFIG["detection"]["tcp_timeout"].get(proto, 5)
        if not _tcp_connect(timeout):
            return False
        
        # åè®®ä¸“å±æ£€æµ‹
        if proto in ["vmess", "vless", "trojan"]:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
                sock.settimeout(4)
                sock.connect((ip_addr, port))
                sock.send(b"\x00")
        elif proto == "hysteria":
            with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as udp_sock:
                udp_sock.settimeout(4)
                udp_sock.sendto(b"\x00", (ip_addr, port))
        return True
    except Exception as e:
        LOG.info(log_msg(f"âš ï¸ TCPæ£€æµ‹å¤±è´¥: {str(e)[:30]}", proto=proto))
        return False

def process_single_node(node: Union[str, Dict]) -> Tuple[Optional[str], str, Optional[str], int, str]:
    """å¤„ç†å•ä¸ªèŠ‚ç‚¹"""
    raw_line = node["line"] if isinstance(node, dict) else node
    source_url = node.get("source_url", "") if isinstance(node, dict) else ""
    
    try:
        if not raw_line:
            return None, "", None, CONFIG["filter"]["DEFAULT_PORT"], source_url
        
        clean_line = clean_node_content(raw_line)
        if not clean_line:
            LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤ç©ºèŠ‚ç‚¹", raw_line))
            return None, "", None, CONFIG["filter"]["DEFAULT_PORT"], source_url
        
        ip, domain, port = None, "", CONFIG["filter"]["DEFAULT_PORT"]
        cfg = None
        proto = ""
        
        # åè®®è·¯ç”±
        if clean_line.startswith('vmess://'):
            proto, cfg = "vmess", parse_vmess(clean_line)
        elif clean_line.startswith('vless://'):
            proto, cfg = "vless", parse_vless(clean_line)
        elif clean_line.startswith('trojan://'):
            proto, cfg = "trojan", parse_trojan(clean_line)
        elif clean_line.startswith('ss://'):
            proto, cfg = "ss", parse_ss(clean_line)
        elif clean_line.startswith('hysteria://'):
            proto, cfg = "hysteria", parse_hysteria(clean_line)
        else:
            proto = "other"
            ip, domain, port = extract_ip_port(clean_line)
        
        # æå–èŠ‚ç‚¹ä¿¡æ¯
        if cfg and isinstance(cfg, dict):
            ip = cfg.get("address", ip)
            domain = cfg.get("serverName") or cfg.get("sni") or domain
            port = cfg.get("port", port)
        
        # è¿‡æ»¤é€»è¾‘
        if is_private_ip(ip):
            LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤ç§æœ‰IPï¼š{ip}:{port}", clean_line, proto))
            return None, "", None, port, source_url
        
        if ip and cfg and not test_node(ip, port, proto):
            LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤ä¸å¯ç”¨èŠ‚ç‚¹ï¼š{ip}:{port}", clean_line, proto))
            return None, "", None, port, source_url
        
        if domain and not dns_resolve(domain):
            LOG.info(log_msg(f"âš ï¸ åŸŸå{domain}è§£æå¤±è´¥ï¼Œä½†IP{ip}æœ‰æ•ˆ", clean_line, proto))
        
        if not ip and not domain:
            LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤ç©ºåœ°å€èŠ‚ç‚¹", clean_line, proto))
            return None, "", None, port, source_url
        
        LOG.info(f"âœ… ä¿ç•™èŠ‚ç‚¹: {ip or domain}:{port}ï¼ˆ{proto}ï¼‰")
        return clean_line, domain, ip, port, source_url
    except Exception as e:
        LOG.info(log_msg(f"âŒ èŠ‚ç‚¹å¤„ç†é”™è¯¯: {str(e)}", raw_line, proto))
        return None, "", None, CONFIG["filter"]["DEFAULT_PORT"], source_url

def dedup_nodes(nodes: List[Dict]) -> List[Dict]:
    """èŠ‚ç‚¹å»é‡ï¼ˆç²¾ç®€protoåˆ¤æ–­ï¼‰"""
    seen = set()
    unique = []
    nodes.sort(key=lambda x: x["weight"], reverse=True)
    proto_list = ["vmess", "vless", "trojan", "ss", "hysteria"]
    
    for node in nodes:
        raw_line = node["line"]
        clean_line = clean_node_content(raw_line)
        ip = node.get("ip", "")
        port = node.get("port", CONFIG["filter"]["DEFAULT_PORT"])
        proto = "other"
        
        # æå‰ç»ˆæ­¢å¾ªç¯
        for p in proto_list:
            if clean_line.startswith(f"{p}://"):
                proto = p
                break
        
        key = f"{ip}:{port}:{proto}" if ip else f"{clean_line[:50]}:{proto}"
        if key not in seen:
            seen.add(key)
            unique.append({"line": raw_line, "source_url": node["source_url"]})
    return unique

# ========== æ•°æ®æºä¸ç»Ÿè®¡ ==========
def fetch_source_data(url: str, weight: int) -> Tuple[List[str], int]:
    """æ‹‰å–è®¢é˜…æºæ•°æ®"""
    cache_dir = ".cache"
    os.makedirs(cache_dir, exist_ok=True)
    cache_key = hashlib.md5(url.encode()).hexdigest()
    cache_path = os.path.join(cache_dir, cache_key)
    
    # åŠ è½½ç¼“å­˜
    if os.path.exists(cache_path):
        try:
            cache_mtime = os.path.getmtime(cache_path)
            if time.time() - cache_mtime < CONFIG["github"]["cache_ttl"]:
                with open(cache_path, "r", encoding="utf-8") as f:
                    lines = json.load(f)
                LOG.info(f"âœ… ç¼“å­˜åŠ è½½ {url}ï¼ˆæƒé‡{weight}ï¼‰ï¼ŒèŠ‚ç‚¹ {len(lines)} æ¡")
                return lines, weight
        except (json.JSONDecodeError, OSError) as e:
            LOG.info(f"âš ï¸ ç¼“å­˜è¯»å–å¤±è´¥ {url}: {str(e)[:50]}")
    
    time.sleep(CONFIG["github"]["interval"])
    
    # æ‹‰å–æ•°æ®
    for retry in range(CONFIG["request"]["retry"]):
        try:
            resp = SESSION.get(url, timeout=CONFIG["request"]["timeout"], verify=False)
            resp.raise_for_status()
            content = decode_b64_sub(resp.text)
            lines = [l.strip() for l in content.split('\n') if l.strip() and not l.startswith('#')]
            
            # ä¿å­˜ç¼“å­˜
            try:
                with open(cache_path, "w", encoding="utf-8") as f:
                    json.dump(lines, f, ensure_ascii=False)
            except OSError as e:
                LOG.info(f"âš ï¸ ç¼“å­˜å†™å…¥å¤±è´¥ {url}: {str(e)[:50]}")
            
            LOG.info(f"âœ… æ‹‰å–æˆåŠŸ {url}ï¼ˆæƒé‡{weight}ï¼‰ï¼ŒèŠ‚ç‚¹ {len(lines)} æ¡")
            return lines, weight
        except Exception as e:
            if retry < CONFIG["request"]["retry"] - 1:
                LOG.info(f"âš ï¸ æ‹‰å–å¤±è´¥ {url}ï¼ˆé‡è¯• {retry+1}ï¼‰: {str(e)[:80]}")
                time.sleep(CONFIG["request"]["retry_delay"])
            else:
                LOG.info(f"âŒ æ‹‰å–æœ€ç»ˆå¤±è´¥ {url}: {str(e)[:80]}")
                return [], weight
    return [], weight

def clean_expired_cache() -> None:
    """æ¸…ç†è¿‡æœŸç¼“å­˜"""
    cache_dir = ".cache"
    if not os.path.exists(cache_dir):
        return
    expire_seconds = CONFIG["github"]["cache_expire_days"] * 86400
    deleted = 0
    
    for file_name in os.listdir(cache_dir):
        file_path = os.path.join(cache_dir, file_name)
        try:
            if os.path.isfile(file_path) and time.time() - os.path.getmtime(file_path) > expire_seconds:
                os.remove(file_path)
                deleted += 1
        except OSError as e:
            LOG.info(f"âš ï¸ ç¼“å­˜åˆ é™¤å¤±è´¥ {file_name}: {str(e)[:50]}")
    
    if deleted:
        LOG.info(f"ğŸ—‘ï¸ æ¸…ç†è¿‡æœŸç¼“å­˜ {deleted} ä¸ª")

def validate_sources() -> bool:
    """æ ¡éªŒè®¢é˜…æºé…ç½®"""
    invalid = []
    pattern = re.compile(r'^https?://', re.IGNORECASE)
    
    for idx, src in enumerate(CONFIG["sources"], 1):
        url = src.get("url", "")
        weight = src.get("weight", 0)
        if not pattern.match(url):
            invalid.append(f"ç¬¬{idx}ä¸ªæºï¼šURLæ ¼å¼é”™è¯¯ {url}")
        if not isinstance(weight, int) or weight < 1:
            invalid.append(f"ç¬¬{idx}ä¸ªæºï¼šæƒé‡æ— æ•ˆ {url}ï¼ˆæƒé‡{weight}ï¼‰")
    
    if invalid:
        LOG.info("âŒ é…ç½®æ ¡éªŒå¤±è´¥ï¼š")
        for err in invalid:
            LOG.info(f"   - {err}")
        return False
    return True

def count_proto(lines: List[Union[str, Dict]]) -> Dict[str, int]:
    """ç»Ÿè®¡åè®®ç±»å‹"""
    count = {"vmess":0, "vless":0, "trojan":0, "ss":0, "hysteria":0, "other":0}
    for line in lines:
        line_str = line["line"] if isinstance(line, dict) else line
        clean_line = clean_node_content(line_str)
        if clean_line.startswith('vmess://'):
            count["vmess"] +=1
        elif clean_line.startswith('vless://'):
            count["vless"] +=1
        elif clean_line.startswith('trojan://'):
            count["trojan"] +=1
        elif clean_line.startswith('ss://'):
            count["ss"] +=1
        elif clean_line.startswith('hysteria://'):
            count["hysteria"] +=1
        else:
            count["other"] +=1
    return count

def fetch_all_sources() -> Tuple[List[Dict], Dict[str, Dict]]:
    """æ‹‰å–æ‰€æœ‰è®¢é˜…æº"""
    all_nodes = []
    source_records = {}
    
    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = {executor.submit(fetch_source_data, src["url"], src["weight"]): src["url"] for src in CONFIG["sources"]}
        for future in as_completed(futures):
            url = futures[future]
            try:
                lines, weight = future.result()
                proto_count = count_proto(lines)
                source_records[url] = {
                    "original": lines,
                    "original_count": len(lines),
                    "weight": weight,
                    "proto_count": proto_count,
                    "retained_count": 0,
                    "retained_lines": []
                }
                all_nodes.extend([{"line": l, "weight": weight, "source_url": url} for l in lines])
            except Exception as e:
                LOG.info(f"âŒ å¤„ç†æº{url}å¼‚å¸¸ï¼š{str(e)[:50]}")
                source_records[url] = {
                    "original": [],
                    "original_count":0,
                    "weight":0,
                    "proto_count":count_proto([]),
                    "retained_count":0
                }
    return all_nodes, source_records

def process_nodes(unique_nodes: List[Dict]) -> Tuple[List[str], List[Dict]]:
    """æ‰¹é‡å¤„ç†èŠ‚ç‚¹"""
    valid_lines = []
    valid_nodes = []
    seen_ips = set()
    seen_domains = set()
    total = len(unique_nodes)
    
    with ThreadPoolExecutor(max_workers=CONFIG["detection"]["thread_pool"]) as executor:
        futures = [executor.submit(process_single_node, node) for node in unique_nodes]
        for idx, future in enumerate(as_completed(futures)):
            if idx % 10 == 0:
                progress = (idx / total) * 100 if total > 0 else 0
                LOG.info(f"â³ å¤„ç†è¿›åº¦ï¼š{idx}/{total} ({progress:.1f}%)")
            try:
                line, domain, ip, port, source_url = future.result()
            except Exception as e:
                LOG.info(f"âš ï¸ èŠ‚ç‚¹å¤„ç†å¼‚å¸¸: {str(e)[:50]}")
                continue
            if not line:
                continue
            
            if domain in seen_domains or ip in seen_ips:
                continue
            if domain:
                seen_domains.add(domain)
            if ip:
                seen_ips.add(ip)
            
            valid_lines.append(line)
            valid_nodes.append({"line": line, "source_url": source_url})
    return valid_lines, valid_nodes

def generate_stats(all_nodes: List[Dict], unique_nodes: List[Dict], valid_lines: List[str], 
                   source_records: Dict, valid_nodes: List[Dict], start_time: float) -> None:
    """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯å¹¶ä¿å­˜ç»“æœ"""
    # æ›´æ–°ä¿ç•™è®°å½•
    for url in source_records:
        retained = [n for n in valid_nodes if n["source_url"] == url]
        source_records[url]["retained_count"] = len(retained)
        source_records[url]["retained_lines"] = retained
    
    # æ’åºï¼ˆä¼˜å…ˆReality/TLSèŠ‚ç‚¹ï¼‰
    def sort_key(line: str) -> int:
        score = 0
        if "reality" in line.lower(): score += 100
        elif "tls" in line.lower(): score += 50
        if line.startswith('vless://'): score += 40
        elif line.startswith('trojan://'): score += 30
        elif line.startswith('vmess://'): score += 20
        elif line.startswith('hysteria://'): score += 10
        elif line.startswith('ss://'): score += 5
        return score
    
    valid_lines.sort(key=sort_key, reverse=True)
    LOG.info(f"âœ… æœ€ç»ˆæœ‰æ•ˆèŠ‚ç‚¹ï¼š{len(valid_lines)} æ¡ï¼ˆReality/TLSä¼˜å…ˆï¼‰")
    
    # ä¿å­˜ç»“æœ
    clean_valid_lines = [clean_node_content(line) for line in valid_lines if clean_node_content(line)]
    encoded = base64.b64encode('\n'.join(clean_valid_lines).encode('utf-8')).decode('utf-8') if clean_valid_lines else ""
    
    try:
        with open('s1.txt', 'w', encoding='utf-8') as f:
            f.write(encoded)
        LOG.info(f"ğŸ“„ è®¢é˜…æ–‡ä»¶ä¿å­˜è‡³ s1.txtï¼ˆ{len(clean_valid_lines)} çº¯å‡€èŠ‚ç‚¹ï¼‰")
    except OSError as e:
        LOG.error(f"âŒ è®¢é˜…æ–‡ä»¶ä¿å­˜å¤±è´¥: {str(e)[:50]}")
    
    # è¾“å‡ºç»Ÿè®¡
    LOG.info(f"\nğŸ“‹ æ•°æ®æºç»Ÿè®¡ï¼š")
    for idx, src in enumerate(CONFIG["sources"], 1):
        url = src["url"]
        rec = source_records.get(url, {"original_count":0, "proto_count":count_proto([]), "retained_count":0})
        rate = f"{(rec['retained_count']/rec['original_count']*100):.2f}%" if rec['original_count']>0 else "0.00%"
        proto = rec["proto_count"]
        LOG.info(f"    {idx}. {url}")
        LOG.info(f"       - ğŸ“ åŸå§‹ï¼š{rec['original_count']} æ¡ï¼ˆVMessï¼š{proto['vmess']} | VLESSï¼š{proto['vless']} | Trojanï¼š{proto['trojan']} | SSï¼š{proto['ss']} | Hysteriaï¼š{proto['hysteria']}ï¼‰ | ä¿ç•™ï¼š{rec['retained_count']} æ¡ | ä¿ç•™ç‡ï¼š{rate}")
    
    valid_proto = count_proto(clean_valid_lines)
    total_cost = time.time() - start_time
    total_original = len(all_nodes)
    retention_rate = f"{(len(clean_valid_lines)/total_original*100):.2f}%" if total_original>0 else "0.00%"
    
    LOG.info(f"\nğŸ“Š ä»»åŠ¡æ€»ç»“ï¼š")
    LOG.info(f"   - åŸå§‹èŠ‚ç‚¹ï¼š{total_original} æ¡ | å»é‡åï¼š{len(unique_nodes)} æ¡ | æœ‰æ•ˆçº¯å‡€èŠ‚ç‚¹ï¼š{len(clean_valid_lines)} æ¡")
    LOG.info(f"   - åè®®åˆ†å¸ƒï¼šVMess({valid_proto['vmess']}) | VLESS({valid_proto['vless']}) | Trojan({valid_proto['trojan']}) | SS({valid_proto['ss']}) | Hysteria({valid_proto['hysteria']})")
    LOG.info(f"   - æ•´ä½“ä¿ç•™ç‡ï¼š{retention_rate}")
    LOG.info(f"   - è€—æ—¶ï¼š{total_cost:.2f} ç§’")

def main() -> None:
    """ä¸»å‡½æ•°"""
    start_time = time.time()
    
    if not validate_sources():
        LOG.info("âŒ é…ç½®æ ¡éªŒå¤±è´¥ï¼Œé€€å‡º")
        return
    
    clean_expired_cache()
    LOG.info(f"ğŸš€ å¼€å§‹èŠ‚ç‚¹æ›´æ–°ï¼ˆ{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}ï¼‰")
    
    all_nodes, source_records = fetch_all_sources()
    LOG.info(f"\nğŸ“Š æ‹‰å–å®Œæˆï¼ŒåŸå§‹èŠ‚ç‚¹ï¼š{len(all_nodes)} æ¡")
    
    unique_nodes = dedup_nodes(all_nodes)
    LOG.info(f"ğŸ” å»é‡åèŠ‚ç‚¹ï¼š{len(unique_nodes)} æ¡")
    
    valid_lines, valid_nodes = process_nodes(unique_nodes)
    generate_stats(all_nodes, unique_nodes, valid_lines, source_records, valid_nodes, start_time)
    
    # å…³é—­ä¼šè¯
    try:
        SESSION.close()
        LOG.info("ğŸ”Œ å…³é—­è¯·æ±‚ä¼šè¯")
    except Exception as e:
        LOG.info(f"âš ï¸ ä¼šè¯å…³é—­å¼‚å¸¸: {str(e)[:50]}")
    
    LOG.info("âœ… èŠ‚ç‚¹æ›´æ–°ä»»åŠ¡å®Œæˆï¼")

if __name__ == "__main__":
    main()
