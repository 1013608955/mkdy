import requests
import re
import socket
import base64
import binascii
import os
import time
import hashlib
import logging
from urllib.parse import unquote
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from functools import lru_cache
import urllib3
from typing import Dict, List, Tuple, Optional, Union
import json

# ========== åŸºç¡€é…ç½®ä¸åˆå§‹åŒ– ==========
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ç²¾ç®€é…ç½®ç»“æ„
CONFIG: Dict = {
    "sources": [
        {"url": "https://raw.githubusercontent.com/barry-far/V2ray-Config/main/Splitted-By-Protocol/vmess.txt", "weight": 5},
        {"url": "https://raw.githubusercontent.com/MatinGhanbari/v2ray-configs/main/subscriptions/v2ray/super-sub.txt", "weight": 5},
        {"url": "https://raw.githubusercontent.com/mfuu/v2ray/master/v2ray", "weight": 4},
        {"url": "https://raw.githubusercontent.com/ermaozi/get_subscribe/main/subscribe/v2ray.txt", "weight": 4},
        {"url": "https://raw.githubusercontent.com/free18/v2ray/refs/heads/main/v.txt", "weight": 3},
        {"url": "https://raw.githubusercontent.com/HakurouKen/free-node/main/public", "weight": 3},
        {"url": "https://raw.githubusercontent.com/Pawdroid/Free-servers/main/sub", "weight": 2}
    ],
    "request": {"timeout": 120, "retry": 2, "retry_delay": 2, "ua": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"},
    "github": {"token": os.getenv("GITHUB_TOKEN", ""), "interval": 0.5, "cache_ttl": 3600, "cache_expire_days": 7},
    "detection": {
        "tcp_timeout": {"vmess":4, "vless":4, "trojan":4, "ss":2, "hysteria":4},
        "tcp_retry": 1,
        "thread_pool": os.cpu_count() * 2 if os.cpu_count() else 8,
        "dns": {"servers": ["223.5.5.5", "119.29.29.29", "8.8.8.8", "1.1.1.1"], "timeout":5, "cache_size":1000}
    },
    "filter": {
        "private_ip": re.compile(r"^(192\.168\.|10\.|172\.(1[6-9]|2\d|3[0-1])\.|127\.|0\.0\.0\.0)"),
        "ports": range(1, 65535),
        "max_remark_bytes": 200  # å¢å¤§å¤‡æ³¨é•¿åº¦é™åˆ¶ï¼Œå‡å°‘label too longé”™è¯¯
    }
}

# å®šä¹‰å¸¸é‡
DNS_CACHE_MAXSIZE = CONFIG["detection"]["dns"]["cache_size"]

# æ—¥å¿—åˆå§‹åŒ–
def init_logger() -> logging.Logger:
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)
    logger.propagate = False
    if not logger.handlers:
        fmt = logging.Formatter("%(asctime)s - %(message)s", "%Y-%m-%d %H:%M:%S")
        handler = logging.StreamHandler()
        handler.setFormatter(fmt)
        logger.addHandler(handler)
    return logger

LOG = init_logger()

# å…¨å±€è¯·æ±‚ä¼šè¯
def init_session() -> requests.Session:
    sess = requests.Session()
    headers = {"User-Agent": CONFIG["request"]["ua"], "Accept": "application/vnd.github.v3.raw+json"}
    if CONFIG["github"]["token"]:
        headers["Authorization"] = f"token {CONFIG['github']['token']}"
    sess.headers.update(headers)
    adapter = requests.adapters.HTTPAdapter(pool_connections=10, pool_maxsize=20, max_retries=3)
    sess.mount("https://", adapter)
    sess.mount("http://", adapter)
    return sess

SESSION = init_session()

# ========== é€šç”¨å·¥å…·å‡½æ•° ==========
def validate_port(port: Union[str, int]) -> int:
    """æ ¡éªŒå¹¶è¿”å›åˆæ³•ç«¯å£ï¼Œé»˜è®¤443"""
    try:
        p = int(port)
        return p if p in CONFIG["filter"]["ports"] else 443
    except (ValueError, TypeError):
        return 443

def log_msg(content: str, line: str = "", proto: str = "") -> str:
    """æ—¥å¿—æ ¼å¼åŒ–"""
    if "ä¿ç•™èŠ‚ç‚¹" in content:
        line_part = ""
    else:
        if "è§£æé”™è¯¯" in content or "è¿‡æ»¤æ— æ•ˆ" in content or "ç©ºåœ°å€èŠ‚ç‚¹" in content:
            line_part = f"ï¼ˆ{line}ï¼‰" if line else ""
        else:
            safe_line = line[:20].encode('ascii', 'ignore').decode('ascii')
            line_part = f"ï¼ˆ{safe_line}...ï¼‰" if safe_line else ""
    proto_part = f"ï¼ˆ{proto}ï¼‰" if proto else ""
    return f"{content}{line_part}{proto_part}"

def is_base64(s: str) -> bool:
    """æ”¾å®½Base64æ ¡éªŒï¼Œä¼˜å…ˆè§£ç å†…å®¹"""
    if not s or len(s) < 4:
        return False
    try:
        s = s.rstrip('=')
        s += '=' * (4 - len(s) % 4) if len(s) % 4 != 0 else ''
        base64.b64decode(s)
        return True
    except (binascii.Error, ValueError, UnicodeDecodeError):
        return False

def decode_b64_sub(text: str) -> str:
    """è§£ç è®¢é˜…å†…å®¹"""
    original_text = text.strip()
    clean_for_b64 = re.sub(r'\s+', '', original_text)
    
    if is_base64(clean_for_b64):
        try:
            clean_for_b64 = clean_for_b64.rstrip('=')
            clean_for_b64 += '=' * (4 - len(clean_for_b64) % 4) if len(clean_for_b64) % 4 != 0 else ''
            decoded = base64.b64decode(clean_for_b64).decode('utf-8', errors='ignore')
            decoded_line_count = len([l for l in decoded.split('\n') if l.strip()])
            LOG.info(log_msg(f"âœ… Base64è§£ç æˆåŠŸï¼Œè§£æå‡º{decoded_line_count}ä¸ªæœ‰æ•ˆèŠ‚ç‚¹"))
            return decoded
        except Exception as e:
            LOG.info(log_msg(f"âŒ Base64è§£ç å¤±è´¥: {str(e)[:50]}"))
            return original_text
    else:
        cleaned_lines = [l.strip() for l in original_text.split('\n')]
        plain_line_count = len([l for l in cleaned_lines if l])
        LOG.info(log_msg(f"âœ… æ˜æ–‡è®¢é˜…å¤„ç†å®Œæˆï¼Œè§£æå‡º{plain_line_count}ä¸ªæœ‰æ•ˆèŠ‚ç‚¹"))
        return '\n'.join(cleaned_lines)

def clean_node_content(line: str) -> str:
    """æ¸…æ´—èŠ‚ç‚¹å†…å®¹"""
    if not line:
        return ""
    line = re.sub(r'[\u4e00-\u9fa5]', '', line)
    error_keywords = ["è®¢é˜…å†…å®¹è§£æé”™è¯¯", "è§£æå¤±è´¥", "æ— æ•ˆèŠ‚ç‚¹", "ç¼ºå¤±å­—æ®µ"]
    for keyword in error_keywords:
        line = line.replace(keyword, "")
    return line.strip()

def is_private_ip(ip: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºç§æœ‰IP"""
    return bool(ip and CONFIG["filter"]["private_ip"].match(ip))

@lru_cache(maxsize=DNS_CACHE_MAXSIZE)
def dns_resolve(domain: str) -> bool:
    """DNSè§£æï¼ˆå¢åŠ é‡è¯•ï¼‰"""
    if not domain or domain == "æœªçŸ¥":
        return False
    original_timeout = socket.getdefaulttimeout()
    socket.setdefaulttimeout(CONFIG["detection"]["dns"]["timeout"])
    try:
        # éå†å¤šä¸ªDNSæœåŠ¡å™¨é‡è¯•
        for dns in CONFIG["detection"]["dns"]["servers"]:
            try:
                # ä¸´æ—¶æŒ‡å®šDNSæœåŠ¡å™¨ï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…å¯é€šè¿‡socketé…ç½®ï¼Œè¿™é‡Œä¼˜å…ˆé‡è¯•ï¼‰
                socket.gethostbyname_ex(domain)
                return True
            except (socket.gaierror, socket.timeout):
                continue
        LOG.info(log_msg(f"âš ï¸ åŸŸå{domain}è§£æå¤±è´¥ï¼ˆæ‰€æœ‰DNSæœåŠ¡å™¨å‡å¤±è´¥ï¼‰"))
        return False
    finally:
        socket.setdefaulttimeout(original_timeout)

def process_remark(remark: str, proto: str) -> str:
    """å¤„ç†èŠ‚ç‚¹å¤‡æ³¨ï¼ˆå¢åŠ å¼‚å¸¸æ•è·ï¼Œé¿å…label too longå´©æºƒï¼‰"""
    if not remark:
        return f"{proto}èŠ‚ç‚¹"
    try:
        decoded = unquote(remark)
        # å…ˆè¿‡æ»¤ä¸å¯æ‰“å°å­—ç¬¦å’Œç‰¹æ®Šemojiï¼Œå‡å°‘å­—èŠ‚æ•°
        decoded = re.sub(r'[^\x20-\x7E\u4e00-\u9fa5]', '', decoded)
        b_remark = decoded.encode('utf-8')
        max_len = CONFIG["filter"]["max_remark_bytes"]
        if len(b_remark) <= max_len:
            return decoded
        
        # å®‰å…¨æˆªæ–­ï¼šä»åå¾€å‰æˆªæ–­ï¼Œé¿å…ä¹±ç 
        trunc_len = max_len
        while trunc_len > 0:
            try:
                trunc = b_remark[:trunc_len].decode('utf-8')
                break
            except UnicodeDecodeError:
                trunc_len -= 1
        else:
            trunc = "æˆªæ–­å¤±è´¥"
        
        if len(trunc.encode('utf-8')) + 3 <= max_len:
            trunc += "..."
        LOG.info(log_msg(f"âš ï¸ {proto}å¤‡æ³¨è¶…é™ï¼Œæˆªæ–­ä¸ºï¼š{trunc}", remark))
        return trunc
    except Exception as e:
        LOG.info(log_msg(f"âš ï¸ {proto}å¤‡æ³¨å¤„ç†å¤±è´¥ï¼š{str(e)[:30]}", remark))
        return f"{proto}èŠ‚ç‚¹"

def validate_fields(fields: Dict, required: List[str], proto: str, line: str) -> bool:
    """å­—æ®µæ ¡éªŒï¼šä»…åˆ¤æ–­å­—æ®µæ˜¯å¦å­˜åœ¨"""
    missing = [f for f in required if f not in fields]
    if missing:
        LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤æ— æ•ˆ{proto}èŠ‚ç‚¹ï¼šç¼ºå¤±{','.join(missing)}", line, proto))
        return False
    return True

def extract_ip_port(line: str) -> Tuple[Optional[str], str, int]:
    """æå–IP/ç«¯å£"""
    ip_match = re.search(r'@([\d\.a-zA-Z-]+):', line)
    ip = ip_match.group(1) if ip_match else None
    
    domain_match = re.search(r'sni=([^&]+)|host=([^&]+)', line, re.I)
    domain = next((g for g in domain_match.groups() if g), "") if domain_match else ""
    
    port_match = re.search(r':(\d+)', line)
    port = validate_port(port_match.group(1)) if port_match else 443
    return ip, domain, port

# ========== åè®®è§£æå‡½æ•°ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šç²¾å‡†æå–VMessçš„Base64ä¸² + ä¿®å¤SSè§£æé€»è¾‘ï¼‰ ==========
def parse_vmess(line: str) -> Optional[Dict]:
    """è§£æVMessèŠ‚ç‚¹ï¼š
    1. ä»…æ ¡éªŒadd/port/idä¸‰ä¸ªæ ¸å¿ƒå­—æ®µ
    2. ç²¾å‡†æå–Base64ä¸²ï¼Œæˆªæ–­åé¢æ‰€æœ‰éBase64å­—ç¬¦ï¼ˆemoji/ç‰¹æ®Šç¬¦å·ç­‰ï¼‰
    """
    try:
        # æ­¥éª¤1ï¼šæå–vmess://åçš„æ‰€æœ‰å†…å®¹
        vmess_raw = line[8:].strip()
        
        # æ ¸å¿ƒä¿®æ”¹ï¼šåŒ¹é…æœ€é•¿çš„è¿ç»­Base64å­—ç¬¦æ®µï¼ˆåªä¿ç•™A-Za-z0-9+/=ï¼‰
        # æ­£åˆ™è¯´æ˜ï¼š^[A-Za-z0-9+/=]+ åŒ¹é…å¼€å¤´è¿ç»­çš„Base64å­—ç¬¦ï¼Œåé¢çš„å…¨éƒ¨æˆªæ–­
        base64_match = re.match(r'^[A-Za-z0-9+/=]+', vmess_raw)
        if not base64_match:
            raise ValueError("æœªæå–åˆ°æœ‰æ•ˆBase64å­—ç¬¦æ®µ")
        vmess_part = base64_match.group(0)
        
        # æ­¥éª¤2ï¼šé™åˆ¶é•¿åº¦ï¼ˆé˜²æ­¢è¶…é•¿ä¸²ï¼‰
        vmess_part = vmess_part[:1024]
        
        # æ­¥éª¤3ï¼šæ ¡éªŒBase64æ ¼å¼
        if not is_base64(vmess_part):
            raise ValueError("éBase64æ ¼å¼")
        
        # æ­¥éª¤4ï¼šè¡¥å…¨å¡«å……ç¬¦å¹¶è§£ç 
        vmess_part = vmess_part.rstrip('=')
        vmess_part += '=' * (4 - len(vmess_part) % 4) if len(vmess_part) % 4 != 0 else ''
        decoded = base64.b64decode(vmess_part).decode('utf-8', errors='ignore')
        
        # æ­¥éª¤5ï¼šæå–JSONé…ç½®
        json_match = re.search(r'\{.*\}', decoded, re.DOTALL)
        if not json_match:
            raise ValueError("æœªæå–åˆ°æœ‰æ•ˆJSONé…ç½®")
        decoded = json_match.group(0)
        decoded = re.sub(r'[\x00-\x1f\x7f-\x9f\u3000]', '', decoded)
        cfg = json.loads(decoded)
        
        # æ­¥éª¤6ï¼šä»…æ ¡éªŒadd/port/idä¸‰ä¸ªçœŸæ­£å¿…å¡«å­—æ®µ
        if not validate_fields(cfg, ["add", "port", "id"], "VMess", line):
            return None
        
        # æ­¥éª¤7ï¼šéå¿…å¡«å­—æ®µé»˜è®¤å€¼å…œåº•ï¼ˆå¯¹é½å®¢æˆ·ç«¯é€»è¾‘ï¼‰
        cfg["ps"] = process_remark(cfg.get('ps', ''), "VMess")
        cfg["port"] = validate_port(cfg.get('port', 443))
        cfg["aid"] = cfg.get('aid', 0)          # aidé»˜è®¤0
        cfg["net"] = cfg.get('net', 'tcp')      # ç½‘ç»œç±»å‹é»˜è®¤tcp
        cfg["scy"] = cfg.get('scy', 'auto')     # åŠ å¯†æ–¹å¼é»˜è®¤auto
        cfg["tls"] = cfg.get('tls', 'none')     # TLSé»˜è®¤å…³é—­
        cfg["host"] = cfg.get('host', cfg["add"])  # hosté»˜è®¤åŒåœ°å€
        cfg["sni"] = cfg.get('sni', cfg["add"])    # snié»˜è®¤åŒåœ°å€

        # è¿”å›è§£æç»“æœ
        return {
            "address": cfg["add"],
            "port": cfg["port"],
            "id": cfg["id"],
            "alterId": cfg["aid"],
            "security": cfg["scy"],
            "network": cfg["net"],
            "tls": cfg["tls"],
            "serverName": cfg["host"] or cfg["sni"],
            "ps": cfg["ps"]
        }
    except Exception as e:
        LOG.info(log_msg(f"âŒ VMessè§£æé”™è¯¯: {str(e)}", line, "vmess"))
        return None

def parse_vless(line: str) -> Optional[Dict]:
    """è§£æVLESSèŠ‚ç‚¹"""
    try:
        vless_core = line[8:]
        vless_parts = vless_core.split('?', 1)
        base_part = vless_parts[0]
        param_part = vless_parts[1] if len(vless_parts) > 1 else ''
        
        if '@' not in base_part:
            raise ValueError("ç¼ºå¤±UUID@åœ°å€æ ¼å¼")
        
        uuid, addr_port = base_part.split('@', 1)
        if not uuid or not addr_port or ':' not in addr_port:
            raise ValueError("UUID/åœ°å€ç«¯å£é”™è¯¯")
        
        address, port_str = addr_port.split(':', 1)
        port = validate_port(port_str)
        params = {}
        for p in param_part.split('&'):
            if '=' in p:
                k, v = p.split('=', 1)
                k_lower = k.lower()
                if k_lower == "remarks":
                    v = process_remark(v, "VLESS")
                params[k_lower] = v
        
        cfg = {
            "uuid": uuid,
            "address": address,
            "port": port,
            "security": params.get('security', 'tls'),
            "sni": params.get('sni', address),
            "network": params.get('type', 'tcp'),
            "remarks": params.get('remarks', 'VLESSèŠ‚ç‚¹')
        }
        
        if not validate_fields(cfg, ["uuid", "address", "port"], "VLESS", line):
            return None
        return cfg
    except ValueError as e:
        LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤æ— æ•ˆVLESSèŠ‚ç‚¹ï¼š{str(e)}", line, "vless"))
        return None
    except Exception as e:
        LOG.info(log_msg(f"âŒ VLESSè§£æé”™è¯¯: {str(e)}", line, "vless"))
        return None

def parse_trojan(line: str) -> Optional[Dict]:
    """è§£æTrojanèŠ‚ç‚¹"""
    try:
        trojan_parts = line.split('#', 1)
        label = process_remark(trojan_parts[1], "Trojan") if len(trojan_parts) > 1 else ""
        trojan_core = trojan_parts[0]
        
        trojan_core_parts = trojan_core[8:].split('?', 1)
        trojan_part = trojan_core_parts[0]
        param_part = trojan_core_parts[1] if len(trojan_core_parts) > 1 else ''
        
        if '@' not in trojan_part:
            raise ValueError("ç¼ºå¤±å¯†ç @åœ°å€æ ¼å¼")
        
        password, addr_port = trojan_part.split('@', 1)
        if not password or not addr_port or ':' not in addr_port:
            raise ValueError("å¯†ç /åœ°å€ç«¯å£é”™è¯¯")
        
        address, port_str = addr_port.rsplit(':', 1)
        port = validate_port(port_str)
        params = {}
        for p in param_part.split('&'):
            if '=' in p:
                k, v = p.split('=', 1)
                params[k.lower()] = v
        
        cfg = {
            "address": address,
            "port": port,
            "password": password,
            "sni": params.get('sni', address),
            "security": params.get('security', 'tls'),
            "label": label or "TrojanèŠ‚ç‚¹"
        }
        
        if not validate_fields(cfg, ["address", "port", "password"], "Trojan", line):
            return None
        return cfg
    except ValueError as e:
        LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤æ— æ•ˆTrojanèŠ‚ç‚¹ï¼š{str(e)}", line, "trojan"))
        return None
    except Exception as e:
        LOG.info(log_msg(f"âŒ Trojanè§£æé”™è¯¯: {str(e)}", line, "trojan"))
        return None

# ========== æ ¸å¿ƒä¿®æ”¹ï¼šä¿®å¤SSèŠ‚ç‚¹è§£æé€»è¾‘ ==========
def parse_ss(line: str) -> Optional[Dict]:
    """è§£æSSèŠ‚ç‚¹ï¼ˆä¿®å¤é€»è¾‘ï¼šå…ˆæ‹†åˆ†å¤‡æ³¨ï¼Œå†è§£ç Base64ï¼‰"""
    try:
        # æ­¥éª¤1ï¼šæ‹†åˆ†å¤‡æ³¨ï¼ˆ#åé¢çš„éƒ¨åˆ†ï¼‰
        if '#' in line:
            ss_main, remark = line.split('#', 1)
            remark = process_remark(remark, "SS")
        else:
            ss_main = line
            remark = "SSèŠ‚ç‚¹"
        
        # æ­¥éª¤2ï¼šæå–ss://åçš„æ ¸å¿ƒéƒ¨åˆ†ï¼ˆBase64ç¼–ç ï¼‰
        if not ss_main.startswith('ss://'):
            raise ValueError("éSSèŠ‚ç‚¹æ ¼å¼")
        ss_base64 = ss_main[5:].strip()  # åªå–ss://åã€#å‰çš„éƒ¨åˆ†
        
        # æ­¥éª¤3ï¼šè§£ç Base64ï¼ˆæ ¸å¿ƒä¿®å¤ï¼šæ— è®ºæ˜¯å¦"çº¯Base64"ï¼Œå…ˆå°è¯•è§£ç ï¼‰
        try:
            # è¡¥å…¨Base64å¡«å……ç¬¦
            ss_base64 = ss_base64.rstrip('=')
            ss_base64 += '=' * (4 - len(ss_base64) % 4) if len(ss_base64) % 4 != 0 else ''
            ss_decoded = base64.b64decode(ss_base64).decode('utf-8', errors='ignore')
        except Exception:
            # è§£ç å¤±è´¥åˆ™è§†ä¸ºæ˜æ–‡æ ¼å¼ï¼ˆå…¼å®¹éä¸»æµå†™æ³•ï¼‰
            ss_decoded = ss_base64
        
        # æ­¥éª¤4ï¼šè§£æè§£ç åçš„å†…å®¹ï¼ˆåŠ å¯†æ–¹å¼:å¯†ç @åœ°å€:ç«¯å£ï¼‰
        if '@' not in ss_decoded:
            raise ValueError("ç¼ºå¤±@åˆ†éš”ç¬¦ï¼ˆåŠ å¯†æ–¹å¼:å¯†ç @åœ°å€:ç«¯å£ï¼‰")
        
        auth_part, addr_port = ss_decoded.split('@', 1)
        if not auth_part or not addr_port or ':' not in addr_port:
            raise ValueError("è®¤è¯éƒ¨åˆ†/åœ°å€ç«¯å£æ ¼å¼é”™è¯¯")
        
        # è§£æåŠ å¯†æ–¹å¼å’Œå¯†ç 
        if ':' not in auth_part:
            method = "aes-256-gcm"  # é»˜è®¤åŠ å¯†æ–¹å¼
            password = auth_part
        else:
            method, password = auth_part.split(':', 1)
        
        # è§£æåœ°å€å’Œç«¯å£
        address, port_str = addr_port.rsplit(':', 1)
        port = validate_port(port_str)
        
        # ç»„è£…é…ç½®
        cfg = {
            "address": address.strip(),
            "port": port,
            "remark": remark,
            "method": method.strip(),
            "password": password.strip()
        }
        
        # æ ¡éªŒæ ¸å¿ƒå­—æ®µ
        if not validate_fields(cfg, ["address", "port"], "SS", line):
            return None
        
        return cfg
    except ValueError as e:
        LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤æ— æ•ˆSSèŠ‚ç‚¹ï¼š{str(e)}", line, "ss"))
        return None
    except Exception as e:
        LOG.info(log_msg(f"âŒ SSè§£æé”™è¯¯: {str(e)}", line, "ss"))
        return None

def parse_hysteria(line: str) -> Optional[Dict]:
    """è§£æHysteriaèŠ‚ç‚¹"""
    try:
        hysteria_parts = line.split('#', 1)
        label = process_remark(hysteria_parts[1], "Hysteria") if len(hysteria_parts) > 1 else ""
        hysteria_core = hysteria_parts[0]
        
        hysteria_core_parts = hysteria_core[10:].split('?', 1)
        core_part = hysteria_core_parts[0]
        param_part = hysteria_core_parts[1] if len(hysteria_core_parts) > 1 else ''
        
        if '@' not in core_part:
            raise ValueError("ç¼ºå¤±è®¤è¯@åœ°å€æ ¼å¼")
        
        auth_part, addr_port = core_part.split('@', 1)
        if not auth_part or not addr_port or ':' not in addr_port:
            raise ValueError("è®¤è¯/åœ°å€ç«¯å£é”™è¯¯")
        
        address, port_str = addr_port.rsplit(':', 1)
        port = validate_port(port_str)
        params = {}
        for p in param_part.split('&'):
            if '=' in p:
                k, v = p.split('=', 1)
                params[k.lower()] = v
        
        cfg = {
            "address": address,
            "port": port,
            "password": auth_part,
            "obfs": params.get('obfs', ''),
            "auth": params.get('auth', ''),
            "alpn": params.get('alpn', ''),
            "label": label or "HysteriaèŠ‚ç‚¹"
        }
        
        if not validate_fields(cfg, ["address", "port", "password"], "Hysteria", line):
            return None
        return cfg
    except ValueError as e:
        LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤æ— æ•ˆHysteriaèŠ‚ç‚¹ï¼š{str(e)}", line, "hysteria"))
        return None
    except Exception as e:
        LOG.info(log_msg(f"âŒ Hysteriaè§£æé”™è¯¯: {str(e)}", line, "hysteria"))
        return None

# ========== èŠ‚ç‚¹å¤„ç†é€»è¾‘ ==========
def test_node(ip: str, port: int, proto: str) -> bool:
    """æ£€æµ‹èŠ‚ç‚¹å¯ç”¨æ€§ï¼ˆå¢åŠ è¶…æ—¶å’Œå¼‚å¸¸æ•è·ï¼‰"""
    port = validate_port(port)
    if not ip or is_private_ip(ip):
        return False
    
    try:
        timeout = CONFIG["detection"]["tcp_timeout"].get(proto, 5)  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°5ç§’
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
            sock.settimeout(timeout)
            # å…ˆå°è¯•DNSè§£æï¼ˆæ˜¾å¼è§£æï¼Œé¿å…éšå¼å¤±è´¥ï¼‰
            try:
                ip_addr = socket.gethostbyname(ip)
            except socket.gaierror:
                LOG.info(log_msg(f"âš ï¸ DNSè§£æå¤±è´¥: {ip}", proto=proto))
                return False
            # è¿æ¥ç«¯å£
            if sock.connect_ex((ip_addr, port)) != 0:
                return False
    except Exception as e:
        LOG.info(log_msg(f"âš ï¸ TCPæ£€æµ‹å¤±è´¥: {str(e)[:30]}", proto=proto))
        return False
    
    try:
        if proto in ["vmess", "vless", "trojan"]:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
                sock.settimeout(4)
                sock.connect((ip_addr, port))
                sock.send(b"\x00")
        elif proto == "hysteria":
            with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as udp_sock:
                udp_sock.settimeout(4)
                udp_sock.sendto(b"\x00", (ip_addr, port))
        return True
    except:
        return False

def process_single_node(node: Union[str, Dict]) -> Tuple[Optional[str], str, Optional[str], int, str]:
    """å¤„ç†å•ä¸ªèŠ‚ç‚¹"""
    raw_line = node["line"] if isinstance(node, dict) else node
    source_url = node.get("source_url", "") if isinstance(node, dict) else ""
    
    try:
        if not raw_line:
            return None, "", None, 443, source_url
        
        clean_line = clean_node_content(raw_line)
        if not clean_line:
            LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤ç©ºèŠ‚ç‚¹", raw_line))
            return None, "", None, 443, source_url
        
        ip, domain, port = None, "", 443
        cfg = None
        proto = ""
        
        # åè®®è·¯ç”±
        if clean_line.startswith('vmess://'):
            proto, cfg = "vmess", parse_vmess(clean_line)
        elif clean_line.startswith('vless://'):
            proto, cfg = "vless", parse_vless(clean_line)
        elif clean_line.startswith('trojan://'):
            proto, cfg = "trojan", parse_trojan(clean_line)
        elif clean_line.startswith('ss://'):
            proto, cfg = "ss", parse_ss(clean_line)
        elif clean_line.startswith('hysteria://'):
            proto, cfg = "hysteria", parse_hysteria(clean_line)
        else:
            proto = "other"
            ip, domain, port = extract_ip_port(clean_line)
        
        # æå–èŠ‚ç‚¹ä¿¡æ¯
        if cfg and isinstance(cfg, dict):
            ip = cfg.get("address", ip)
            domain = cfg.get("serverName") or cfg.get("sni") or domain
            port = cfg.get("port", port)
        
        # è¿‡æ»¤é€»è¾‘
        if is_private_ip(ip):
            LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤ç§æœ‰IPï¼š{ip}:{port}", clean_line, proto))
            return None, "", None, 443, source_url
        
        if ip and cfg and not test_node(ip, port, proto):
            LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤ä¸å¯ç”¨èŠ‚ç‚¹ï¼š{ip}:{port}", clean_line, proto))
            return None, "", None, 443, source_url
        
        if domain and not dns_resolve(domain):
            LOG.info(log_msg(f"âš ï¸ åŸŸå{domain}è§£æå¤±è´¥ï¼Œä½†IP{ip}æœ‰æ•ˆ", clean_line, proto))
        
        if not ip and not domain:
            LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤ç©ºåœ°å€èŠ‚ç‚¹", clean_line, proto))
            return None, "", None, 443, source_url
        
        LOG.info(f"âœ… ä¿ç•™èŠ‚ç‚¹: {ip or domain}:{port}ï¼ˆ{proto}ï¼‰")
        return clean_line, domain, ip, port, source_url
    except Exception as e:
        LOG.info(log_msg(f"âŒ èŠ‚ç‚¹å¤„ç†é”™è¯¯: {str(e)}", raw_line, proto))
        return None, "", None, 443, source_url

def dedup_nodes(nodes: List[Dict]) -> List[Dict]:
    """èŠ‚ç‚¹å»é‡"""
    seen = set()
    unique = []
    nodes.sort(key=lambda x: x["weight"], reverse=True)
    
    for node in nodes:
        raw_line = node["line"]
        clean_line = clean_node_content(raw_line)
        ip = node.get("ip", "")
        port = node.get("port", 443)
        
        proto = "other"
        proto_list = ["vmess", "vless", "trojan", "ss", "hysteria"]
        for p in proto_list:
            if clean_line.startswith(f"{p}://"):
                proto = p
                break
        
        key = f"{ip}:{port}:{proto}" if ip else f"{clean_line[:50]}:{proto}"
        if key not in seen:
            seen.add(key)
            unique.append({"line": raw_line, "source_url": node["source_url"]})
    return unique

# ========== æ•°æ®æºä¸ä¸»é€»è¾‘ ==========
def fetch_source_data(url: str, weight: int) -> Tuple[List[str], int]:
    """æ‹‰å–è®¢é˜…æºæ•°æ®"""
    cache_dir = ".cache"
    os.makedirs(cache_dir, exist_ok=True)
    cache_key = hashlib.md5(url.encode()).hexdigest()
    cache_path = os.path.join(cache_dir, cache_key)
    
    if os.path.exists(cache_path):
        try:
            cache_mtime = os.path.getmtime(cache_path)
            if time.time() - cache_mtime < CONFIG["github"]["cache_ttl"]:
                with open(cache_path, "r", encoding="utf-8") as f:
                    lines = json.load(f)
                LOG.info(f"âœ… ç¼“å­˜åŠ è½½ {url}ï¼ˆæƒé‡{weight}ï¼‰ï¼ŒèŠ‚ç‚¹ {len(lines)} æ¡")
                return lines, weight
        except (json.JSONDecodeError, OSError) as e:
            LOG.info(f"âš ï¸ ç¼“å­˜è¯»å–å¤±è´¥ {url}: {str(e)[:50]}")
    
    time.sleep(CONFIG["github"]["interval"])
    
    for retry in range(CONFIG["request"]["retry"]):
        try:
            resp = SESSION.get(url, timeout=CONFIG["request"]["timeout"], verify=False)
            resp.raise_for_status()
            content = decode_b64_sub(resp.text)
            lines = [l.strip() for l in content.split('\n') if l.strip() and not l.startswith('#')]
            
            try:
                with open(cache_path, "w", encoding="utf-8") as f:
                    json.dump(lines, f, ensure_ascii=False)
            except OSError as e:
                LOG.info(f"âš ï¸ ç¼“å­˜å†™å…¥å¤±è´¥ {url}: {str(e)[:50]}")
            
            LOG.info(f"âœ… æ‹‰å–æˆåŠŸ {url}ï¼ˆæƒé‡{weight}ï¼‰ï¼ŒèŠ‚ç‚¹ {len(lines)} æ¡")
            return lines, weight
        except Exception as e:
            if retry < CONFIG["request"]["retry"] - 1:
                LOG.info(f"âš ï¸ æ‹‰å–å¤±è´¥ {url}ï¼ˆé‡è¯• {retry+1}ï¼‰: {str(e)[:80]}")
                time.sleep(CONFIG["request"]["retry_delay"])
            else:
                LOG.info(f"âŒ æ‹‰å–æœ€ç»ˆå¤±è´¥ {url}: {str(e)[:80]}")
                return [], weight
    return [], weight

def clean_expired_cache() -> None:
    """æ¸…ç†è¿‡æœŸç¼“å­˜"""
    cache_dir = ".cache"
    if not os.path.exists(cache_dir):
        return
    expire_seconds = CONFIG["github"]["cache_expire_days"] * 86400
    deleted = 0
    for file_name in os.listdir(cache_dir):
        file_path = os.path.join(cache_dir, file_name)
        try:
            if os.path.isfile(file_path) and time.time() - os.path.getmtime(file_path) > expire_seconds:
                os.remove(file_path)
                deleted += 1
        except OSError as e:
            LOG.info(f"âš ï¸ ç¼“å­˜åˆ é™¤å¤±è´¥ {file_name}: {str(e)[:50]}")
    if deleted:
        LOG.info(f"ğŸ—‘ï¸ æ¸…ç†è¿‡æœŸç¼“å­˜ {deleted} ä¸ª")

def validate_sources() -> bool:
    """æ ¡éªŒè®¢é˜…æºé…ç½®"""
    invalid = []
    pattern = re.compile(r'^https?://', re.IGNORECASE)
    for idx, src in enumerate(CONFIG["sources"], 1):
        url = src.get("url", "")
        weight = src.get("weight", 0)
        if not pattern.match(url):
            invalid.append(f"ç¬¬{idx}ä¸ªæºï¼šURLæ ¼å¼é”™è¯¯ {url}")
        if not isinstance(weight, int) or weight < 1:
            invalid.append(f"ç¬¬{idx}ä¸ªæºï¼šæƒé‡æ— æ•ˆ {url}ï¼ˆæƒé‡{weight}ï¼‰")
    
    if invalid:
        LOG.info("âŒ é…ç½®æ ¡éªŒå¤±è´¥ï¼š")
        for err in invalid:
            LOG.info(f"   - {err}")
        return False
    return True

def count_proto(lines: List[Union[str, Dict]]) -> Dict[str, int]:
    """ç»Ÿè®¡åè®®ç±»å‹"""
    count = {"vmess":0, "vless":0, "trojan":0, "ss":0, "hysteria":0, "other":0}
    for line in lines:
        line_str = line["line"] if isinstance(line, dict) else line
        clean_line = clean_node_content(line_str)
        if clean_line.startswith('vmess://'):
            count["vmess"] +=1
        elif clean_line.startswith('vless://'):
            count["vless"] +=1
        elif clean_line.startswith('trojan://'):
            count["trojan"] +=1
        elif clean_line.startswith('ss://'):
            count["ss"] +=1
        elif clean_line.startswith('hysteria://'):
            count["hysteria"] +=1
        else:
            count["other"] +=1
    return count

def fetch_all_sources() -> Tuple[List[Dict], Dict[str, Dict]]:
    """æ‹‰å–æ‰€æœ‰è®¢é˜…æº"""
    all_nodes = []
    source_records = {}
    
    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = {executor.submit(fetch_source_data, src["url"], src["weight"]): src["url"] for src in CONFIG["sources"]}
        for future in as_completed(futures):
            url = futures[future]
            try:
                lines, weight = future.result()
                proto_count = count_proto(lines)
                source_records[url] = {
                    "original": lines,
                    "original_count": len(lines),
                    "weight": weight,
                    "proto_count": proto_count,
                    "retained_count": 0,
                    "retained_lines": []
                }
                all_nodes.extend([{"line": l, "weight": weight, "source_url": url} for l in lines])
            except Exception as e:
                LOG.info(f"âŒ å¤„ç†æº{url}å¼‚å¸¸ï¼š{str(e)[:50]}")
                source_records[url] = {
                    "original": [],
                    "original_count":0,
                    "weight":0,
                    "proto_count":count_proto([]),
                    "retained_count":0
                }
    return all_nodes, source_records

def process_nodes(unique_nodes: List[Dict]) -> Tuple[List[str], List[Dict]]:
    """æ‰¹é‡å¤„ç†èŠ‚ç‚¹"""
    valid_lines = []
    valid_nodes = []
    seen_ips = set()
    seen_domains = set()
    total = len(unique_nodes)
    
    with ThreadPoolExecutor(max_workers=CONFIG["detection"]["thread_pool"]) as executor:
        futures = [executor.submit(process_single_node, node) for node in unique_nodes]
        for idx, future in enumerate(as_completed(futures)):
            if idx % 10 == 0:
                progress = (idx / total) * 100 if total > 0 else 0
                LOG.info(f"â³ å¤„ç†è¿›åº¦ï¼š{idx}/{total} ({progress:.1f}%)")
            try:
                line, domain, ip, port, source_url = future.result()
            except Exception as e:
                LOG.info(f"âš ï¸ èŠ‚ç‚¹å¤„ç†å¼‚å¸¸: {str(e)[:50]}")
                continue
            if not line:
                continue
            
            if domain in seen_domains or ip in seen_ips:
                continue
            if domain:
                seen_domains.add(domain)
            if ip:
                seen_ips.add(ip)
            
            valid_lines.append(line)
            valid_nodes.append({"line": line, "source_url": source_url})
    return valid_lines, valid_nodes

def generate_stats(all_nodes: List[Dict], unique_nodes: List[Dict], valid_lines: List[str], 
                   source_records: Dict, valid_nodes: List[Dict], start_time: float) -> None:
    """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯å¹¶ä¿å­˜ç»“æœ"""
    # æ›´æ–°ä¿ç•™è®°å½•
    for url in source_records:
        retained = [n for n in valid_nodes if n["source_url"] == url]
        source_records[url]["retained_count"] = len(retained)
        source_records[url]["retained_lines"] = retained
    
    # æ’åºï¼ˆä¼˜å…ˆä¿ç•™å¸¦Reality/TLSçš„èŠ‚ç‚¹ï¼‰
    def sort_key(line: str) -> int:
        score = 0
        if "reality" in line.lower(): score += 100
        elif "tls" in line.lower(): score += 50
        if line.startswith('vless://'): score += 40
        elif line.startswith('trojan://'): score += 30
        elif line.startswith('vmess://'): score += 20
        elif line.startswith('hysteria://'): score += 10
        elif line.startswith('ss://'): score += 5
        return score
    
    valid_lines.sort(key=sort_key, reverse=True)
    LOG.info(f"âœ… æœ€ç»ˆæœ‰æ•ˆèŠ‚ç‚¹ï¼š{len(valid_lines)} æ¡ï¼ˆReality/TLSä¼˜å…ˆï¼‰")
    
    # ä¿å­˜çº¯å‡€èŠ‚ç‚¹åˆ°æ–‡ä»¶
    clean_valid_lines = [clean_node_content(line) for line in valid_lines if clean_node_content(line)]
    encoded = base64.b64encode('\n'.join(clean_valid_lines).encode('utf-8')).decode('utf-8') if clean_valid_lines else ""
    
    try:
        with open('s1.txt', 'w', encoding='utf-8') as f:
            f.write(encoded)
        LOG.info(f"ğŸ“„ è®¢é˜…æ–‡ä»¶ä¿å­˜è‡³ s1.txtï¼ˆ{len(clean_valid_lines)} çº¯å‡€èŠ‚ç‚¹ï¼‰")
    except OSError as e:
        LOG.error(f"âŒ è®¢é˜…æ–‡ä»¶ä¿å­˜å¤±è´¥: {str(e)[:50]}")
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    LOG.info(f"\nğŸ“‹ æ•°æ®æºç»Ÿè®¡ï¼š")
    for idx, src in enumerate(CONFIG["sources"], 1):
        url = src["url"]
        rec = source_records.get(url, {"original_count":0, "proto_count":count_proto([]), "retained_count":0})
        rate = f"{(rec['retained_count']/rec['original_count']*100):.2f}%" if rec['original_count']>0 else "0.00%"
        proto = rec["proto_count"]
        LOG.info(f"    {idx}. {url}")
        LOG.info(f"       - ğŸ“ åŸå§‹ï¼š{rec['original_count']} æ¡ï¼ˆVMessï¼š{proto['vmess']} | VLESSï¼š{proto['vless']} | Trojanï¼š{proto['trojan']} | SSï¼š{proto['ss']} | Hysteriaï¼š{proto['hysteria']}ï¼‰ | ä¿ç•™ï¼š{rec['retained_count']} æ¡ | ä¿ç•™ç‡ï¼š{rate}")
    
    valid_proto = count_proto(clean_valid_lines)
    total_cost = time.time() - start_time
    total_original = len(all_nodes)
    retention_rate = f"{(len(clean_valid_lines)/total_original*100):.2f}%" if total_original>0 else "0.00%"
    
    LOG.info(f"\nğŸ“Š ä»»åŠ¡æ€»ç»“ï¼š")
    LOG.info(f"   - åŸå§‹èŠ‚ç‚¹ï¼š{total_original} æ¡ | å»é‡åï¼š{len(unique_nodes)} æ¡ | æœ‰æ•ˆçº¯å‡€èŠ‚ç‚¹ï¼š{len(clean_valid_lines)} æ¡")
    LOG.info(f"   - åè®®åˆ†å¸ƒï¼šVMess({valid_proto['vmess']}) | VLESS({valid_proto['vless']}) | Trojan({valid_proto['trojan']}) | SS({valid_proto['ss']}) | Hysteria({valid_proto['hysteria']})")
    LOG.info(f"   - æ•´ä½“ä¿ç•™ç‡ï¼š{retention_rate}")
    LOG.info(f"   - è€—æ—¶ï¼š{total_cost:.2f} ç§’")

def main() -> None:
    """ä¸»å‡½æ•°"""
    start_time = time.time()
    
    # æ ¡éªŒé…ç½®
    if not validate_sources():
        LOG.info("âŒ é…ç½®æ ¡éªŒå¤±è´¥ï¼Œé€€å‡º")
        return
    
    # æ¸…ç†ç¼“å­˜
    clean_expired_cache()
    LOG.info(f"ğŸš€ å¼€å§‹èŠ‚ç‚¹æ›´æ–°ï¼ˆ{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}ï¼‰")
    
    # æ‹‰å–æ‰€æœ‰æº
    all_nodes, source_records = fetch_all_sources()
    LOG.info(f"\nğŸ“Š æ‹‰å–å®Œæˆï¼ŒåŸå§‹èŠ‚ç‚¹ï¼š{len(all_nodes)} æ¡")
    
    # å»é‡
    unique_nodes = dedup_nodes(all_nodes)
    LOG.info(f"ğŸ” å»é‡åèŠ‚ç‚¹ï¼š{len(unique_nodes)} æ¡")
    
    # å¤„ç†èŠ‚ç‚¹
    valid_lines, valid_nodes = process_nodes(unique_nodes)
    
    # ç”Ÿæˆç»Ÿè®¡
    generate_stats(all_nodes, unique_nodes, valid_lines, source_records, valid_nodes, start_time)
    
    # å…³é—­ä¼šè¯
    try:
        SESSION.close()
        LOG.info("ğŸ”Œ å…³é—­è¯·æ±‚ä¼šè¯")
    except Exception as e:
        LOG.info(f"âš ï¸ ä¼šè¯å…³é—­å¼‚å¸¸: {str(e)[:50]}")
    
    LOG.info("âœ… èŠ‚ç‚¹æ›´æ–°ä»»åŠ¡å®Œæˆï¼")

if __name__ == "__main__":
    main()
