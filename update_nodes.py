import requests
import re
import socket
import base64
import json
import binascii
import os
import time
import hashlib
import logging
from urllib.parse import unquote
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from functools import lru_cache
import urllib3
from typing import Dict, List, Tuple, Optional, Union

# ========== åŸºç¡€é…ç½®ä¸åˆå§‹åŒ– ==========
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ç²¾ç®€é…ç½®ç»“æ„ï¼Œåˆå¹¶å†—ä½™é…ç½®é¡¹
CONFIG: Dict = {
    "sources": [
        {"url": "https://raw.githubusercontent.com/barry-far/V2ray-Config/main/Splitted-By-Protocol/vmess.txt", "weight": 5},
        {"url": "https://raw.githubusercontent.com/MatinGhanbari/v2ray-configs/main/subscriptions/v2ray/super-sub.txt", "weight": 5},
        {"url": "https://raw.githubusercontent.com/mfuu/v2ray/master/v2ray", "weight": 4},
        {"url": "https://raw.githubusercontent.com/ermaozi/get_subscribe/main/subscribe/v2ray.txt", "weight": 4},
        {"url": "https://raw.githubusercontent.com/free18/v2ray/refs/heads/main/v.txt", "weight": 3},
        {"url": "https://raw.githubusercontent.com/HakurouKen/free-node/main/public", "weight": 3},
        {"url": "https://raw.githubusercontent.com/Pawdroid/Free-servers/main/sub", "weight": 2}
    ],
    "request": {"timeout": 120, "retry": 2, "retry_delay": 2, "ua": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"},
    "github": {"token": os.getenv("GITHUB_TOKEN", ""), "interval": 0.5, "cache_ttl": 3600, "cache_expire_days": 7},
    "detection": {
        "tcp_timeout": {"vmess":4, "vless":4, "trojan":4, "ss":2, "hysteria":4},
        "tcp_retry": 1,
        "thread_pool": os.cpu_count() * 2 if os.cpu_count() else 8,
        "dns": {"servers": ["223.5.5.5", "119.29.29.29", "8.8.8.8", "1.1.1.1"], "timeout":5, "cache_size":1000}
    },
    "filter": {
        "private_ip": re.compile(r"^(192\.168\.|10\.|172\.(1[6-9]|2\d|3[0-1])\.|127\.|0\.0\.0\.0)"),
        "ports": range(1, 65535),
        "max_remark_bytes": 120
    }
}

# å®šä¹‰å¸¸é‡ï¼ˆä¿®å¤lru_cacheåŠ¨æ€å‚æ•°éšæ‚£ï¼‰
DNS_CACHE_MAXSIZE = CONFIG["detection"]["dns"]["cache_size"]

# æ—¥å¿—åˆå§‹åŒ–ï¼ˆç²¾ç®€é€»è¾‘ï¼‰
def init_logger() -> logging.Logger:
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)
    logger.propagate = False
    if not logger.handlers:
        fmt = logging.Formatter("%(asctime)s - %(message)s", "%Y-%m-%d %H:%M:%S")
        handler = logging.StreamHandler()
        handler.setFormatter(fmt)
        logger.addHandler(handler)
    return logger

LOG = init_logger()

# å…¨å±€è¯·æ±‚ä¼šè¯ï¼ˆç²¾ç®€åˆå§‹åŒ–ï¼‰
def init_session() -> requests.Session:
    sess = requests.Session()
    headers = {"User-Agent": CONFIG["request"]["ua"], "Accept": "application/vnd.github.v3.raw+json"}
    if CONFIG["github"]["token"]:
        headers["Authorization"] = f"token {CONFIG['github']['token']}"
    sess.headers.update(headers)
    adapter = requests.adapters.HTTPAdapter(pool_connections=10, pool_maxsize=20, max_retries=3)
    sess.mount("https://", adapter)
    sess.mount("http://", adapter)
    return sess

SESSION = init_session()

# ========== é€šç”¨å·¥å…·å‡½æ•°ï¼ˆæè‡´ç²¾ç®€+ä¿®å¤éšæ‚£ï¼‰ ==========
def validate_port(port: Union[str, int]) -> int:
    """æ ¡éªŒå¹¶è¿”å›åˆæ³•ç«¯å£ï¼Œé»˜è®¤443"""
    try:
        p = int(port)
        return p if p in CONFIG["filter"]["ports"] else 443
    except (ValueError, TypeError):
        return 443

def log_msg(content: str, line: str = "", proto: str = "") -> str:
    """ç²¾ç®€æ—¥å¿—æ ¼å¼åŒ–"""
    line_part = f"ï¼ˆ{line[:20]}...ï¼‰" if line else ""
    proto_part = f"ï¼ˆ{proto}ï¼‰" if proto else ""
    return f"{content}{line_part}{proto_part}"

def is_base64(s: str) -> bool:
    """ç®€åŒ–Base64æ ¡éªŒ"""
    if not s or len(s) < 4:
        return False
    try:
        s += '=' * (4 - len(s) % 4) if len(s) % 4 != 0 else ''
        base64.b64decode(s, validate=True)
        return True
    except (binascii.Error, ValueError):
        return False

def decode_b64_sub(text: str) -> str:
    """ä¿®å¤æ ¸å¿ƒï¼šä¿ç•™æ˜æ–‡çš„æ¢è¡Œç¬¦ï¼Œä»…æ¸…ç†Base64çš„ç©ºç™½å­—ç¬¦ï¼Œè§£å†³æ‹‰å–æ•°é‡ä¸æ‰‹åŠ¨ä¸‹è½½ä¸ä¸€è‡´é—®é¢˜"""
    original_text = text.strip()
    # å…ˆå°è¯•åˆ¤æ–­æ˜¯å¦æ˜¯Base64ç¼–ç ï¼ˆBase64è®¢é˜…é€šå¸¸æ— æ¢è¡Œï¼Œæˆ–åªæœ‰å°‘é‡ç©ºç™½ï¼‰
    clean_for_b64 = re.sub(r'\s+', '', original_text)
    if is_base64(clean_for_b64):
        try:
            # Base64è§£ç ï¼šè§£ç åæ¢å¤ä¸ºå¤šè¡ŒèŠ‚ç‚¹
            clean_for_b64 += '=' * (4 - len(clean_for_b64) % 4) if len(clean_for_b64) % 4 != 0 else ''
            decoded = base64.b64decode(clean_for_b64).decode('utf-8', errors='ignore')
            # æ–°å¢æ—¥å¿—ï¼šæ‰“å°è§£ç åçš„èŠ‚ç‚¹æ•°ï¼Œæ–¹ä¾¿æ ¸å¯¹
            decoded_line_count = len([l for l in decoded.split('\n') if l.strip()])
            LOG.info(log_msg(f"âœ… Base64è§£ç æˆåŠŸï¼Œè§£æå‡º{decoded_line_count}ä¸ªæœ‰æ•ˆèŠ‚ç‚¹"))
            return decoded
        except Exception as e:
            LOG.info(log_msg(f"âŒ Base64è§£ç å¤±è´¥: {str(e)[:50]}"))
            return original_text  # è§£ç å¤±è´¥åˆ™è¿”å›åŸå§‹å†…å®¹
    else:
        # æ˜æ–‡è®¢é˜…ï¼šä»…æ¸…ç†æ¯è¡Œçš„é¦–å°¾ç©ºç™½ï¼Œä¿ç•™æ¢è¡Œç¬¦ï¼ˆæ ¸å¿ƒä¿®å¤ç‚¹ï¼‰
        cleaned_lines = [l.strip() for l in original_text.split('\n')]
        # æ–°å¢æ—¥å¿—ï¼šæ‰“å°æ˜æ–‡è®¢é˜…çš„èŠ‚ç‚¹æ•°ï¼Œæ–¹ä¾¿æ ¸å¯¹
        plain_line_count = len([l for l in cleaned_lines if l])
        LOG.info(log_msg(f"âœ… æ˜æ–‡è®¢é˜…å¤„ç†å®Œæˆï¼Œè§£æå‡º{plain_line_count}ä¸ªæœ‰æ•ˆèŠ‚ç‚¹"))
        return '\n'.join(cleaned_lines)

def is_private_ip(ip: str) -> bool:
    """ç®€åŒ–ç§æœ‰IPåˆ¤æ–­ï¼ˆå•æ­£åˆ™åŒ¹é…ï¼‰"""
    return bool(ip and CONFIG["filter"]["private_ip"].match(ip))

@lru_cache(maxsize=DNS_CACHE_MAXSIZE)  # ä½¿ç”¨å¸¸é‡ä¿®å¤åŠ¨æ€å‚æ•°éšæ‚£
def dns_resolve(domain: str) -> bool:
    """ç²¾ç®€DNSè§£æï¼ˆä¿®å¤å…¨å±€socketè¶…æ—¶ä¿®æ”¹éšæ‚£ï¼‰"""
    if not domain or domain == "æœªçŸ¥":
        return False
    # ä¿å­˜åŸæœ‰è¶…æ—¶ï¼Œæ‰§è¡Œåè¿˜åŸ
    original_timeout = socket.getdefaulttimeout()
    socket.setdefaulttimeout(CONFIG["detection"]["dns"]["timeout"])
    try:
        for dns in CONFIG["detection"]["dns"]["servers"]:
            try:
                socket.gethostbyname_ex(domain)
                return True
            except (socket.gaierror, socket.timeout):
                continue
        LOG.info(log_msg(f"âš ï¸ åŸŸå{domain}è§£æå¤±è´¥"))
        return False
    finally:
        # è¿˜åŸå…¨å±€socketè¶…æ—¶
        socket.setdefaulttimeout(original_timeout)

def process_remark(remark: str, proto: str) -> str:
    """ç²¾ç®€å¤‡æ³¨å¤„ç†é€»è¾‘"""
    if not remark:
        return f"{proto}èŠ‚ç‚¹"
    try:
        decoded = unquote(remark)
        b_remark = decoded.encode('utf-8')
        max_len = CONFIG["filter"]["max_remark_bytes"]
        if len(b_remark) <= max_len:
            return decoded
        
        # ç²¾ç®€æˆªæ–­é€»è¾‘
        for step in range(0, 6):
            try:
                trunc = b_remark[:max_len-step].decode('utf-8')
                break
            except UnicodeDecodeError:
                continue
        else:
            trunc = b_remark[:max_len-5].decode('utf-8', errors='ignore')
        
        # ç²¾ç®€çœç•¥å·å¤„ç†
        if len(trunc.encode('utf-8')) + 3 <= max_len:
            trunc += "..."
        LOG.info(log_msg(f"âš ï¸ {proto}å¤‡æ³¨è¶…é™ï¼Œæˆªæ–­ä¸º{len(trunc.encode('utf-8'))}å­—èŠ‚", remark))
        return trunc
    except Exception as e:
        LOG.info(log_msg(f"âš ï¸ {proto}å¤‡æ³¨å¤„ç†å¤±è´¥ï¼š{str(e)[:30]}", remark))
        return f"{proto}èŠ‚ç‚¹"

def validate_fields(fields: Dict, required: List[str], proto: str, line: str) -> bool:
    """ç²¾ç®€å­—æ®µæ ¡éªŒ"""
    missing = [f for f in required if not fields.get(f)]
    if missing:
        LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤æ— æ•ˆ{proto}èŠ‚ç‚¹ï¼šç¼ºå¤±{','.join(missing)}", line))
        return False
    return True

def extract_ip_port(line: str) -> Tuple[Optional[str], str, int]:
    """ç²¾ç®€IP/ç«¯å£/åŸŸåæå–"""
    ip_match = re.search(r'@([\d\.a-zA-Z-]+):', line)
    ip = ip_match.group(1) if ip_match else None
    
    domain_match = re.search(r'sni=([^&]+)|host=([^&]+)', line, re.I)
    domain = next((g for g in domain_match.groups() if g), "") if domain_match else ""
    
    port_match = re.search(r':(\d+)', line)
    port = validate_port(port_match.group(1)) if port_match else 443
    return ip, domain, port

# ========== åè®®è§£æå‡½æ•°ï¼ˆç»Ÿä¸€ç²¾ç®€+ä¿®å¤ç´¢å¼•è¶Šç•Œéšæ‚£ï¼‰ ==========
def parse_vmess(line: str) -> Optional[Dict]:
    """è§£æVMessï¼ˆç²¾ç®€é€»è¾‘+ä¿®å¤æˆªæ–­éšæ‚£ï¼‰"""
    try:
        # é™åˆ¶é•¿åº¦ä½†ä¿ç•™åˆç†èŒƒå›´ï¼ˆä¿®å¤ç¡¬ç¼–ç 500å¯èƒ½æˆªæ–­æœ‰æ•ˆå†…å®¹ï¼‰
        vmess_part = re.sub(r'[@#]', '', line[8:])[:1024]
        vmess_part = re.sub(r'[^A-Za-z0-9+/=]', '', vmess_part)
        if not is_base64(vmess_part):
            raise ValueError("éBase64æ ¼å¼")
        
        vmess_part += '=' * (4 - len(vmess_part) % 4) if len(vmess_part) % 4 != 0 else ''
        decoded = base64.b64decode(vmess_part).decode('utf-8', errors='ignore')
        json_match = re.search(r'\{.*\}', decoded, re.DOTALL)
        decoded = json_match.group(0) if json_match else decoded
        decoded = re.sub(r'[\x00-\x1f\x7f-\x9f\u3000]', '', decoded)
        cfg = json.loads(decoded)
        
        if not validate_fields(cfg, ["add", "port", "id", "aid"], "VMess", line):
            return None
        
        cfg["ps"] = process_remark(cfg.get('ps', ''), "VMess")
        cfg["port"] = validate_port(cfg.get('port', 443))
        return {
            "address": cfg.get('add'), "port": cfg["port"], "id": cfg.get('id'),
            "alterId": cfg.get('aid', 0), "security": cfg.get('scy', 'auto'),
            "network": cfg.get('net', 'tcp'), "tls": cfg.get('tls', ''),
            "serverName": cfg.get('host') or cfg.get('sni', ''), "ps": cfg["ps"]
        }
    except Exception as e:
        LOG.info(log_msg(f"âŒ VMessè§£æé”™è¯¯: {str(e)[:50]}", line))
        return None

def parse_vless(line: str) -> Optional[Dict]:
    """è§£æVLESSï¼ˆä¿®å¤ç´¢å¼•è¶Šç•Œéšæ‚£ï¼‰"""
    try:
        vless_core = line[8:]
        # å®‰å…¨æ‹†åˆ†å‚æ•°ï¼ˆé¿å…æ— ?æ—¶ç´¢å¼•è¶Šç•Œï¼‰
        vless_parts = vless_core.split('?', 1)
        base_part = vless_parts[0]
        param_part = vless_parts[1] if len(vless_parts) > 1 else ''
        
        if '@' not in base_part:
            raise ValueError("ç¼ºå¤±UUID@åœ°å€æ ¼å¼")
        
        uuid, addr_port = base_part.split('@', 1)
        if not uuid or not addr_port or ':' not in addr_port:
            raise ValueError("UUID/åœ°å€ç«¯å£é”™è¯¯")
        
        address, port_str = addr_port.split(':', 1)
        port = validate_port(port_str)
        # å®‰å…¨è§£æå‚æ•°
        params = {}
        for p in param_part.split('&'):
            if '=' in p:
                k, v = p.split('=', 1)
                k_lower = k.lower()
                if k_lower == "remarks":
                    v = process_remark(v, "VLESS")
                params[k_lower] = v
        
        cfg = {"uuid": uuid, "address": address, "port": port, "security": params.get('security', 'tls'),
               "sni": params.get('sni', ''), "network": params.get('type', 'tcp'), "remarks": params.get('remarks', 'VLESSèŠ‚ç‚¹')}
        
        if not validate_fields(cfg, ["uuid", "address", "port"], "VLESS", line):
            return None
        return cfg
    except ValueError as e:
        LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤æ— æ•ˆVLESSèŠ‚ç‚¹ï¼š{str(e)}", line))
        return None
    except Exception as e:
        LOG.info(log_msg(f"âŒ VLESSè§£æé”™è¯¯: {str(e)[:50]}", line))
        return None

def parse_trojan(line: str) -> Optional[Dict]:
    """è§£æTrojanï¼ˆä¿®å¤è¯­æ³•+ç´¢å¼•è¶Šç•Œéšæ‚£ï¼‰"""
    try:
        # å®‰å…¨å¤„ç†å¤‡æ³¨
        trojan_parts = line.split('#', 1)
        label = process_remark(trojan_parts[1], "Trojan") if len(trojan_parts) > 1 else ""
        trojan_core = trojan_parts[0]
        
        # å®‰å…¨æ‹†åˆ†å‚æ•°å’Œæ ¸å¿ƒéƒ¨åˆ†
        trojan_core_parts = trojan_core[8:].split('?', 1)
        trojan_part = trojan_core_parts[0]
        param_part = trojan_core_parts[1] if len(trojan_core_parts) > 1 else ''
        
        if '@' not in trojan_part:
            raise ValueError("ç¼ºå¤±å¯†ç @åœ°å€æ ¼å¼")
        
        password, addr_port = trojan_part.split('@', 1)
        if not password or not addr_port or ':' not in addr_port:
            raise ValueError("å¯†ç /åœ°å€ç«¯å£é”™è¯¯")
        
        address, port_str = addr_port.rsplit(':', 1)
        port = validate_port(port_str)
        # å®‰å…¨è§£æå‚æ•°
        params = {}
        for p in param_part.split('&'):
            if '=' in p:
                k, v = p.split('=', 1)
                params[k.lower()] = v
        
        cfg = {"address": address, "port": port, "password": password, "sni": params.get('sni', ''),
               "security": params.get('security', 'tls'), "label": label or "TrojanèŠ‚ç‚¹"}
        
        if not validate_fields(cfg, ["address", "port", "password"], "Trojan", line):
            return None
        return cfg
    except ValueError as e:
        LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤æ— æ•ˆTrojanèŠ‚ç‚¹ï¼š{str(e)}", line))
        return None
    except Exception as e:
        LOG.info(log_msg(f"âŒ Trojanè§£æé”™è¯¯: {str(e)[:50]}", line))
        return None

def parse_ss(line: str) -> Optional[Dict]:
    """è§£æSSï¼ˆç²¾ç®€é€»è¾‘ï¼‰"""
    try:
        ss_part = line[5:]
        if is_base64(ss_part):
            ss_part += '=' * (4 - len(ss_part) % 4) if len(ss_part) % 4 != 0 else ''
            ss_part = base64.b64decode(ss_part).decode('utf-8', errors='ignore')
        
        # å®‰å…¨å¤„ç†å¤‡æ³¨
        ss_parts = ss_part.split('#', 1)
        remark = process_remark(ss_parts[1], "SS") if len(ss_parts) > 1 else ""
        ss_core = ss_parts[0]
        
        if '@' not in ss_core:
            raise ValueError("ç¼ºå¤±@åˆ†éš”ç¬¦")
        
        auth_part, addr_port = ss_core.split('@', 1)
        if not auth_part or not addr_port or ':' not in addr_port:
            raise ValueError("è®¤è¯/åœ°å€ç«¯å£é”™è¯¯")
        
        address, port_str = addr_port.rsplit(':', 1)
        port = validate_port(port_str)
        method = auth_part.split(':')[0] if ':' in auth_part else ""
        
        cfg = {"address": address.strip(), "port": port, "remark": remark or "SSèŠ‚ç‚¹", "method": method}
        if not validate_fields(cfg, ["address", "port"], "SS", line):
            return None
        return cfg
    except ValueError as e:
        LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤æ— æ•ˆSSèŠ‚ç‚¹ï¼š{str(e)}", line))
        return None
    except Exception as e:
        LOG.info(log_msg(f"âŒ SSè§£æé”™è¯¯: {str(e)[:50]}", line))
        return None

def parse_hysteria(line: str) -> Optional[Dict]:
    """è§£æHysteriaï¼ˆä¿®å¤ç´¢å¼•è¶Šç•Œéšæ‚£ï¼‰"""
    try:
        # å®‰å…¨å¤„ç†å¤‡æ³¨
        hysteria_parts = line.split('#', 1)
        label = process_remark(hysteria_parts[1], "Hysteria") if len(hysteria_parts) > 1 else ""
        hysteria_core = hysteria_parts[0]
        
        # å®‰å…¨æ‹†åˆ†å‚æ•°å’Œæ ¸å¿ƒéƒ¨åˆ†
        hysteria_core_parts = hysteria_core[10:].split('?', 1)
        core_part = hysteria_core_parts[0]
        param_part = hysteria_core_parts[1] if len(hysteria_core_parts) > 1 else ''
        
        if '@' not in core_part:
            raise ValueError("ç¼ºå¤±è®¤è¯@åœ°å€æ ¼å¼")
        
        auth_part, addr_port = core_part.split('@', 1)
        if not auth_part or not addr_port or ':' not in addr_port:
            raise ValueError("è®¤è¯/åœ°å€ç«¯å£é”™è¯¯")
        
        address, port_str = addr_port.rsplit(':', 1)
        port = validate_port(port_str)
        # å®‰å…¨è§£æå‚æ•°
        params = {}
        for p in param_part.split('&'):
            if '=' in p:
                k, v = p.split('=', 1)
                params[k.lower()] = v
        
        cfg = {"address": address, "port": port, "password": auth_part, "obfs": params.get('obfs', ''),
               "auth": params.get('auth', ''), "alpn": params.get('alpn', ''), "label": label or "HysteriaèŠ‚ç‚¹"}
        
        if not validate_fields(cfg, ["address", "port", "password"], "Hysteria", line):
            return None
        return cfg
    except ValueError as e:
        LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤æ— æ•ˆHysteriaèŠ‚ç‚¹ï¼š{str(e)}", line))
        return None
    except Exception as e:
        LOG.info(log_msg(f"âŒ Hysteriaè§£æé”™è¯¯: {str(e)[:50]}", line))
        return None

# ========== èŠ‚ç‚¹æ£€æµ‹ä¸å¤„ç†ï¼ˆä¿®å¤cfgä¸ºNoneçš„éšæ‚£ï¼‰ ==========
def test_node(ip: str, port: int, proto: str) -> bool:
    """ç²¾ç®€èŠ‚ç‚¹å¯ç”¨æ€§æ£€æµ‹"""
    port = validate_port(port)
    if not ip or is_private_ip(ip):
        return False
    
    # TCPæ¡æ‰‹æ£€æµ‹
    try:
        timeout = CONFIG["detection"]["tcp_timeout"].get(proto, 3)
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
            sock.settimeout(timeout)
            if sock.connect_ex((ip, port)) != 0:
                return False
    except Exception as e:
        LOG.info(log_msg(f"âš ï¸ TCPæ£€æµ‹å¤±è´¥: {str(e)[:30]}", proto_type=proto))
        return False
    
    # ç®€æ˜“åè®®éªŒè¯
    try:
        if proto in ["vmess", "vless", "trojan"]:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
                sock.settimeout(4)
                sock.connect((ip, port))
                sock.send(b"\x00")
        elif proto == "hysteria":
            with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as udp_sock:
                udp_sock.settimeout(4)
                udp_sock.sendto(b"\x00", (ip, port))
        return True
    except:
        return True  # å®½æ¾éªŒè¯ï¼Œè¶…æ—¶/é‡ç½®å‡è§†ä¸ºå¯ç”¨

def process_single_node(node: Union[str, Dict]) -> Tuple[Optional[str], str, Optional[str], int, str]:
    """ç²¾ç®€å•èŠ‚ç‚¹å¤„ç†ï¼ˆä¿®å¤cfgä¸ºNoneçš„éšæ‚£ï¼‰"""
    line = node["line"] if isinstance(node, dict) else node
    source_url = node.get("source_url", "") if isinstance(node, dict) else ""
    
    try:
        if not line:
            return None, "", None, 443, source_url
        
        ip, domain, port = None, "", 443
        cfg = None
        proto = ""
        
        # åè®®è§£æè·¯ç”±
        if line.startswith('vmess://'):
            proto, cfg = "vmess", parse_vmess(line)
        elif line.startswith('vless://'):
            proto, cfg = "vless", parse_vless(line)
        elif line.startswith('trojan://'):
            proto, cfg = "trojan", parse_trojan(line)
        elif line.startswith('ss://'):
            proto, cfg = "ss", parse_ss(line)
        elif line.startswith('hysteria://'):
            proto, cfg = "hysteria", parse_hysteria(line)
        else:
            proto = "other"
            ip, domain, port = extract_ip_port(line)
        
        # è§£æç»“æœæå–ï¼ˆä¿®å¤cfgä¸ºNoneçš„éšæ‚£ï¼‰
        if cfg and isinstance(cfg, dict):
            ip = cfg.get("address", ip)
            domain = cfg.get("serverName") or cfg.get("sni") or domain
            port = cfg.get("port", port)
        
        # è¿‡æ»¤é€»è¾‘
        if is_private_ip(ip):
            LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤ç§æœ‰IPï¼š{ip}:{port}", line, proto))
            return None, "", None, 443, source_url
        
        # ä»…å½“ipå’Œcfgéƒ½å­˜åœ¨æ—¶æ‰æ£€æµ‹
        if ip and cfg:
            if not test_node(ip, port, proto):
                LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤ä¸å¯ç”¨èŠ‚ç‚¹ï¼š{ip}:{port}", line, proto))
                return None, "", None, 443, source_url
        
        if domain and not dns_resolve(domain):
            LOG.info(log_msg(f"âš ï¸ åŸŸå{domain}è§£æå¤±è´¥ï¼Œä½†IP{ip}æœ‰æ•ˆ", line, proto))
        
        if not ip and not domain:
            LOG.info(log_msg(f"ğŸ“ è¿‡æ»¤ç©ºåœ°å€èŠ‚ç‚¹", line, proto))
            return None, "", None, 443, source_url
        
        LOG.info(log_msg(f"âœ… ä¿ç•™èŠ‚ç‚¹: {ip or domain}:{port}", line, proto))
        return line, domain, ip, port, source_url
    except Exception as e:
        LOG.info(log_msg(f"âŒ èŠ‚ç‚¹å¤„ç†é”™è¯¯: {str(e)[:50]}", line))
        return None, "", None, 443, source_url

def dedup_nodes(nodes: List[Dict]) -> List[Dict]:
    """ç²¾ç®€å»é‡é€»è¾‘ï¼ˆä¿®å¤next()æ— é»˜è®¤å€¼éšæ‚£ï¼‰"""
    seen = set()
    unique = []
    nodes.sort(key=lambda x: x["weight"], reverse=True)
    
    for node in nodes:
        line = node["line"]
        ip = node.get("ip", "")
        port = node.get("port", 443)
        # å®‰å…¨è·å–åè®®ç±»å‹ï¼ˆæ·»åŠ é»˜è®¤å€¼ï¼‰
        proto_list = ["vmess", "vless", "trojan", "ss", "hysteria"]
        proto = "other"
        for p in proto_list:
            if line.startswith(f"{p}://"):
                proto = p
                break
        # ç”Ÿæˆå»é‡é”®
        key = f"{ip}:{port}:{proto}" if ip else f"{line[:50]}:{proto}"
        
        if key not in seen:
            seen.add(key)
            unique.append({"line": line, "source_url": node["source_url"]})
    return unique

# ========== æ•°æ®æºå¤„ç†ï¼ˆä¿®å¤ç¼“å­˜è¯»å†™å¼‚å¸¸å¤„ç†éšæ‚£ï¼‰ ==========
def fetch_source_data(url: str, weight: int) -> Tuple[List[str], int]:
    """ç²¾ç®€æºæ•°æ®æ‹‰å–ï¼ˆå¢å¼ºç¼“å­˜å¼‚å¸¸å¤„ç†ï¼‰"""
    # ç¼“å­˜å¤„ç†
    cache_dir = ".cache"
    os.makedirs(cache_dir, exist_ok=True)
    cache_key = hashlib.md5(url.encode()).hexdigest()
    cache_path = os.path.join(cache_dir, cache_key)
    
    # è¯»å–ç¼“å­˜ï¼ˆå¢å¼ºå¼‚å¸¸å¤„ç†ï¼‰
    if os.path.exists(cache_path):
        try:
            cache_mtime = os.path.getmtime(cache_path)
            if time.time() - cache_mtime < CONFIG["github"]["cache_ttl"]:
                with open(cache_path, "r", encoding="utf-8") as f:
                    lines = json.load(f)
                LOG.info(f"âœ… ç¼“å­˜åŠ è½½ {url}ï¼ˆæƒé‡{weight}ï¼‰ï¼ŒèŠ‚ç‚¹ {len(lines)} æ¡")
                return lines, weight
        except (json.JSONDecodeError, OSError, PermissionError) as e:
            LOG.info(f"âš ï¸ ç¼“å­˜è¯»å–å¤±è´¥ {url}: {str(e)[:50]}ï¼Œé‡æ–°æ‹‰å–")
    
    # é™æµ
    time.sleep(CONFIG["github"]["interval"])
    
    # é‡è¯•æ‹‰å–
    for retry in range(CONFIG["request"]["retry"]):
        try:
            resp = SESSION.get(url, timeout=CONFIG["request"]["timeout"], verify=False)
            resp.raise_for_status()
            content = decode_b64_sub(resp.text)
            lines = [l.strip() for l in content.split('\n') if l.strip() and not l.startswith('#')]
            
            # å†™å…¥ç¼“å­˜ï¼ˆå¢å¼ºå¼‚å¸¸å¤„ç†ï¼‰
            try:
                with open(cache_path, "w", encoding="utf-8") as f:
                    json.dump(lines, f, ensure_ascii=False)
            except (OSError, PermissionError) as e:
                LOG.info(f"âš ï¸ ç¼“å­˜å†™å…¥å¤±è´¥ {url}: {str(e)[:50]}")
            
            LOG.info(f"âœ… æ‹‰å–æˆåŠŸ {url}ï¼ˆæƒé‡{weight}ï¼‰ï¼ŒèŠ‚ç‚¹ {len(lines)} æ¡")
            return lines, weight
        except Exception as e:
            if retry < CONFIG["request"]["retry"] - 1:
                LOG.info(f"âš ï¸ æ‹‰å–å¤±è´¥ {url}ï¼ˆé‡è¯• {retry+1}ï¼‰: {str(e)[:80]}")
                time.sleep(CONFIG["request"]["retry_delay"])
            else:
                LOG.info(f"âŒ æ‹‰å–æœ€ç»ˆå¤±è´¥ {url}: {str(e)[:80]}")
                return [], weight
    return [], weight

def clean_expired_cache() -> None:
    """ç²¾ç®€ç¼“å­˜æ¸…ç†ï¼ˆå¢å¼ºå¼‚å¸¸å¤„ç†ï¼‰"""
    cache_dir = ".cache"
    if not os.path.exists(cache_dir):
        return
    expire_seconds = CONFIG["github"]["cache_expire_days"] * 86400
    deleted = 0
    for file_name in os.listdir(cache_dir):
        file_path = os.path.join(cache_dir, file_name)
        try:
            if os.path.isfile(file_path) and time.time() - os.path.getmtime(file_path) > expire_seconds:
                os.remove(file_path)
                deleted += 1
        except (OSError, PermissionError) as e:
            LOG.info(f"âš ï¸ ç¼“å­˜æ–‡ä»¶åˆ é™¤å¤±è´¥ {file_name}: {str(e)[:50]}")
    if deleted:
        LOG.info(f"ğŸ—‘ï¸ æ¸…ç†è¿‡æœŸç¼“å­˜ {deleted} ä¸ª")

def validate_sources() -> bool:
    """ç²¾ç®€æºé…ç½®æ ¡éªŒ"""
    invalid = []
    pattern = re.compile(r'^https?://', re.IGNORECASE)
    for idx, src in enumerate(CONFIG["sources"], 1):
        url = src.get("url", "")
        weight = src.get("weight", 0)
        if not pattern.match(url):
            invalid.append(f"ç¬¬{idx}ä¸ªæºï¼šURLæ ¼å¼é”™è¯¯ {url}")
        if not isinstance(weight, int) or weight < 1:
            invalid.append(f"ç¬¬{idx}ä¸ªæºï¼šæƒé‡æ— æ•ˆ {url}ï¼ˆæƒé‡{weight}ï¼‰")
    
    if invalid:
        LOG.info("âŒ æºé…ç½®æ ¡éªŒå¤±è´¥ï¼š")
        for err in invalid:
            LOG.info(f"   - {err}")
        return False
    return True

def count_proto(lines: List[Union[str, Dict]]) -> Dict[str, int]:
    """ç²¾ç®€åè®®ç»Ÿè®¡"""
    count = {"vmess":0, "vless":0, "trojan":0, "ss":0, "hysteria":0, "other":0}
    for line in lines:
        line_str = line["line"] if isinstance(line, dict) else line
        if line_str.startswith('vmess://'):
            count["vmess"] +=1
        elif line_str.startswith('vless://'):
            count["vless"] +=1
        elif line_str.startswith('trojan://'):
            count["trojan"] +=1
        elif line_str.startswith('ss://'):
            count["ss"] +=1
        elif line_str.startswith('hysteria://'):
            count["hysteria"] +=1
        else:
            count["other"] +=1
    return count

# ========== ä¸»å‡½æ•°æ‹†åˆ†ï¼ˆä¿®å¤globalå˜é‡éšæ‚£ï¼‰ ==========
def fetch_all_sources() -> Tuple[List[Dict], Dict[str, Dict]]:
    """æ‹‰å–æ‰€æœ‰æºæ•°æ®"""
    all_nodes = []
    source_records = {}
    
    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = {executor.submit(fetch_source_data, src["url"], src["weight"]): src["url"] for src in CONFIG["sources"]}
        for future in as_completed(futures):
            url = futures[future]
            try:
                lines, weight = future.result()
                proto_count = count_proto(lines)
                source_records[url] = {
                    "original": lines, "original_count": len(lines), "weight": weight,
                    "proto_count": proto_count, "retained_count": 0, "retained_lines": []
                }
                all_nodes.extend([{"line": l, "weight": weight, "source_url": url} for l in lines])
            except Exception as e:
                LOG.info(f"âŒ å¤„ç†æº{url}å¼‚å¸¸ï¼š{str(e)[:50]}", exc_info=True)
                source_records[url] = {"original": [], "original_count":0, "weight":0, "proto_count":count_proto([]), "retained_count":0}
    return all_nodes, source_records

def process_nodes(unique_nodes: List[Dict]) -> Tuple[List[str], List[Dict]]:
    """å¤„ç†å»é‡åçš„èŠ‚ç‚¹"""
    valid_lines = []
    valid_nodes = []
    seen_ips = set()
    seen_domains = set()
    total = len(unique_nodes)
    
    with ThreadPoolExecutor(max_workers=CONFIG["detection"]["thread_pool"]) as executor:
        futures = [executor.submit(process_single_node, node) for node in unique_nodes]
        for idx, future in enumerate(as_completed(futures)):
            if idx % 10 == 0:
                progress = (idx / total) * 100 if total > 0 else 0
                LOG.info(f"â³ å¤„ç†è¿›åº¦ï¼š{idx}/{total} ({progress:.1f}%)")
            try:
                line, domain, ip, port, source_url = future.result()
            except Exception as e:
                LOG.info(f"âš ï¸ èŠ‚ç‚¹å¤„ç†å¼‚å¸¸: {str(e)[:50]}", exc_info=True)
                continue
            if not line:
                continue
            
            # æœ€ç»ˆå»é‡
            if domain in seen_domains or ip in seen_ips:
                continue
            if domain:
                seen_domains.add(domain)
            if ip:
                seen_ips.add(ip)
            
            valid_lines.append(line)
            valid_nodes.append({"line": line, "source_url": source_url})
    return valid_lines, valid_nodes

def generate_stats(all_nodes: List[Dict], unique_nodes: List[Dict], valid_lines: List[str], 
                   source_records: Dict, valid_nodes: List[Dict], start_time: float) -> None:
    """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
    # æ›´æ–°æºä¿ç•™ç»Ÿè®¡
    for url in source_records:
        retained = [n for n in valid_nodes if n["source_url"] == url]
        source_records[url]["retained_count"] = len(retained)
        source_records[url]["retained_lines"] = retained
    
    # æ’åºï¼ˆReality/TLSä¼˜å…ˆï¼‰
    def sort_key(line: str) -> int:
        score = 0
        if "reality" in line.lower(): 
            score += 100
        elif "tls" in line.lower(): 
            score += 50
        if line.startswith('vless://'): 
            score += 40
        elif line.startswith('trojan://'): 
            score += 30
        elif line.startswith('vmess://'): 
            score += 20
        elif line.startswith('hysteria://'): 
            score += 10
        elif line.startswith('ss://'): 
            score += 5
        return score
    
    valid_lines.sort(key=sort_key, reverse=True)
    LOG.info(f"âœ… æœ€ç»ˆæœ‰æ•ˆèŠ‚ç‚¹ï¼š{len(valid_lines)} æ¡ï¼ˆReality/TLSä¼˜å…ˆï¼‰")
    
    # ä¿å­˜æ–‡ä»¶ï¼ˆä¿®å¤ç©ºå­—ç¬¦ä¸²ç¼–ç éšæ‚£ï¼‰
    if valid_lines:
        content = '\n'.join(valid_lines)
        encoded = base64.b64encode(content.encode('utf-8')).decode('utf-8')
    else:
        encoded = ""
    try:
        with open('s1.txt', 'w', encoding='utf-8') as f:
            f.write(encoded)
        LOG.info(f"ğŸ“„ è®¢é˜…æ–‡ä»¶ä¿å­˜è‡³ s1.txtï¼ˆ{len(valid_lines)} èŠ‚ç‚¹ï¼‰")
    except (OSError, PermissionError) as e:
        LOG.error(f"âŒ è®¢é˜…æ–‡ä»¶ä¿å­˜å¤±è´¥: {str(e)[:50]}")
    
    # è¾“å‡ºè¯¦ç»†ç»Ÿè®¡
    LOG.info(f"\nğŸ“‹ æ•°æ®æºç»Ÿè®¡ï¼š")
    for idx, src in enumerate(CONFIG["sources"], 1):
        url = src["url"]
        rec = source_records.get(url, {"original_count":0, "proto_count":count_proto([]), "retained_count":0})
        original_count = rec["original_count"]
        rate = f"{(rec['retained_count']/original_count*100):.2f}%" if original_count > 0 else "0.00%"
        proto = rec["proto_count"]
        LOG.info(f"    {idx}. {url}")
        stat_line = (f"       - ğŸ“ åŸå§‹ï¼š{original_count} æ¡ï¼ˆVMessï¼š{proto['vmess']} | VLESSï¼š{proto['vless']} | "
                     f"Trojanï¼š{proto['trojan']} | SSï¼š{proto['ss']} | Hysteriaï¼š{proto['hysteria']}ï¼‰ | "
                     f"ä¿ç•™ï¼š{rec['retained_count']} æ¡ | ä¿ç•™ç‡ï¼š{rate}")
        LOG.info(stat_line)
    
    # æ€»ç»Ÿè®¡
    valid_proto = count_proto(valid_lines)
    total_cost = time.time() - start_time
    total_original = len(all_nodes)
    retention_rate = f"{(len(valid_lines)/total_original*100):.2f}%" if total_original > 0 else "0.00%"
    
    LOG.info(f"\nğŸ“Š ä»»åŠ¡æ€»ç»“ï¼š")
    LOG.info(f"   - åŸå§‹èŠ‚ç‚¹ï¼š{total_original} æ¡ | å»é‡åï¼š{len(unique_nodes)} æ¡ | æœ‰æ•ˆèŠ‚ç‚¹ï¼š{len(valid_lines)} æ¡")
    LOG.info(f"   - åè®®åˆ†å¸ƒï¼šVMess({valid_proto['vmess']}) | VLESS({valid_proto['vless']}) | Trojan({valid_proto['trojan']}) | SS({valid_proto['ss']}) | Hysteria({valid_proto['hysteria']})")
    LOG.info(f"   - æ•´ä½“ä¿ç•™ç‡ï¼š{retention_rate}")
    LOG.info(f"   - è€—æ—¶ï¼š{total_cost:.2f} ç§’")

def main() -> None:
    """ä¸»å‡½æ•°ï¼ˆä¿®å¤æ‰€æœ‰éšæ‚£ï¼Œæ— globalå˜é‡ï¼‰"""
    start_time = time.time()
    
    # å‰ç½®æ£€æŸ¥
    if not validate_sources():
        LOG.info("âŒ é…ç½®æ ¡éªŒå¤±è´¥ï¼Œé€€å‡º")
        return
    
    # åˆå§‹åŒ–
    clean_expired_cache()
    LOG.info(f"ğŸš€ å¼€å§‹èŠ‚ç‚¹æ›´æ–°ï¼ˆ{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}ï¼‰")
    
    # æ ¸å¿ƒæµç¨‹
    all_nodes, source_records = fetch_all_sources()
    LOG.info(f"\nğŸ“Š æ‹‰å–å®Œæˆï¼ŒåŸå§‹èŠ‚ç‚¹ï¼š{len(all_nodes)} æ¡")
    
    unique_nodes = dedup_nodes(all_nodes)
    LOG.info(f"ğŸ” å»é‡åèŠ‚ç‚¹ï¼š{len(unique_nodes)} æ¡")
    
    valid_lines, valid_nodes = process_nodes(unique_nodes)
    generate_stats(all_nodes, unique_nodes, valid_lines, source_records, valid_nodes, start_time)
    
    # èµ„æºé‡Šæ”¾
    try:
        SESSION.close()
        LOG.info("ğŸ”Œ å…³é—­è¯·æ±‚ä¼šè¯ï¼Œé‡Šæ”¾èµ„æº")
    except Exception as e:
        LOG.info(f"âš ï¸ ä¼šè¯å…³é—­å¼‚å¸¸: {str(e)[:50]}")
    
    LOG.info("âœ… èŠ‚ç‚¹æ›´æ–°ä»»åŠ¡å®Œæˆï¼")

if __name__ == "__main__":
    main()
